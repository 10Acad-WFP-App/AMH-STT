{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65ba901e-04fd-4370-8349-5922a37763aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy.io.wavfile as wav\n",
    "import glob\n",
    "import numpy as np\n",
    "from six.moves import xrange as range\n",
    "import json\n",
    "from python_speech_features import mfcc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import (BatchNormalization, Conv1D, Dense, Input, \n",
    "    TimeDistributed, Activation, Bidirectional, SimpleRNN, GRU, LSTM)\n",
    "# from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import (Input, Lambda)\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint  \n",
    "import librosa \n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "import gc\n",
    "\n",
    "# import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27c17201-9ec8-4e7d-a59c-07d80a01a0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants \n",
    "SPACE_TOKEN = '<space>'\n",
    "SPACE_INDEX = 0\n",
    "FIRST_INDEX = 1\n",
    "FEAT_MASK_VALUE = 1e+10\n",
    "\n",
    "# Some configs\n",
    "# filters=200\n",
    "# kernel_size=11\n",
    "# conv_stride=2\n",
    "# conv_border_mode='valid'\n",
    "units=200\n",
    "num_features = 13\n",
    "num_units = 100\n",
    "num_classes = 222 + 1 # 285(including space) + blamk label = 286\n",
    "\n",
    "# Hyper-parameters\n",
    "num_epochs = 100\n",
    "num_layers = 1\n",
    "batch_size = 16\n",
    "initial_learning_rate = 0.0005\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe58f0c6-de98-40b6-ab43-3dd420eefc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "file_path = glob.glob('/home/dibora_gebreyohannes/AMH-STT/data/train/wav/*.wav')\n",
    "# file_path = file_path[28:32]\n",
    "audio_list = []\n",
    "fs_list = []\n",
    "dur_list = []\n",
    "dropped_file_path = []\n",
    "\n",
    "for file_name in file_path:\n",
    "    audio,fs = librosa.load(file_name,sr=16000)\n",
    "    dur = librosa.get_duration(audio,sr=16000)\n",
    "    if dur > 2 and dur < 6:\n",
    "        dropped_file_path.append(file_name)\n",
    "        audio_list.append(audio)\n",
    "        dur_list.append(dur)\n",
    "        fs_list.append(fs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53ef3f13-0679-4128-a785-46f813715e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "724"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(audio_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cdb52b7-cf76-4083-bbd3-288ad8cc3f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset composed of data with variable lengths\n",
    "inputs_list = []\n",
    "for index in range(len(audio_list)):\n",
    "    input_val = mfcc(audio_list[index], samplerate=fs_list[index])\n",
    "    input_val = (input_val - np.mean(input_val)) / np.std(input_val)\n",
    "    inputs_list.append(input_val)\n",
    "\n",
    "# Transform in 3D Array\n",
    "train_inputs = tf.ragged.constant([i for i in inputs_list], dtype=np.float32)\n",
    "train_seq_len = tf.cast(train_inputs.row_lengths(), tf.int32)\n",
    "train_inputs = train_inputs.to_tensor(default_value=FEAT_MASK_VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c773b459-59ae-44c1-8136-a366baa4bca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('labels.json', 'r', encoding='UTF-8') as label_file:\n",
    "    labels = json.load(label_file)\n",
    "with open('language_model.json', 'r', encoding='UTF-8') as language_file:\n",
    "    alphabets = json.load(language_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6866b469-9e4b-425e-817f-fc5b2a3f25bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Targets\n",
    "original_list = []\n",
    "targets_list = []\n",
    "\n",
    "for path in dropped_file_path:\n",
    "    file_name = path[:-4].split('wav')[1][1:]\n",
    "    # Read Label\n",
    "    label = labels[file_name]\n",
    "    original = \" \".join(label.strip().split(' '))\n",
    "    original_list.append(original)\n",
    "#     print(original)\n",
    "    target = original.replace(' ', '  ')\n",
    "    # print('step-1. ',target)\n",
    "    target = target.split(' ')\n",
    "    # print('step-2. ', target)\n",
    "    # Adding blank label\n",
    "    target = np.hstack([SPACE_TOKEN if x == '' else list(x) for x in target])\n",
    "    # print('step-3. ', target)\n",
    "    # Transform char into index\n",
    "    target = np.asarray([alphabets['char_to_num'][x] for x in target])\n",
    "    # print('step-4. ', target)\n",
    "    targets_list.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b00706-84e4-4b68-82fe-863431fa5dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a538fce2-5e7b-4a68-a1e8-c94bf3c75ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating sparse representation to feed the placeholder\n",
    "train_targets = tf.ragged.constant([i for i in targets_list], dtype=np.int32)\n",
    "train_targets_len = tf.cast(train_targets.row_lengths(), tf.int32)\n",
    "train_targets = train_targets.to_sparse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbd1d6c7-6281-4129-a4f5-6056ff0919d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_inputs, val_targets, val_seq_len, val_targets_len = train_inputs, train_targets, train_seq_len, train_targets_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b26420e6-239a-40d4-9169-ac3f1ec73681",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTCLossLayer(tf.keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        labels = inputs[0]\n",
    "        logits = inputs[1]\n",
    "        label_len = inputs[2]\n",
    "        logit_len = inputs[3]\n",
    "\n",
    "        logits_trans = tf.transpose(logits, (1,0,2))\n",
    "        label_len = tf.reshape(label_len, (-1,))\n",
    "        logit_len = tf.reshape(logit_len, (-1,))\n",
    "        loss = tf.reduce_mean(tf.nn.ctc_loss(labels, logits_trans, label_len, logit_len, blank_index=-1))\n",
    "        # define loss here instead of in compile\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        # Decode\n",
    "        decoded, _ = tf.nn.ctc_greedy_decoder(logits_trans, logit_len)\n",
    "\n",
    "        # Inaccuracy: label error rate\n",
    "        ler = tf.reduce_mean(tf.edit_distance(tf.cast(decoded[0], tf.int32),labels))\n",
    "        self.add_metric(ler, name='ler', aggregation='mean')\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2068651d-1947-48fb-bedb-a671095f20ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Training Cells\n",
    "num_units = 50\n",
    "cells = []\n",
    "for _ in range(num_layers):\n",
    "    cell = tf.keras.layers.GRUCell(num_units)\n",
    "    cells.append(cell)\n",
    "\n",
    "stack = tf.keras.layers.StackedRNNCells(cells)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08477705-ad36-44ea-b87e-a136207a3567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definning Input Parameters\n",
    "input_feature = tf.keras.layers.Input((None, num_features), name='input_feature')\n",
    "input_label = tf.keras.layers.Input((None,), dtype=tf.int32, sparse=True, name='input_label')\n",
    "input_feature_len = tf.keras.layers.Input((1,), dtype=tf.int32, name='input_feature_len')\n",
    "input_label_len =tf.keras.layers.Input((1,), dtype=tf.int32, name='input_label_len')\n",
    "\n",
    "input_masking = tf.keras.layers.Masking(FEAT_MASK_VALUE)(input_feature)\n",
    "x = tf.keras.layers.LSTM(100,return_sequences=True)(input_masking)\n",
    "x_1 = tf.keras.layers.BatchNormalization()(x)\n",
    "x_2 = tf.keras.layers.LSTM(100,return_sequences=True)(x_1)\n",
    "# x_3= tf.keras.layers.BatchNormalization()(x_2)\n",
    "# x = tf.keras.layers.LSTM(50,return_sequences=True)(x)\n",
    "# x = tf.keras.layers.BatchNormalization()(x)\n",
    "# layer_rnn = tf.keras.layers.LSTM(10, return_sequences=True)(layer_bn)\n",
    "# x = tf.keras.layers.Dropout(0.2, seed=42)(x)\n",
    "layer_output = tf.keras.layers.TimeDistributed(Dense(num_classes, kernel_initializer=tf.keras.initializers.TruncatedNormal(0.0,0.1), bias_initializer='zeros', name='logit'))(x_2)\n",
    "\n",
    "layer_loss = CTCLossLayer()([input_label, layer_output, input_label_len, input_feature_len])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ebad848-3b83-4a0a-acc9-cc02c2659d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_feature (InputLayer)      [(None, None, 13)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, None, 13)     0           input_feature[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, None, 100)    45600       masking[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, None, 100)    400         lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, None, 100)    80400       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "input_label (InputLayer)        [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 223)    22523       lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_label_len (InputLayer)    [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_feature_len (InputLayer)  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc_loss_layer (CTCLossLayer)   (None, None, 223)    0           input_label[0][0]                \n",
      "                                                                 time_distributed[0][0]           \n",
      "                                                                 input_label_len[0][0]            \n",
      "                                                                 input_feature_len[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 148,923\n",
      "Trainable params: 148,723\n",
      "Non-trainable params: 200\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create models for training and prediction\n",
    "model_train = tf.keras.models.Model(inputs=[input_feature, input_label, input_feature_len, input_label_len],\n",
    "            outputs=layer_loss)\n",
    "print(model_train.summary())\n",
    "model_predict = tf.keras.models.Model(inputs=input_feature, outputs=layer_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65a3acd2-a149-4e10-8305-80a2d67ef2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "46/46 [==============================] - 12s 104ms/step - loss: 667.9526 - ler: 0.9066 - val_loss: 144.5536 - val_ler: 0.8776\n",
      "\n",
      "Epoch 00001: ler improved from inf to 0.90665, saving model to best_model_RNN.hdf5\n",
      "Epoch 2/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 141.4641 - ler: 0.8628 - val_loss: 138.5162 - val_ler: 0.9026\n",
      "\n",
      "Epoch 00002: ler improved from 0.90665 to 0.86283, saving model to best_model_RNN.hdf5\n",
      "Epoch 3/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 136.8146 - ler: 0.8669 - val_loss: 133.2925 - val_ler: 0.8867\n",
      "\n",
      "Epoch 00003: ler did not improve from 0.86283\n",
      "Epoch 4/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 133.0566 - ler: 0.8476 - val_loss: 130.6001 - val_ler: 0.8549\n",
      "\n",
      "Epoch 00004: ler improved from 0.86283 to 0.84763, saving model to best_model_RNN.hdf5\n",
      "Epoch 5/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 128.9170 - ler: 0.8592 - val_loss: 128.8913 - val_ler: 0.8633\n",
      "\n",
      "Epoch 00005: ler did not improve from 0.84763\n",
      "Epoch 6/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 130.1588 - ler: 0.8511 - val_loss: 127.9434 - val_ler: 0.8671\n",
      "\n",
      "Epoch 00006: ler did not improve from 0.84763\n",
      "Epoch 7/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 125.5795 - ler: 0.8403 - val_loss: 127.0183 - val_ler: 0.8481\n",
      "\n",
      "Epoch 00007: ler improved from 0.84763 to 0.84031, saving model to best_model_RNN.hdf5\n",
      "Epoch 8/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 124.9224 - ler: 0.8476 - val_loss: 126.2892 - val_ler: 0.8574\n",
      "\n",
      "Epoch 00008: ler did not improve from 0.84031\n",
      "Epoch 9/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 127.4070 - ler: 0.8482 - val_loss: 126.1824 - val_ler: 0.8622\n",
      "\n",
      "Epoch 00009: ler did not improve from 0.84031\n",
      "Epoch 10/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 123.0905 - ler: 0.8376 - val_loss: 124.7374 - val_ler: 0.8529\n",
      "\n",
      "Epoch 00010: ler improved from 0.84031 to 0.83764, saving model to best_model_RNN.hdf5\n",
      "Epoch 11/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 124.9524 - ler: 0.8434 - val_loss: 123.7702 - val_ler: 0.8392\n",
      "\n",
      "Epoch 00011: ler did not improve from 0.83764\n",
      "Epoch 12/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 122.1043 - ler: 0.8405 - val_loss: 123.6695 - val_ler: 0.8531\n",
      "\n",
      "Epoch 00012: ler did not improve from 0.83764\n",
      "Epoch 13/250\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 121.9636 - ler: 0.8363 - val_loss: 122.5331 - val_ler: 0.8383\n",
      "\n",
      "Epoch 00013: ler improved from 0.83764 to 0.83629, saving model to best_model_RNN.hdf5\n",
      "Epoch 14/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 122.5351 - ler: 0.8356 - val_loss: 122.0607 - val_ler: 0.8329\n",
      "\n",
      "Epoch 00014: ler improved from 0.83629 to 0.83562, saving model to best_model_RNN.hdf5\n",
      "Epoch 15/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 122.1875 - ler: 0.8365 - val_loss: 123.1391 - val_ler: 0.8588\n",
      "\n",
      "Epoch 00015: ler did not improve from 0.83562\n",
      "Epoch 16/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 123.3432 - ler: 0.8412 - val_loss: 120.7690 - val_ler: 0.8371\n",
      "\n",
      "Epoch 00016: ler did not improve from 0.83562\n",
      "Epoch 17/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 121.7752 - ler: 0.8361 - val_loss: 120.5251 - val_ler: 0.8390\n",
      "\n",
      "Epoch 00017: ler did not improve from 0.83562\n",
      "Epoch 18/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 121.5379 - ler: 0.8365 - val_loss: 119.7698 - val_ler: 0.8288\n",
      "\n",
      "Epoch 00018: ler did not improve from 0.83562\n",
      "Epoch 19/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 119.6903 - ler: 0.8315 - val_loss: 119.2519 - val_ler: 0.8232\n",
      "\n",
      "Epoch 00019: ler improved from 0.83562 to 0.83149, saving model to best_model_RNN.hdf5\n",
      "Epoch 20/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 118.9697 - ler: 0.8298 - val_loss: 119.3790 - val_ler: 0.8421\n",
      "\n",
      "Epoch 00020: ler improved from 0.83149 to 0.82981, saving model to best_model_RNN.hdf5\n",
      "Epoch 21/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 118.8962 - ler: 0.8283 - val_loss: 118.6337 - val_ler: 0.8276\n",
      "\n",
      "Epoch 00021: ler improved from 0.82981 to 0.82831, saving model to best_model_RNN.hdf5\n",
      "Epoch 22/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 120.0962 - ler: 0.8303 - val_loss: 118.6147 - val_ler: 0.8308\n",
      "\n",
      "Epoch 00022: ler did not improve from 0.82831\n",
      "Epoch 23/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 119.9100 - ler: 0.8260 - val_loss: 117.6189 - val_ler: 0.8208\n",
      "\n",
      "Epoch 00023: ler improved from 0.82831 to 0.82596, saving model to best_model_RNN.hdf5\n",
      "Epoch 24/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 115.5006 - ler: 0.8247 - val_loss: 117.0912 - val_ler: 0.8311\n",
      "\n",
      "Epoch 00024: ler improved from 0.82596 to 0.82467, saving model to best_model_RNN.hdf5\n",
      "Epoch 25/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 116.2397 - ler: 0.8234 - val_loss: 117.3530 - val_ler: 0.8348\n",
      "\n",
      "Epoch 00025: ler improved from 0.82467 to 0.82337, saving model to best_model_RNN.hdf5\n",
      "Epoch 26/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 118.1685 - ler: 0.8215 - val_loss: 116.0227 - val_ler: 0.8228\n",
      "\n",
      "Epoch 00026: ler improved from 0.82337 to 0.82147, saving model to best_model_RNN.hdf5\n",
      "Epoch 27/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 118.1906 - ler: 0.8195 - val_loss: 115.4752 - val_ler: 0.8218\n",
      "\n",
      "Epoch 00027: ler improved from 0.82147 to 0.81948, saving model to best_model_RNN.hdf5\n",
      "Epoch 28/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 113.6151 - ler: 0.8141 - val_loss: 114.8247 - val_ler: 0.8214\n",
      "\n",
      "Epoch 00028: ler improved from 0.81948 to 0.81409, saving model to best_model_RNN.hdf5\n",
      "Epoch 29/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 115.2621 - ler: 0.8137 - val_loss: 114.6075 - val_ler: 0.8082\n",
      "\n",
      "Epoch 00029: ler improved from 0.81409 to 0.81368, saving model to best_model_RNN.hdf5\n",
      "Epoch 30/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 113.7823 - ler: 0.8082 - val_loss: 113.9667 - val_ler: 0.8091\n",
      "\n",
      "Epoch 00030: ler improved from 0.81368 to 0.80822, saving model to best_model_RNN.hdf5\n",
      "Epoch 31/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 115.6196 - ler: 0.8086 - val_loss: 114.4202 - val_ler: 0.8108\n",
      "\n",
      "Epoch 00031: ler did not improve from 0.80822\n",
      "Epoch 32/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 117.4832 - ler: 0.8349 - val_loss: 116.8078 - val_ler: 0.8152\n",
      "\n",
      "Epoch 00032: ler did not improve from 0.80822\n",
      "Epoch 33/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 115.9240 - ler: 0.8154 - val_loss: 115.1537 - val_ler: 0.8175\n",
      "\n",
      "Epoch 00033: ler did not improve from 0.80822\n",
      "Epoch 34/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 115.4826 - ler: 0.8149 - val_loss: 114.6274 - val_ler: 0.8179\n",
      "\n",
      "Epoch 00034: ler did not improve from 0.80822\n",
      "Epoch 35/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 112.2346 - ler: 0.8111 - val_loss: 113.0250 - val_ler: 0.8049\n",
      "\n",
      "Epoch 00035: ler did not improve from 0.80822\n",
      "Epoch 36/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 111.0609 - ler: 0.8074 - val_loss: 112.5269 - val_ler: 0.7977\n",
      "\n",
      "Epoch 00036: ler improved from 0.80822 to 0.80739, saving model to best_model_RNN.hdf5\n",
      "Epoch 37/250\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 114.3418 - ler: 0.8035 - val_loss: 111.7320 - val_ler: 0.8027\n",
      "\n",
      "Epoch 00037: ler improved from 0.80739 to 0.80351, saving model to best_model_RNN.hdf5\n",
      "Epoch 38/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 111.3535 - ler: 0.8021 - val_loss: 111.2865 - val_ler: 0.7968\n",
      "\n",
      "Epoch 00038: ler improved from 0.80351 to 0.80213, saving model to best_model_RNN.hdf5\n",
      "Epoch 39/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 109.1708 - ler: 0.7997 - val_loss: 110.6649 - val_ler: 0.7998\n",
      "\n",
      "Epoch 00039: ler improved from 0.80213 to 0.79969, saving model to best_model_RNN.hdf5\n",
      "Epoch 40/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 109.7976 - ler: 0.7993 - val_loss: 110.4871 - val_ler: 0.7996\n",
      "\n",
      "Epoch 00040: ler improved from 0.79969 to 0.79933, saving model to best_model_RNN.hdf5\n",
      "Epoch 41/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 109.9320 - ler: 0.7975 - val_loss: 109.3743 - val_ler: 0.7897\n",
      "\n",
      "Epoch 00041: ler improved from 0.79933 to 0.79754, saving model to best_model_RNN.hdf5\n",
      "Epoch 42/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 110.1373 - ler: 0.7899 - val_loss: 109.7830 - val_ler: 0.7940\n",
      "\n",
      "Epoch 00042: ler improved from 0.79754 to 0.78986, saving model to best_model_RNN.hdf5\n",
      "Epoch 43/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 110.3769 - ler: 0.7869 - val_loss: 108.5207 - val_ler: 0.7837\n",
      "\n",
      "Epoch 00043: ler improved from 0.78986 to 0.78691, saving model to best_model_RNN.hdf5\n",
      "Epoch 44/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 108.2100 - ler: 0.7879 - val_loss: 108.1958 - val_ler: 0.7795\n",
      "\n",
      "Epoch 00044: ler did not improve from 0.78691\n",
      "Epoch 45/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 108.7820 - ler: 0.7823 - val_loss: 107.8320 - val_ler: 0.7758\n",
      "\n",
      "Epoch 00045: ler improved from 0.78691 to 0.78234, saving model to best_model_RNN.hdf5\n",
      "Epoch 46/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 108.1468 - ler: 0.7822 - val_loss: 107.8461 - val_ler: 0.7851\n",
      "\n",
      "Epoch 00046: ler improved from 0.78234 to 0.78219, saving model to best_model_RNN.hdf5\n",
      "Epoch 47/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 106.0917 - ler: 0.7784 - val_loss: 106.9781 - val_ler: 0.7815\n",
      "\n",
      "Epoch 00047: ler improved from 0.78219 to 0.77838, saving model to best_model_RNN.hdf5\n",
      "Epoch 48/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 103.5288 - ler: 0.7770 - val_loss: 105.9943 - val_ler: 0.7659\n",
      "\n",
      "Epoch 00048: ler improved from 0.77838 to 0.77703, saving model to best_model_RNN.hdf5\n",
      "Epoch 49/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 106.8036 - ler: 0.7729 - val_loss: 106.4950 - val_ler: 0.7795\n",
      "\n",
      "Epoch 00049: ler improved from 0.77703 to 0.77290, saving model to best_model_RNN.hdf5\n",
      "Epoch 50/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 106.8178 - ler: 0.7712 - val_loss: 105.7956 - val_ler: 0.7707\n",
      "\n",
      "Epoch 00050: ler improved from 0.77290 to 0.77125, saving model to best_model_RNN.hdf5\n",
      "Epoch 51/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 106.1838 - ler: 0.7698 - val_loss: 105.3824 - val_ler: 0.7681\n",
      "\n",
      "Epoch 00051: ler improved from 0.77125 to 0.76977, saving model to best_model_RNN.hdf5\n",
      "Epoch 52/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 106.0709 - ler: 0.7723 - val_loss: 104.2429 - val_ler: 0.7470\n",
      "\n",
      "Epoch 00052: ler did not improve from 0.76977\n",
      "Epoch 53/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 104.2398 - ler: 0.7620 - val_loss: 104.6057 - val_ler: 0.7663\n",
      "\n",
      "Epoch 00053: ler improved from 0.76977 to 0.76201, saving model to best_model_RNN.hdf5\n",
      "Epoch 54/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 105.5529 - ler: 0.7620 - val_loss: 102.8788 - val_ler: 0.7562\n",
      "\n",
      "Epoch 00054: ler improved from 0.76201 to 0.76197, saving model to best_model_RNN.hdf5\n",
      "Epoch 55/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 103.8895 - ler: 0.7575 - val_loss: 103.1045 - val_ler: 0.7594\n",
      "\n",
      "Epoch 00055: ler improved from 0.76197 to 0.75748, saving model to best_model_RNN.hdf5\n",
      "Epoch 56/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 104.9546 - ler: 0.7559 - val_loss: 102.4368 - val_ler: 0.7579\n",
      "\n",
      "Epoch 00056: ler improved from 0.75748 to 0.75589, saving model to best_model_RNN.hdf5\n",
      "Epoch 57/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 103.4940 - ler: 0.7524 - val_loss: 101.7693 - val_ler: 0.7580\n",
      "\n",
      "Epoch 00057: ler improved from 0.75589 to 0.75236, saving model to best_model_RNN.hdf5\n",
      "Epoch 58/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 99.9094 - ler: 0.7494 - val_loss: 101.1443 - val_ler: 0.7571\n",
      "\n",
      "Epoch 00058: ler improved from 0.75236 to 0.74936, saving model to best_model_RNN.hdf5\n",
      "Epoch 59/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 100.1739 - ler: 0.7505 - val_loss: 100.3298 - val_ler: 0.7418\n",
      "\n",
      "Epoch 00059: ler did not improve from 0.74936\n",
      "Epoch 60/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 98.5877 - ler: 0.7430 - val_loss: 101.0729 - val_ler: 0.7373\n",
      "\n",
      "Epoch 00060: ler improved from 0.74936 to 0.74298, saving model to best_model_RNN.hdf5\n",
      "Epoch 61/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 101.1759 - ler: 0.7394 - val_loss: 99.6551 - val_ler: 0.7438\n",
      "\n",
      "Epoch 00061: ler improved from 0.74298 to 0.73940, saving model to best_model_RNN.hdf5\n",
      "Epoch 62/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 98.9549 - ler: 0.7403 - val_loss: 99.3431 - val_ler: 0.7446\n",
      "\n",
      "Epoch 00062: ler did not improve from 0.73940\n",
      "Epoch 63/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 98.9681 - ler: 0.7347 - val_loss: 98.9815 - val_ler: 0.7491\n",
      "\n",
      "Epoch 00063: ler improved from 0.73940 to 0.73467, saving model to best_model_RNN.hdf5\n",
      "Epoch 64/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 97.3098 - ler: 0.7310 - val_loss: 98.3851 - val_ler: 0.7365\n",
      "\n",
      "Epoch 00064: ler improved from 0.73467 to 0.73099, saving model to best_model_RNN.hdf5\n",
      "Epoch 65/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 98.8459 - ler: 0.7347 - val_loss: 98.1686 - val_ler: 0.7320\n",
      "\n",
      "Epoch 00065: ler did not improve from 0.73099\n",
      "Epoch 66/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 97.9260 - ler: 0.7282 - val_loss: 97.4908 - val_ler: 0.7266\n",
      "\n",
      "Epoch 00066: ler improved from 0.73099 to 0.72823, saving model to best_model_RNN.hdf5\n",
      "Epoch 67/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 98.7467 - ler: 0.7258 - val_loss: 97.3697 - val_ler: 0.7242\n",
      "\n",
      "Epoch 00067: ler improved from 0.72823 to 0.72583, saving model to best_model_RNN.hdf5\n",
      "Epoch 68/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 97.4545 - ler: 0.7214 - val_loss: 95.7011 - val_ler: 0.7171\n",
      "\n",
      "Epoch 00068: ler improved from 0.72583 to 0.72140, saving model to best_model_RNN.hdf5\n",
      "Epoch 69/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 94.6069 - ler: 0.7187 - val_loss: 95.1722 - val_ler: 0.7178\n",
      "\n",
      "Epoch 00069: ler improved from 0.72140 to 0.71871, saving model to best_model_RNN.hdf5\n",
      "Epoch 70/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 94.4971 - ler: 0.7163 - val_loss: 94.8832 - val_ler: 0.7136\n",
      "\n",
      "Epoch 00070: ler improved from 0.71871 to 0.71630, saving model to best_model_RNN.hdf5\n",
      "Epoch 71/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 93.6869 - ler: 0.7107 - val_loss: 94.7848 - val_ler: 0.7086\n",
      "\n",
      "Epoch 00071: ler improved from 0.71630 to 0.71067, saving model to best_model_RNN.hdf5\n",
      "Epoch 72/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 95.6335 - ler: 0.7097 - val_loss: 93.6745 - val_ler: 0.7075\n",
      "\n",
      "Epoch 00072: ler improved from 0.71067 to 0.70974, saving model to best_model_RNN.hdf5\n",
      "Epoch 73/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 93.9674 - ler: 0.7080 - val_loss: 92.9847 - val_ler: 0.7059\n",
      "\n",
      "Epoch 00073: ler improved from 0.70974 to 0.70796, saving model to best_model_RNN.hdf5\n",
      "Epoch 74/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 91.2115 - ler: 0.7046 - val_loss: 92.7041 - val_ler: 0.7062\n",
      "\n",
      "Epoch 00074: ler improved from 0.70796 to 0.70459, saving model to best_model_RNN.hdf5\n",
      "Epoch 75/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 94.5932 - ler: 0.6988 - val_loss: 92.1095 - val_ler: 0.6877\n",
      "\n",
      "Epoch 00075: ler improved from 0.70459 to 0.69878, saving model to best_model_RNN.hdf5\n",
      "Epoch 76/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 90.4099 - ler: 0.6964 - val_loss: 93.6842 - val_ler: 0.7007\n",
      "\n",
      "Epoch 00076: ler improved from 0.69878 to 0.69636, saving model to best_model_RNN.hdf5\n",
      "Epoch 77/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 92.9220 - ler: 0.6996 - val_loss: 91.2942 - val_ler: 0.6912\n",
      "\n",
      "Epoch 00077: ler did not improve from 0.69636\n",
      "Epoch 78/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 92.8543 - ler: 0.6933 - val_loss: 90.6092 - val_ler: 0.6918\n",
      "\n",
      "Epoch 00078: ler improved from 0.69636 to 0.69334, saving model to best_model_RNN.hdf5\n",
      "Epoch 79/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 91.6455 - ler: 0.6914 - val_loss: 90.4622 - val_ler: 0.6766\n",
      "\n",
      "Epoch 00079: ler improved from 0.69334 to 0.69136, saving model to best_model_RNN.hdf5\n",
      "Epoch 80/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 91.6697 - ler: 0.6872 - val_loss: 90.2871 - val_ler: 0.6765\n",
      "\n",
      "Epoch 00080: ler improved from 0.69136 to 0.68715, saving model to best_model_RNN.hdf5\n",
      "Epoch 81/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 91.2088 - ler: 0.6866 - val_loss: 90.3180 - val_ler: 0.6958\n",
      "\n",
      "Epoch 00081: ler improved from 0.68715 to 0.68663, saving model to best_model_RNN.hdf5\n",
      "Epoch 82/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 90.1157 - ler: 0.6839 - val_loss: 89.3568 - val_ler: 0.6705\n",
      "\n",
      "Epoch 00082: ler improved from 0.68663 to 0.68392, saving model to best_model_RNN.hdf5\n",
      "Epoch 83/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 88.6640 - ler: 0.6785 - val_loss: 88.0130 - val_ler: 0.6734\n",
      "\n",
      "Epoch 00083: ler improved from 0.68392 to 0.67847, saving model to best_model_RNN.hdf5\n",
      "Epoch 84/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 85.4963 - ler: 0.6750 - val_loss: 87.7784 - val_ler: 0.6595\n",
      "\n",
      "Epoch 00084: ler improved from 0.67847 to 0.67496, saving model to best_model_RNN.hdf5\n",
      "Epoch 85/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 88.1104 - ler: 0.6720 - val_loss: 87.8546 - val_ler: 0.6687\n",
      "\n",
      "Epoch 00085: ler improved from 0.67496 to 0.67202, saving model to best_model_RNN.hdf5\n",
      "Epoch 86/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 89.3121 - ler: 0.6724 - val_loss: 86.6717 - val_ler: 0.6718\n",
      "\n",
      "Epoch 00086: ler did not improve from 0.67202\n",
      "Epoch 87/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 88.4171 - ler: 0.6681 - val_loss: 86.5765 - val_ler: 0.6597\n",
      "\n",
      "Epoch 00087: ler improved from 0.67202 to 0.66807, saving model to best_model_RNN.hdf5\n",
      "Epoch 88/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 87.0059 - ler: 0.6656 - val_loss: 85.6040 - val_ler: 0.6562\n",
      "\n",
      "Epoch 00088: ler improved from 0.66807 to 0.66557, saving model to best_model_RNN.hdf5\n",
      "Epoch 89/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 87.8703 - ler: 0.6642 - val_loss: 85.0719 - val_ler: 0.6514\n",
      "\n",
      "Epoch 00089: ler improved from 0.66557 to 0.66425, saving model to best_model_RNN.hdf5\n",
      "Epoch 90/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 84.1622 - ler: 0.6600 - val_loss: 85.1025 - val_ler: 0.6545\n",
      "\n",
      "Epoch 00090: ler improved from 0.66425 to 0.65996, saving model to best_model_RNN.hdf5\n",
      "Epoch 91/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 84.0704 - ler: 0.6556 - val_loss: 84.0815 - val_ler: 0.6542\n",
      "\n",
      "Epoch 00091: ler improved from 0.65996 to 0.65557, saving model to best_model_RNN.hdf5\n",
      "Epoch 92/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 83.6690 - ler: 0.6539 - val_loss: 83.3996 - val_ler: 0.6395\n",
      "\n",
      "Epoch 00092: ler improved from 0.65557 to 0.65389, saving model to best_model_RNN.hdf5\n",
      "Epoch 93/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 85.5522 - ler: 0.6506 - val_loss: 83.5977 - val_ler: 0.6388\n",
      "\n",
      "Epoch 00093: ler improved from 0.65389 to 0.65064, saving model to best_model_RNN.hdf5\n",
      "Epoch 94/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 86.7701 - ler: 0.6525 - val_loss: 86.0014 - val_ler: 0.6505\n",
      "\n",
      "Epoch 00094: ler did not improve from 0.65064\n",
      "Epoch 95/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 85.1543 - ler: 0.6526 - val_loss: 82.9357 - val_ler: 0.6428\n",
      "\n",
      "Epoch 00095: ler did not improve from 0.65064\n",
      "Epoch 96/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 85.1412 - ler: 0.6453 - val_loss: 81.6059 - val_ler: 0.6413\n",
      "\n",
      "Epoch 00096: ler improved from 0.65064 to 0.64527, saving model to best_model_RNN.hdf5\n",
      "Epoch 97/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 80.8761 - ler: 0.6405 - val_loss: 81.1266 - val_ler: 0.6271\n",
      "\n",
      "Epoch 00097: ler improved from 0.64527 to 0.64046, saving model to best_model_RNN.hdf5\n",
      "Epoch 98/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 81.5485 - ler: 0.6365 - val_loss: 81.2293 - val_ler: 0.6213\n",
      "\n",
      "Epoch 00098: ler improved from 0.64046 to 0.63646, saving model to best_model_RNN.hdf5\n",
      "Epoch 99/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 81.8366 - ler: 0.6319 - val_loss: 80.5714 - val_ler: 0.6373\n",
      "\n",
      "Epoch 00099: ler improved from 0.63646 to 0.63187, saving model to best_model_RNN.hdf5\n",
      "Epoch 100/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 80.5707 - ler: 0.6293 - val_loss: 80.0792 - val_ler: 0.6282\n",
      "\n",
      "Epoch 00100: ler improved from 0.63187 to 0.62926, saving model to best_model_RNN.hdf5\n",
      "Epoch 101/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 81.1639 - ler: 0.6307 - val_loss: 79.1648 - val_ler: 0.6108\n",
      "\n",
      "Epoch 00101: ler did not improve from 0.62926\n",
      "Epoch 102/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 79.6385 - ler: 0.6249 - val_loss: 80.6880 - val_ler: 0.6123\n",
      "\n",
      "Epoch 00102: ler improved from 0.62926 to 0.62487, saving model to best_model_RNN.hdf5\n",
      "Epoch 103/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 80.0380 - ler: 0.6219 - val_loss: 78.1947 - val_ler: 0.6118\n",
      "\n",
      "Epoch 00103: ler improved from 0.62487 to 0.62188, saving model to best_model_RNN.hdf5\n",
      "Epoch 104/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 79.6965 - ler: 0.6139 - val_loss: 77.6413 - val_ler: 0.6028\n",
      "\n",
      "Epoch 00104: ler improved from 0.62188 to 0.61385, saving model to best_model_RNN.hdf5\n",
      "Epoch 105/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 78.2603 - ler: 0.6174 - val_loss: 78.0709 - val_ler: 0.6249\n",
      "\n",
      "Epoch 00105: ler did not improve from 0.61385\n",
      "Epoch 106/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 78.0152 - ler: 0.6116 - val_loss: 78.1134 - val_ler: 0.6189\n",
      "\n",
      "Epoch 00106: ler improved from 0.61385 to 0.61156, saving model to best_model_RNN.hdf5\n",
      "Epoch 107/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 79.1604 - ler: 0.6089 - val_loss: 76.9650 - val_ler: 0.6065\n",
      "\n",
      "Epoch 00107: ler improved from 0.61156 to 0.60894, saving model to best_model_RNN.hdf5\n",
      "Epoch 108/250\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 80.1260 - ler: 0.6078 - val_loss: 77.9139 - val_ler: 0.6118\n",
      "\n",
      "Epoch 00108: ler improved from 0.60894 to 0.60781, saving model to best_model_RNN.hdf5\n",
      "Epoch 109/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 76.0088 - ler: 0.6062 - val_loss: 76.3430 - val_ler: 0.6083\n",
      "\n",
      "Epoch 00109: ler improved from 0.60781 to 0.60622, saving model to best_model_RNN.hdf5\n",
      "Epoch 110/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 75.1275 - ler: 0.6032 - val_loss: 75.0803 - val_ler: 0.5856\n",
      "\n",
      "Epoch 00110: ler improved from 0.60622 to 0.60324, saving model to best_model_RNN.hdf5\n",
      "Epoch 111/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 76.7554 - ler: 0.5964 - val_loss: 75.5939 - val_ler: 0.6004\n",
      "\n",
      "Epoch 00111: ler improved from 0.60324 to 0.59644, saving model to best_model_RNN.hdf5\n",
      "Epoch 112/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 76.8528 - ler: 0.5979 - val_loss: 74.1800 - val_ler: 0.5707\n",
      "\n",
      "Epoch 00112: ler did not improve from 0.59644\n",
      "Epoch 113/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 74.3115 - ler: 0.5875 - val_loss: 73.3289 - val_ler: 0.5795\n",
      "\n",
      "Epoch 00113: ler improved from 0.59644 to 0.58755, saving model to best_model_RNN.hdf5\n",
      "Epoch 114/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 73.6654 - ler: 0.5881 - val_loss: 73.1567 - val_ler: 0.5804\n",
      "\n",
      "Epoch 00114: ler did not improve from 0.58755\n",
      "Epoch 115/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 72.8752 - ler: 0.5859 - val_loss: 73.3425 - val_ler: 0.5722\n",
      "\n",
      "Epoch 00115: ler improved from 0.58755 to 0.58590, saving model to best_model_RNN.hdf5\n",
      "Epoch 116/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 72.8123 - ler: 0.5780 - val_loss: 72.0347 - val_ler: 0.5593\n",
      "\n",
      "Epoch 00116: ler improved from 0.58590 to 0.57797, saving model to best_model_RNN.hdf5\n",
      "Epoch 117/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 73.5755 - ler: 0.5746 - val_loss: 71.8183 - val_ler: 0.5775\n",
      "\n",
      "Epoch 00117: ler improved from 0.57797 to 0.57455, saving model to best_model_RNN.hdf5\n",
      "Epoch 118/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 74.1440 - ler: 0.5726 - val_loss: 70.9249 - val_ler: 0.5624\n",
      "\n",
      "Epoch 00118: ler improved from 0.57455 to 0.57261, saving model to best_model_RNN.hdf5\n",
      "Epoch 119/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 72.8394 - ler: 0.5707 - val_loss: 71.2338 - val_ler: 0.5598\n",
      "\n",
      "Epoch 00119: ler improved from 0.57261 to 0.57069, saving model to best_model_RNN.hdf5\n",
      "Epoch 120/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 70.3971 - ler: 0.5725 - val_loss: 70.0947 - val_ler: 0.5473\n",
      "\n",
      "Epoch 00120: ler did not improve from 0.57069\n",
      "Epoch 121/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 71.1920 - ler: 0.5636 - val_loss: 69.7230 - val_ler: 0.5501\n",
      "\n",
      "Epoch 00121: ler improved from 0.57069 to 0.56364, saving model to best_model_RNN.hdf5\n",
      "Epoch 122/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 72.4642 - ler: 0.5632 - val_loss: 69.3707 - val_ler: 0.5455\n",
      "\n",
      "Epoch 00122: ler improved from 0.56364 to 0.56318, saving model to best_model_RNN.hdf5\n",
      "Epoch 123/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 71.2514 - ler: 0.5598 - val_loss: 68.9813 - val_ler: 0.5462\n",
      "\n",
      "Epoch 00123: ler improved from 0.56318 to 0.55978, saving model to best_model_RNN.hdf5\n",
      "Epoch 124/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 69.7576 - ler: 0.5534 - val_loss: 68.2766 - val_ler: 0.5507\n",
      "\n",
      "Epoch 00124: ler improved from 0.55978 to 0.55340, saving model to best_model_RNN.hdf5\n",
      "Epoch 125/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 70.9629 - ler: 0.5531 - val_loss: 68.6052 - val_ler: 0.5476\n",
      "\n",
      "Epoch 00125: ler improved from 0.55340 to 0.55312, saving model to best_model_RNN.hdf5\n",
      "Epoch 126/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 69.8624 - ler: 0.5509 - val_loss: 67.6642 - val_ler: 0.5381\n",
      "\n",
      "Epoch 00126: ler improved from 0.55312 to 0.55087, saving model to best_model_RNN.hdf5\n",
      "Epoch 127/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 67.7511 - ler: 0.5505 - val_loss: 67.3316 - val_ler: 0.5337\n",
      "\n",
      "Epoch 00127: ler improved from 0.55087 to 0.55046, saving model to best_model_RNN.hdf5\n",
      "Epoch 128/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 68.1258 - ler: 0.5448 - val_loss: 67.5089 - val_ler: 0.5505\n",
      "\n",
      "Epoch 00128: ler improved from 0.55046 to 0.54481, saving model to best_model_RNN.hdf5\n",
      "Epoch 129/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 69.0825 - ler: 0.5404 - val_loss: 66.5879 - val_ler: 0.5250\n",
      "\n",
      "Epoch 00129: ler improved from 0.54481 to 0.54036, saving model to best_model_RNN.hdf5\n",
      "Epoch 130/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 68.9332 - ler: 0.5393 - val_loss: 65.5443 - val_ler: 0.5181\n",
      "\n",
      "Epoch 00130: ler improved from 0.54036 to 0.53928, saving model to best_model_RNN.hdf5\n",
      "Epoch 131/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 66.8321 - ler: 0.5288 - val_loss: 65.2415 - val_ler: 0.5302\n",
      "\n",
      "Epoch 00131: ler improved from 0.53928 to 0.52883, saving model to best_model_RNN.hdf5\n",
      "Epoch 132/250\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 65.7542 - ler: 0.5309 - val_loss: 66.5760 - val_ler: 0.5467\n",
      "\n",
      "Epoch 00132: ler did not improve from 0.52883\n",
      "Epoch 133/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 65.9775 - ler: 0.5302 - val_loss: 64.8437 - val_ler: 0.5163\n",
      "\n",
      "Epoch 00133: ler did not improve from 0.52883\n",
      "Epoch 134/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 65.8465 - ler: 0.5222 - val_loss: 64.9066 - val_ler: 0.5071\n",
      "\n",
      "Epoch 00134: ler improved from 0.52883 to 0.52224, saving model to best_model_RNN.hdf5\n",
      "Epoch 135/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 65.6128 - ler: 0.5208 - val_loss: 63.5851 - val_ler: 0.5066\n",
      "\n",
      "Epoch 00135: ler improved from 0.52224 to 0.52077, saving model to best_model_RNN.hdf5\n",
      "Epoch 136/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 64.7026 - ler: 0.5184 - val_loss: 63.6390 - val_ler: 0.5017\n",
      "\n",
      "Epoch 00136: ler improved from 0.52077 to 0.51842, saving model to best_model_RNN.hdf5\n",
      "Epoch 137/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 64.6549 - ler: 0.5149 - val_loss: 63.5726 - val_ler: 0.5014\n",
      "\n",
      "Epoch 00137: ler improved from 0.51842 to 0.51485, saving model to best_model_RNN.hdf5\n",
      "Epoch 138/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 64.1224 - ler: 0.5157 - val_loss: 63.0062 - val_ler: 0.5120\n",
      "\n",
      "Epoch 00138: ler did not improve from 0.51485\n",
      "Epoch 139/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 64.9941 - ler: 0.5066 - val_loss: 63.6489 - val_ler: 0.5150\n",
      "\n",
      "Epoch 00139: ler improved from 0.51485 to 0.50662, saving model to best_model_RNN.hdf5\n",
      "Epoch 140/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 63.5116 - ler: 0.5117 - val_loss: 62.0508 - val_ler: 0.4990\n",
      "\n",
      "Epoch 00140: ler did not improve from 0.50662\n",
      "Epoch 141/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 62.9679 - ler: 0.5050 - val_loss: 62.1675 - val_ler: 0.5062\n",
      "\n",
      "Epoch 00141: ler improved from 0.50662 to 0.50499, saving model to best_model_RNN.hdf5\n",
      "Epoch 142/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 63.2226 - ler: 0.5047 - val_loss: 59.9576 - val_ler: 0.4863\n",
      "\n",
      "Epoch 00142: ler improved from 0.50499 to 0.50473, saving model to best_model_RNN.hdf5\n",
      "Epoch 143/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 60.8028 - ler: 0.4952 - val_loss: 59.9321 - val_ler: 0.4850\n",
      "\n",
      "Epoch 00143: ler improved from 0.50473 to 0.49517, saving model to best_model_RNN.hdf5\n",
      "Epoch 144/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 62.7348 - ler: 0.4915 - val_loss: 59.7427 - val_ler: 0.4726\n",
      "\n",
      "Epoch 00144: ler improved from 0.49517 to 0.49149, saving model to best_model_RNN.hdf5\n",
      "Epoch 145/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 60.9027 - ler: 0.4909 - val_loss: 59.3232 - val_ler: 0.4755\n",
      "\n",
      "Epoch 00145: ler improved from 0.49149 to 0.49087, saving model to best_model_RNN.hdf5\n",
      "Epoch 146/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 60.6941 - ler: 0.4893 - val_loss: 58.8972 - val_ler: 0.4629\n",
      "\n",
      "Epoch 00146: ler improved from 0.49087 to 0.48932, saving model to best_model_RNN.hdf5\n",
      "Epoch 147/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 59.2734 - ler: 0.4844 - val_loss: 58.8007 - val_ler: 0.4788\n",
      "\n",
      "Epoch 00147: ler improved from 0.48932 to 0.48437, saving model to best_model_RNN.hdf5\n",
      "Epoch 148/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 60.1477 - ler: 0.4953 - val_loss: 58.4908 - val_ler: 0.4677\n",
      "\n",
      "Epoch 00148: ler did not improve from 0.48437\n",
      "Epoch 149/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 59.7100 - ler: 0.4793 - val_loss: 57.5616 - val_ler: 0.4725\n",
      "\n",
      "Epoch 00149: ler improved from 0.48437 to 0.47928, saving model to best_model_RNN.hdf5\n",
      "Epoch 150/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 59.6962 - ler: 0.4743 - val_loss: 58.0105 - val_ler: 0.4586\n",
      "\n",
      "Epoch 00150: ler improved from 0.47928 to 0.47431, saving model to best_model_RNN.hdf5\n",
      "Epoch 151/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 58.8356 - ler: 0.4781 - val_loss: 56.9777 - val_ler: 0.4572\n",
      "\n",
      "Epoch 00151: ler did not improve from 0.47431\n",
      "Epoch 152/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 59.5176 - ler: 0.4693 - val_loss: 57.7781 - val_ler: 0.4763\n",
      "\n",
      "Epoch 00152: ler improved from 0.47431 to 0.46930, saving model to best_model_RNN.hdf5\n",
      "Epoch 153/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 59.0451 - ler: 0.4735 - val_loss: 57.6302 - val_ler: 0.4724\n",
      "\n",
      "Epoch 00153: ler did not improve from 0.46930\n",
      "Epoch 154/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 60.0087 - ler: 0.4752 - val_loss: 56.9069 - val_ler: 0.4509\n",
      "\n",
      "Epoch 00154: ler did not improve from 0.46930\n",
      "Epoch 155/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 59.1973 - ler: 0.4728 - val_loss: 60.2838 - val_ler: 0.4824\n",
      "\n",
      "Epoch 00155: ler did not improve from 0.46930\n",
      "Epoch 156/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 61.5091 - ler: 0.4794 - val_loss: 56.7156 - val_ler: 0.4615\n",
      "\n",
      "Epoch 00156: ler did not improve from 0.46930\n",
      "Epoch 157/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 56.9851 - ler: 0.4688 - val_loss: 55.5906 - val_ler: 0.4427\n",
      "\n",
      "Epoch 00157: ler improved from 0.46930 to 0.46878, saving model to best_model_RNN.hdf5\n",
      "Epoch 158/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 57.7016 - ler: 0.4604 - val_loss: 56.1162 - val_ler: 0.4416\n",
      "\n",
      "Epoch 00158: ler improved from 0.46878 to 0.46037, saving model to best_model_RNN.hdf5\n",
      "Epoch 159/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 58.2117 - ler: 0.4580 - val_loss: 55.4973 - val_ler: 0.4448\n",
      "\n",
      "Epoch 00159: ler improved from 0.46037 to 0.45798, saving model to best_model_RNN.hdf5\n",
      "Epoch 160/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 56.6516 - ler: 0.4541 - val_loss: 54.6515 - val_ler: 0.4302\n",
      "\n",
      "Epoch 00160: ler improved from 0.45798 to 0.45410, saving model to best_model_RNN.hdf5\n",
      "Epoch 161/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 58.1411 - ler: 0.4571 - val_loss: 53.9597 - val_ler: 0.4445\n",
      "\n",
      "Epoch 00161: ler did not improve from 0.45410\n",
      "Epoch 162/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 54.6857 - ler: 0.4515 - val_loss: 53.5913 - val_ler: 0.4261\n",
      "\n",
      "Epoch 00162: ler improved from 0.45410 to 0.45154, saving model to best_model_RNN.hdf5\n",
      "Epoch 163/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 54.1451 - ler: 0.4456 - val_loss: 53.4224 - val_ler: 0.4302\n",
      "\n",
      "Epoch 00163: ler improved from 0.45154 to 0.44560, saving model to best_model_RNN.hdf5\n",
      "Epoch 164/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 54.9425 - ler: 0.4437 - val_loss: 53.5996 - val_ler: 0.4220\n",
      "\n",
      "Epoch 00164: ler improved from 0.44560 to 0.44368, saving model to best_model_RNN.hdf5\n",
      "Epoch 165/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 53.8607 - ler: 0.4411 - val_loss: 52.1953 - val_ler: 0.4328\n",
      "\n",
      "Epoch 00165: ler improved from 0.44368 to 0.44109, saving model to best_model_RNN.hdf5\n",
      "Epoch 166/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 53.9957 - ler: 0.4381 - val_loss: 51.9282 - val_ler: 0.4125\n",
      "\n",
      "Epoch 00166: ler improved from 0.44109 to 0.43809, saving model to best_model_RNN.hdf5\n",
      "Epoch 167/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 50.8530 - ler: 0.4297 - val_loss: 52.2349 - val_ler: 0.4159\n",
      "\n",
      "Epoch 00167: ler improved from 0.43809 to 0.42973, saving model to best_model_RNN.hdf5\n",
      "Epoch 168/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 51.2921 - ler: 0.4258 - val_loss: 50.7325 - val_ler: 0.4106\n",
      "\n",
      "Epoch 00168: ler improved from 0.42973 to 0.42584, saving model to best_model_RNN.hdf5\n",
      "Epoch 169/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 53.3598 - ler: 0.4254 - val_loss: 50.4649 - val_ler: 0.4135\n",
      "\n",
      "Epoch 00169: ler improved from 0.42584 to 0.42537, saving model to best_model_RNN.hdf5\n",
      "Epoch 170/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 51.5573 - ler: 0.4237 - val_loss: 50.2392 - val_ler: 0.4071\n",
      "\n",
      "Epoch 00170: ler improved from 0.42537 to 0.42373, saving model to best_model_RNN.hdf5\n",
      "Epoch 171/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 51.4234 - ler: 0.4233 - val_loss: 50.1106 - val_ler: 0.4043\n",
      "\n",
      "Epoch 00171: ler improved from 0.42373 to 0.42330, saving model to best_model_RNN.hdf5\n",
      "Epoch 172/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 51.8801 - ler: 0.4188 - val_loss: 49.6768 - val_ler: 0.3963\n",
      "\n",
      "Epoch 00172: ler improved from 0.42330 to 0.41876, saving model to best_model_RNN.hdf5\n",
      "Epoch 173/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 50.5566 - ler: 0.4126 - val_loss: 49.7784 - val_ler: 0.4120\n",
      "\n",
      "Epoch 00173: ler improved from 0.41876 to 0.41257, saving model to best_model_RNN.hdf5\n",
      "Epoch 174/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 49.9405 - ler: 0.4166 - val_loss: 49.4838 - val_ler: 0.3991\n",
      "\n",
      "Epoch 00174: ler did not improve from 0.41257\n",
      "Epoch 175/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 51.3915 - ler: 0.4173 - val_loss: 49.5636 - val_ler: 0.4003\n",
      "\n",
      "Epoch 00175: ler did not improve from 0.41257\n",
      "Epoch 176/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 51.0979 - ler: 0.4087 - val_loss: 48.0918 - val_ler: 0.3850\n",
      "\n",
      "Epoch 00176: ler improved from 0.41257 to 0.40869, saving model to best_model_RNN.hdf5\n",
      "Epoch 177/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 50.1842 - ler: 0.4018 - val_loss: 48.2254 - val_ler: 0.3835\n",
      "\n",
      "Epoch 00177: ler improved from 0.40869 to 0.40183, saving model to best_model_RNN.hdf5\n",
      "Epoch 178/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 50.0829 - ler: 0.4100 - val_loss: 48.6934 - val_ler: 0.3987\n",
      "\n",
      "Epoch 00178: ler did not improve from 0.40183\n",
      "Epoch 179/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 50.1481 - ler: 0.4034 - val_loss: 47.5687 - val_ler: 0.3810\n",
      "\n",
      "Epoch 00179: ler did not improve from 0.40183\n",
      "Epoch 180/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 47.9564 - ler: 0.3995 - val_loss: 47.4297 - val_ler: 0.3895\n",
      "\n",
      "Epoch 00180: ler improved from 0.40183 to 0.39946, saving model to best_model_RNN.hdf5\n",
      "Epoch 181/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 49.8105 - ler: 0.3917 - val_loss: 48.3141 - val_ler: 0.3947\n",
      "\n",
      "Epoch 00181: ler improved from 0.39946 to 0.39173, saving model to best_model_RNN.hdf5\n",
      "Epoch 182/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 50.1807 - ler: 0.4024 - val_loss: 46.8244 - val_ler: 0.3886\n",
      "\n",
      "Epoch 00182: ler did not improve from 0.39173\n",
      "Epoch 183/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 48.1124 - ler: 0.3858 - val_loss: 45.4905 - val_ler: 0.3701\n",
      "\n",
      "Epoch 00183: ler improved from 0.39173 to 0.38579, saving model to best_model_RNN.hdf5\n",
      "Epoch 184/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 48.3760 - ler: 0.3857 - val_loss: 46.0914 - val_ler: 0.3663\n",
      "\n",
      "Epoch 00184: ler improved from 0.38579 to 0.38566, saving model to best_model_RNN.hdf5\n",
      "Epoch 185/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 46.5499 - ler: 0.3849 - val_loss: 44.8352 - val_ler: 0.3654\n",
      "\n",
      "Epoch 00185: ler improved from 0.38566 to 0.38489, saving model to best_model_RNN.hdf5\n",
      "Epoch 186/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 46.4057 - ler: 0.3803 - val_loss: 45.6298 - val_ler: 0.3680\n",
      "\n",
      "Epoch 00186: ler improved from 0.38489 to 0.38026, saving model to best_model_RNN.hdf5\n",
      "Epoch 187/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 47.4622 - ler: 0.3841 - val_loss: 45.6418 - val_ler: 0.3626\n",
      "\n",
      "Epoch 00187: ler did not improve from 0.38026\n",
      "Epoch 188/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 47.3039 - ler: 0.3790 - val_loss: 45.0759 - val_ler: 0.3666\n",
      "\n",
      "Epoch 00188: ler improved from 0.38026 to 0.37902, saving model to best_model_RNN.hdf5\n",
      "Epoch 189/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 46.6557 - ler: 0.3749 - val_loss: 44.2716 - val_ler: 0.3492\n",
      "\n",
      "Epoch 00189: ler improved from 0.37902 to 0.37494, saving model to best_model_RNN.hdf5\n",
      "Epoch 190/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 45.6800 - ler: 0.3735 - val_loss: 44.4276 - val_ler: 0.3638\n",
      "\n",
      "Epoch 00190: ler improved from 0.37494 to 0.37349, saving model to best_model_RNN.hdf5\n",
      "Epoch 191/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 46.9785 - ler: 0.3757 - val_loss: 44.0281 - val_ler: 0.3574\n",
      "\n",
      "Epoch 00191: ler did not improve from 0.37349\n",
      "Epoch 192/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 44.8165 - ler: 0.3695 - val_loss: 43.6058 - val_ler: 0.3484\n",
      "\n",
      "Epoch 00192: ler improved from 0.37349 to 0.36951, saving model to best_model_RNN.hdf5\n",
      "Epoch 193/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 45.9973 - ler: 0.3684 - val_loss: 43.9217 - val_ler: 0.3604\n",
      "\n",
      "Epoch 00193: ler improved from 0.36951 to 0.36843, saving model to best_model_RNN.hdf5\n",
      "Epoch 194/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 46.9739 - ler: 0.3845 - val_loss: 46.0500 - val_ler: 0.3661\n",
      "\n",
      "Epoch 00194: ler did not improve from 0.36843\n",
      "Epoch 195/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 45.9026 - ler: 0.3770 - val_loss: 43.8038 - val_ler: 0.3464\n",
      "\n",
      "Epoch 00195: ler did not improve from 0.36843\n",
      "Epoch 196/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 46.3644 - ler: 0.3650 - val_loss: 42.6921 - val_ler: 0.3396\n",
      "\n",
      "Epoch 00196: ler improved from 0.36843 to 0.36498, saving model to best_model_RNN.hdf5\n",
      "Epoch 197/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 43.2116 - ler: 0.3604 - val_loss: 43.3625 - val_ler: 0.3472\n",
      "\n",
      "Epoch 00197: ler improved from 0.36498 to 0.36037, saving model to best_model_RNN.hdf5\n",
      "Epoch 198/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 46.0421 - ler: 0.3705 - val_loss: 45.6721 - val_ler: 0.3810\n",
      "\n",
      "Epoch 00198: ler did not improve from 0.36037\n",
      "Epoch 199/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 46.6560 - ler: 0.3765 - val_loss: 43.2401 - val_ler: 0.3442\n",
      "\n",
      "Epoch 00199: ler did not improve from 0.36037\n",
      "Epoch 200/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 44.5092 - ler: 0.3631 - val_loss: 41.5160 - val_ler: 0.3354\n",
      "\n",
      "Epoch 00200: ler did not improve from 0.36037\n",
      "Epoch 201/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 43.0540 - ler: 0.3441 - val_loss: 41.1023 - val_ler: 0.3273\n",
      "\n",
      "Epoch 00201: ler improved from 0.36037 to 0.34414, saving model to best_model_RNN.hdf5\n",
      "Epoch 202/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 42.2026 - ler: 0.3436 - val_loss: 40.3044 - val_ler: 0.3213\n",
      "\n",
      "Epoch 00202: ler improved from 0.34414 to 0.34361, saving model to best_model_RNN.hdf5\n",
      "Epoch 203/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 42.3593 - ler: 0.3415 - val_loss: 40.0811 - val_ler: 0.3192\n",
      "\n",
      "Epoch 00203: ler improved from 0.34361 to 0.34153, saving model to best_model_RNN.hdf5\n",
      "Epoch 204/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 42.4925 - ler: 0.3469 - val_loss: 40.3946 - val_ler: 0.3202\n",
      "\n",
      "Epoch 00204: ler did not improve from 0.34153\n",
      "Epoch 205/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 41.6791 - ler: 0.3339 - val_loss: 39.9970 - val_ler: 0.3123\n",
      "\n",
      "Epoch 00205: ler improved from 0.34153 to 0.33390, saving model to best_model_RNN.hdf5\n",
      "Epoch 206/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 41.9885 - ler: 0.3338 - val_loss: 39.1750 - val_ler: 0.3119\n",
      "\n",
      "Epoch 00206: ler improved from 0.33390 to 0.33377, saving model to best_model_RNN.hdf5\n",
      "Epoch 207/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 40.8202 - ler: 0.3401 - val_loss: 39.8542 - val_ler: 0.3165\n",
      "\n",
      "Epoch 00207: ler did not improve from 0.33377\n",
      "Epoch 208/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 43.5936 - ler: 0.3464 - val_loss: 40.4150 - val_ler: 0.3261\n",
      "\n",
      "Epoch 00208: ler did not improve from 0.33377\n",
      "Epoch 209/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 40.7669 - ler: 0.3427 - val_loss: 40.1480 - val_ler: 0.3184\n",
      "\n",
      "Epoch 00209: ler did not improve from 0.33377\n",
      "Epoch 210/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 40.9513 - ler: 0.3318 - val_loss: 39.0189 - val_ler: 0.3088\n",
      "\n",
      "Epoch 00210: ler improved from 0.33377 to 0.33181, saving model to best_model_RNN.hdf5\n",
      "Epoch 211/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 39.7133 - ler: 0.3270 - val_loss: 39.0912 - val_ler: 0.3065\n",
      "\n",
      "Epoch 00211: ler improved from 0.33181 to 0.32705, saving model to best_model_RNN.hdf5\n",
      "Epoch 212/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 39.2290 - ler: 0.3271 - val_loss: 38.4898 - val_ler: 0.3008\n",
      "\n",
      "Epoch 00212: ler did not improve from 0.32705\n",
      "Epoch 213/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 39.6800 - ler: 0.3164 - val_loss: 37.4473 - val_ler: 0.2971\n",
      "\n",
      "Epoch 00213: ler improved from 0.32705 to 0.31640, saving model to best_model_RNN.hdf5\n",
      "Epoch 214/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 40.6652 - ler: 0.3156 - val_loss: 37.5806 - val_ler: 0.2880\n",
      "\n",
      "Epoch 00214: ler improved from 0.31640 to 0.31556, saving model to best_model_RNN.hdf5\n",
      "Epoch 215/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 37.8679 - ler: 0.3113 - val_loss: 36.7535 - val_ler: 0.2895\n",
      "\n",
      "Epoch 00215: ler improved from 0.31556 to 0.31130, saving model to best_model_RNN.hdf5\n",
      "Epoch 216/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 37.7322 - ler: 0.3119 - val_loss: 37.0067 - val_ler: 0.2889\n",
      "\n",
      "Epoch 00216: ler did not improve from 0.31130\n",
      "Epoch 217/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 39.1680 - ler: 0.3120 - val_loss: 36.4595 - val_ler: 0.2860\n",
      "\n",
      "Epoch 00217: ler did not improve from 0.31130\n",
      "Epoch 218/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 41.3270 - ler: 0.3165 - val_loss: 37.1559 - val_ler: 0.2905\n",
      "\n",
      "Epoch 00218: ler did not improve from 0.31130\n",
      "Epoch 219/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 37.5013 - ler: 0.3120 - val_loss: 37.5275 - val_ler: 0.2971\n",
      "\n",
      "Epoch 00219: ler did not improve from 0.31130\n",
      "Epoch 220/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 37.8542 - ler: 0.3111 - val_loss: 36.4567 - val_ler: 0.2909\n",
      "\n",
      "Epoch 00220: ler improved from 0.31130 to 0.31110, saving model to best_model_RNN.hdf5\n",
      "Epoch 221/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 40.1565 - ler: 0.3101 - val_loss: 35.8070 - val_ler: 0.2794\n",
      "\n",
      "Epoch 00221: ler improved from 0.31110 to 0.31006, saving model to best_model_RNN.hdf5\n",
      "Epoch 222/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 37.6754 - ler: 0.2986 - val_loss: 35.7664 - val_ler: 0.2775\n",
      "\n",
      "Epoch 00222: ler improved from 0.31006 to 0.29862, saving model to best_model_RNN.hdf5\n",
      "Epoch 223/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 38.0643 - ler: 0.3066 - val_loss: 36.4829 - val_ler: 0.2813\n",
      "\n",
      "Epoch 00223: ler did not improve from 0.29862\n",
      "Epoch 224/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 38.2959 - ler: 0.2999 - val_loss: 35.4873 - val_ler: 0.2812\n",
      "\n",
      "Epoch 00224: ler did not improve from 0.29862\n",
      "Epoch 225/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 35.9315 - ler: 0.2957 - val_loss: 35.1637 - val_ler: 0.2743\n",
      "\n",
      "Epoch 00225: ler improved from 0.29862 to 0.29569, saving model to best_model_RNN.hdf5\n",
      "Epoch 226/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 37.4181 - ler: 0.3038 - val_loss: 35.4240 - val_ler: 0.2898\n",
      "\n",
      "Epoch 00226: ler did not improve from 0.29569\n",
      "Epoch 227/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 37.5421 - ler: 0.3022 - val_loss: 35.5211 - val_ler: 0.2739\n",
      "\n",
      "Epoch 00227: ler did not improve from 0.29569\n",
      "Epoch 228/250\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 37.7862 - ler: 0.2940 - val_loss: 34.8568 - val_ler: 0.2732\n",
      "\n",
      "Epoch 00228: ler improved from 0.29569 to 0.29403, saving model to best_model_RNN.hdf5\n",
      "Epoch 229/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 35.9729 - ler: 0.2982 - val_loss: 34.7240 - val_ler: 0.2725\n",
      "\n",
      "Epoch 00229: ler did not improve from 0.29403\n",
      "Epoch 230/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 36.9202 - ler: 0.2946 - val_loss: 34.2406 - val_ler: 0.2780\n",
      "\n",
      "Epoch 00230: ler did not improve from 0.29403\n",
      "Epoch 231/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 35.1796 - ler: 0.2873 - val_loss: 34.2921 - val_ler: 0.2667\n",
      "\n",
      "Epoch 00231: ler improved from 0.29403 to 0.28734, saving model to best_model_RNN.hdf5\n",
      "Epoch 232/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 34.4775 - ler: 0.2802 - val_loss: 33.4626 - val_ler: 0.2591\n",
      "\n",
      "Epoch 00232: ler improved from 0.28734 to 0.28023, saving model to best_model_RNN.hdf5\n",
      "Epoch 233/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 35.2688 - ler: 0.2791 - val_loss: 34.1878 - val_ler: 0.2763\n",
      "\n",
      "Epoch 00233: ler improved from 0.28023 to 0.27914, saving model to best_model_RNN.hdf5\n",
      "Epoch 234/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 35.6453 - ler: 0.2782 - val_loss: 33.5632 - val_ler: 0.2572\n",
      "\n",
      "Epoch 00234: ler improved from 0.27914 to 0.27818, saving model to best_model_RNN.hdf5\n",
      "Epoch 235/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 35.1100 - ler: 0.2807 - val_loss: 33.1050 - val_ler: 0.2546\n",
      "\n",
      "Epoch 00235: ler did not improve from 0.27818\n",
      "Epoch 236/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 34.1215 - ler: 0.2767 - val_loss: 34.3927 - val_ler: 0.2799\n",
      "\n",
      "Epoch 00236: ler improved from 0.27818 to 0.27665, saving model to best_model_RNN.hdf5\n",
      "Epoch 237/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 34.7206 - ler: 0.2724 - val_loss: 32.1774 - val_ler: 0.2509\n",
      "\n",
      "Epoch 00237: ler improved from 0.27665 to 0.27242, saving model to best_model_RNN.hdf5\n",
      "Epoch 238/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 33.9511 - ler: 0.2702 - val_loss: 32.4008 - val_ler: 0.2618\n",
      "\n",
      "Epoch 00238: ler improved from 0.27242 to 0.27018, saving model to best_model_RNN.hdf5\n",
      "Epoch 239/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 33.3547 - ler: 0.2685 - val_loss: 33.1850 - val_ler: 0.2642\n",
      "\n",
      "Epoch 00239: ler improved from 0.27018 to 0.26845, saving model to best_model_RNN.hdf5\n",
      "Epoch 240/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 33.3846 - ler: 0.2793 - val_loss: 32.8529 - val_ler: 0.2671\n",
      "\n",
      "Epoch 00240: ler did not improve from 0.26845\n",
      "Epoch 241/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 34.3177 - ler: 0.2753 - val_loss: 32.1299 - val_ler: 0.2533\n",
      "\n",
      "Epoch 00241: ler did not improve from 0.26845\n",
      "Epoch 242/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 32.5868 - ler: 0.2765 - val_loss: 33.2723 - val_ler: 0.2542\n",
      "\n",
      "Epoch 00242: ler did not improve from 0.26845\n",
      "Epoch 243/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 34.7723 - ler: 0.2792 - val_loss: 32.1442 - val_ler: 0.2553\n",
      "\n",
      "Epoch 00243: ler did not improve from 0.26845\n",
      "Epoch 244/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 36.3579 - ler: 0.2946 - val_loss: 33.2523 - val_ler: 0.2618\n",
      "\n",
      "Epoch 00244: ler did not improve from 0.26845\n",
      "Epoch 245/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 34.9740 - ler: 0.2793 - val_loss: 31.5716 - val_ler: 0.2434\n",
      "\n",
      "Epoch 00245: ler did not improve from 0.26845\n",
      "Epoch 246/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 34.2440 - ler: 0.2691 - val_loss: 31.8797 - val_ler: 0.2453\n",
      "\n",
      "Epoch 00246: ler did not improve from 0.26845\n",
      "Epoch 247/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 33.9855 - ler: 0.2733 - val_loss: 32.6149 - val_ler: 0.2567\n",
      "\n",
      "Epoch 00247: ler did not improve from 0.26845\n",
      "Epoch 248/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 34.5691 - ler: 0.2751 - val_loss: 31.8854 - val_ler: 0.2530\n",
      "\n",
      "Epoch 00248: ler did not improve from 0.26845\n",
      "Epoch 249/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 34.2545 - ler: 0.2824 - val_loss: 33.5784 - val_ler: 0.2719\n",
      "\n",
      "Epoch 00249: ler did not improve from 0.26845\n",
      "Epoch 250/250\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 34.0670 - ler: 0.2745 - val_loss: 31.5025 - val_ler: 0.2497\n",
      "\n",
      "Epoch 00250: ler did not improve from 0.26845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f76c00a5190>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile Training Model with selected optimizer\n",
    "optimizer = tf.keras.optimizers.SGD(initial_learning_rate, momentum)\n",
    "model_train.compile(optimizer=optimizer)\n",
    "\n",
    "checkpointer = ModelCheckpoint('best_model_RNN.hdf5',monitor='ler',verbose=1, save_best_only=True, mode='min')\n",
    "# ModelCheckpoint(filepath='../models/'+\"RNN\"+'.h5', verbose=0,)\n",
    "\n",
    "# Training, Our y is already defined so no need# mlflow.tensorflow.autolog()\n",
    "history = model_train.fit(x=[train_inputs, train_targets, train_seq_len, train_targets_len], y=None,\n",
    "                validation_data=([val_inputs, val_targets, val_seq_len, val_targets_len], None),\n",
    "                batch_size=batch_size, epochs=300,callbacks=[checkpointer])\n",
    "\n",
    "# try:\n",
    "#     experiment_id = mlflow.create_experiment(\"Stacked RNN(LSTM): 50 Cells\")\n",
    "#     experiment = mlflow.get_experiment(experiment_id)\n",
    "# except mlflow.exceptions.MlflowException:\n",
    "#     experiment = mlflow.get_experiment_by_name(\"Stacked RNN(LSTM): 50 Cells\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3297fc44-8655-439d-8442-87b8905793fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d2819bd-fbb4-43ee-8f1e-5bf82b0f89c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "     \n",
      "    \n",
      "        \n",
      "        \n",
      "Decoded:\n",
      "     \n",
      "   \n",
      "        \n",
      "       \n",
      "                \n",
      "          \n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "# Decoding\n",
    "print('Original:')\n",
    "print(original_list[0])\n",
    "print(original_list[1])\n",
    "print(original_list[2])\n",
    "print(original_list[3])\n",
    "print('Decoded:')\n",
    "\n",
    "\n",
    "train_inputs = tf.ragged.constant([i for i in inputs_list[:6]], dtype=np.float32)\n",
    "train_seq_len = tf.cast(train_inputs.row_lengths(), tf.int32)\n",
    "train_inputs = train_inputs.to_tensor(default_value=FEAT_MASK_VALUE)\n",
    "\n",
    "decoded, _ = tf.nn.ctc_greedy_decoder(tf.transpose(\n",
    "    model_predict.predict(train_inputs), (1, 0, 2)), train_seq_len)\n",
    "\n",
    "d = tf.sparse.to_dense(decoded[0], default_value=-1).numpy()\n",
    "str_decoded = [''.join([alphabets['num_to_char'][str(x)]\n",
    "                       for x in np.asarray(row) if x != -1]) for row in d]\n",
    "\n",
    "# print('decoded',str_decoded)\n",
    "for s in str_decoded:\n",
    "    # Replacing blank label to none\n",
    "    # s = s.replace(chr(ord('z') + 1), '')\n",
    "    # Replacing space label to space\n",
    "    s = s.replace(alphabets['num_to_char']['0'], ' ')\n",
    "    print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382d422e-0f52-4970-a7f3-d5a2aabe639a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
