{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65ba901e-04fd-4370-8349-5922a37763aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy.io.wavfile as wav\n",
    "import glob\n",
    "import numpy as np\n",
    "from six.moves import xrange as range\n",
    "import json\n",
    "from python_speech_features import mfcc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import (BatchNormalization, Conv1D, Dense, Input, \n",
    "    TimeDistributed, Activation, Bidirectional, SimpleRNN, GRU, LSTM)\n",
    "# from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import (Input, Lambda)\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint  \n",
    "import librosa \n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "import gc\n",
    "\n",
    "# import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27c17201-9ec8-4e7d-a59c-07d80a01a0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants \n",
    "SPACE_TOKEN = '<space>'\n",
    "SPACE_INDEX = 0\n",
    "FIRST_INDEX = 1\n",
    "FEAT_MASK_VALUE = 1e+10\n",
    "\n",
    "# Some configs\n",
    "# filters=200\n",
    "# kernel_size=11\n",
    "# conv_stride=2\n",
    "# conv_border_mode='valid'\n",
    "units=200\n",
    "num_features = 13\n",
    "num_units = 100\n",
    "num_classes = 222 + 1 # 285(including space) + blamk label = 286\n",
    "\n",
    "# Hyper-parameters\n",
    "num_epochs = 100\n",
    "num_layers = 1\n",
    "batch_size = 16\n",
    "initial_learning_rate = 0.0005\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe58f0c6-de98-40b6-ab43-3dd420eefc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "file_path = glob.glob('/home/dibora_gebreyohannes/AMH-STT/data/train/wav/*.wav')\n",
    "# file_path = file_path[28:32]\n",
    "audio_list = []\n",
    "fs_list = []\n",
    "dur_list = []\n",
    "dropped_file_path = []\n",
    "\n",
    "for file_name in file_path:\n",
    "    audio,fs = librosa.load(file_name,sr=16000)\n",
    "    dur = librosa.get_duration(audio,sr=16000)\n",
    "    if dur > 2 and dur < 6:\n",
    "        dropped_file_path.append(file_name)\n",
    "        audio_list.append(audio)\n",
    "        dur_list.append(dur)\n",
    "        fs_list.append(fs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53ef3f13-0679-4128-a785-46f813715e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "724"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(audio_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cdb52b7-cf76-4083-bbd3-288ad8cc3f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset composed of data with variable lengths\n",
    "inputs_list = []\n",
    "for index in range(len(audio_list)):\n",
    "    input_val = mfcc(audio_list[index], samplerate=fs_list[index])\n",
    "    input_val = (input_val - np.mean(input_val)) / np.std(input_val)\n",
    "    inputs_list.append(input_val)\n",
    "\n",
    "# Transform in 3D Array\n",
    "train_inputs = tf.ragged.constant([i for i in inputs_list], dtype=np.float32)\n",
    "train_seq_len = tf.cast(train_inputs.row_lengths(), tf.int32)\n",
    "train_inputs = train_inputs.to_tensor(default_value=FEAT_MASK_VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c773b459-59ae-44c1-8136-a366baa4bca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('labels.json', 'r', encoding='UTF-8') as label_file:\n",
    "    labels = json.load(label_file)\n",
    "with open('language_model.json', 'r', encoding='UTF-8') as language_file:\n",
    "    alphabets = json.load(language_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6866b469-9e4b-425e-817f-fc5b2a3f25bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Targets\n",
    "original_list = []\n",
    "targets_list = []\n",
    "\n",
    "for path in dropped_file_path:\n",
    "    file_name = path[:-4].split('wav')[1][1:]\n",
    "    # Read Label\n",
    "    label = labels[file_name]\n",
    "    original = \" \".join(label.strip().split(' '))\n",
    "    original_list.append(original)\n",
    "#     print(original)\n",
    "    target = original.replace(' ', '  ')\n",
    "    # print('step-1. ',target)\n",
    "    target = target.split(' ')\n",
    "    # print('step-2. ', target)\n",
    "    # Adding blank label\n",
    "    target = np.hstack([SPACE_TOKEN if x == '' else list(x) for x in target])\n",
    "    # print('step-3. ', target)\n",
    "    # Transform char into index\n",
    "    target = np.asarray([alphabets['char_to_num'][x] for x in target])\n",
    "    # print('step-4. ', target)\n",
    "    targets_list.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b00706-84e4-4b68-82fe-863431fa5dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a538fce2-5e7b-4a68-a1e8-c94bf3c75ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating sparse representation to feed the placeholder\n",
    "train_targets = tf.ragged.constant([i for i in targets_list], dtype=np.int32)\n",
    "train_targets_len = tf.cast(train_targets.row_lengths(), tf.int32)\n",
    "train_targets = train_targets.to_sparse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbd1d6c7-6281-4129-a4f5-6056ff0919d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_inputs, val_targets, val_seq_len, val_targets_len = train_inputs, train_targets, train_seq_len, train_targets_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b26420e6-239a-40d4-9169-ac3f1ec73681",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTCLossLayer(tf.keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        labels = inputs[0]\n",
    "        logits = inputs[1]\n",
    "        label_len = inputs[2]\n",
    "        logit_len = inputs[3]\n",
    "\n",
    "        logits_trans = tf.transpose(logits, (1,0,2))\n",
    "        label_len = tf.reshape(label_len, (-1,))\n",
    "        logit_len = tf.reshape(logit_len, (-1,))\n",
    "        loss = tf.reduce_mean(tf.nn.ctc_loss(labels, logits_trans, label_len, logit_len, blank_index=-1))\n",
    "        # define loss here instead of in compile\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        # Decode\n",
    "        decoded, _ = tf.nn.ctc_greedy_decoder(logits_trans, logit_len)\n",
    "\n",
    "        # Inaccuracy: label error rate\n",
    "        ler = tf.reduce_mean(tf.edit_distance(tf.cast(decoded[0], tf.int32),labels))\n",
    "        self.add_metric(ler, name='ler', aggregation='mean')\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2068651d-1947-48fb-bedb-a671095f20ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Training Cells\n",
    "# num_units = 50\n",
    "# cells = []\n",
    "# for _ in range(num_layers):\n",
    "#     cell = tf.keras.layers.GRUCell(num_units)\n",
    "#     cells.append(cell)\n",
    "\n",
    "# stack = tf.keras.layers.StackedRNNCells(cells)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08477705-ad36-44ea-b87e-a136207a3567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definning Input Parameters\n",
    "input_feature = tf.keras.layers.Input((None, num_features), name='input_feature')\n",
    "input_label = tf.keras.layers.Input((None,), dtype=tf.int32, sparse=True, name='input_label')\n",
    "input_feature_len = tf.keras.layers.Input((1,), dtype=tf.int32, name='input_feature_len')\n",
    "input_label_len =tf.keras.layers.Input((1,), dtype=tf.int32, name='input_label_len')\n",
    "\n",
    "input_masking = tf.keras.layers.Masking(FEAT_MASK_VALUE)(input_feature)\n",
    "x = tf.keras.layers.LSTM(120,return_sequences=True)(input_masking)\n",
    "x_1 = tf.keras.layers.BatchNormalization()(x)\n",
    "x_2 = tf.keras.layers.LSTM(120,return_sequences=True)(x_1)\n",
    "# x_3= tf.keras.layers.BatchNormalization()(x_2)\n",
    "# x_4 = tf.keras.layers.LSTM(50,return_sequences=True)(x_3)\n",
    "# x = tf.keras.layers.BatchNormalization()(x)\n",
    "# layer_rnn = tf.keras.layers.LSTM(10, return_sequences=True)(layer_bn)\n",
    "# x = tf.keras.layers.Dropout(0.2, seed=42)(x)\n",
    "layer_output = tf.keras.layers.TimeDistributed(Dense(num_classes, kernel_initializer=tf.keras.initializers.TruncatedNormal(0.0,0.1), bias_initializer='zeros', name='logit'))(x_2)\n",
    "\n",
    "layer_loss = CTCLossLayer()([input_label, layer_output, input_label_len, input_feature_len])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ebad848-3b83-4a0a-acc9-cc02c2659d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_feature (InputLayer)      [(None, None, 13)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, None, 13)     0           input_feature[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, None, 120)    64320       masking[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, None, 120)    480         lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, None, 120)    115680      batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "input_label (InputLayer)        [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 223)    26983       lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_label_len (InputLayer)    [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_feature_len (InputLayer)  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc_loss_layer (CTCLossLayer)   (None, None, 223)    0           input_label[0][0]                \n",
      "                                                                 time_distributed[0][0]           \n",
      "                                                                 input_label_len[0][0]            \n",
      "                                                                 input_feature_len[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 207,463\n",
      "Trainable params: 207,223\n",
      "Non-trainable params: 240\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create models for training and prediction\n",
    "model_train = tf.keras.models.Model(inputs=[input_feature, input_label, input_feature_len, input_label_len],\n",
    "            outputs=layer_loss)\n",
    "print(model_train.summary())\n",
    "model_predict = tf.keras.models.Model(inputs=input_feature, outputs=layer_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65a3acd2-a149-4e10-8305-80a2d67ef2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "46/46 [==============================] - 12s 104ms/step - loss: 624.4453 - ler: 0.9489 - val_loss: 149.2170 - val_ler: 0.9225\n",
      "\n",
      "Epoch 00001: ler improved from inf to 0.94890, saving model to ../models/RNN.h5\n",
      "Epoch 2/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 145.2790 - ler: 0.8872 - val_loss: 149.4561 - val_ler: 0.9284\n",
      "\n",
      "Epoch 00002: ler improved from 0.94890 to 0.88716, saving model to ../models/RNN.h5\n",
      "Epoch 3/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 139.0784 - ler: 0.8892 - val_loss: 138.4657 - val_ler: 0.9064\n",
      "\n",
      "Epoch 00003: ler did not improve from 0.88716\n",
      "Epoch 4/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 139.1520 - ler: 0.8876 - val_loss: 136.9313 - val_ler: 0.9095\n",
      "\n",
      "Epoch 00004: ler did not improve from 0.88716\n",
      "Epoch 5/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 134.3340 - ler: 0.8827 - val_loss: 134.9665 - val_ler: 0.9096\n",
      "\n",
      "Epoch 00005: ler improved from 0.88716 to 0.88271, saving model to ../models/RNN.h5\n",
      "Epoch 6/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 134.3232 - ler: 0.9050 - val_loss: 131.1834 - val_ler: 0.9305\n",
      "\n",
      "Epoch 00006: ler did not improve from 0.88271\n",
      "Epoch 7/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 129.7887 - ler: 0.9132 - val_loss: 129.1165 - val_ler: 0.9227\n",
      "\n",
      "Epoch 00007: ler did not improve from 0.88271\n",
      "Epoch 8/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 127.7024 - ler: 0.9077 - val_loss: 127.9046 - val_ler: 0.9131\n",
      "\n",
      "Epoch 00008: ler did not improve from 0.88271\n",
      "Epoch 9/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 127.9301 - ler: 0.8857 - val_loss: 127.2133 - val_ler: 0.8521\n",
      "\n",
      "Epoch 00009: ler did not improve from 0.88271\n",
      "Epoch 10/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 128.1723 - ler: 0.8498 - val_loss: 126.0266 - val_ler: 0.8329\n",
      "\n",
      "Epoch 00010: ler improved from 0.88271 to 0.84983, saving model to ../models/RNN.h5\n",
      "Epoch 11/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 124.8369 - ler: 0.8261 - val_loss: 125.6574 - val_ler: 0.8111\n",
      "\n",
      "Epoch 00011: ler improved from 0.84983 to 0.82613, saving model to ../models/RNN.h5\n",
      "Epoch 12/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 125.4888 - ler: 0.8076 - val_loss: 125.3588 - val_ler: 0.8070\n",
      "\n",
      "Epoch 00012: ler improved from 0.82613 to 0.80763, saving model to ../models/RNN.h5\n",
      "Epoch 13/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 126.0855 - ler: 0.8070 - val_loss: 126.1348 - val_ler: 0.7800\n",
      "\n",
      "Epoch 00013: ler improved from 0.80763 to 0.80696, saving model to ../models/RNN.h5\n",
      "Epoch 14/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 124.9140 - ler: 0.8007 - val_loss: 125.8013 - val_ler: 0.8166\n",
      "\n",
      "Epoch 00014: ler improved from 0.80696 to 0.80067, saving model to ../models/RNN.h5\n",
      "Epoch 15/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 126.2206 - ler: 0.8005 - val_loss: 123.7515 - val_ler: 0.7959\n",
      "\n",
      "Epoch 00015: ler improved from 0.80067 to 0.80046, saving model to ../models/RNN.h5\n",
      "Epoch 16/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 123.7668 - ler: 0.7991 - val_loss: 124.5199 - val_ler: 0.7794\n",
      "\n",
      "Epoch 00016: ler improved from 0.80046 to 0.79911, saving model to ../models/RNN.h5\n",
      "Epoch 17/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 122.9882 - ler: 0.7976 - val_loss: 122.9620 - val_ler: 0.7999\n",
      "\n",
      "Epoch 00017: ler improved from 0.79911 to 0.79762, saving model to ../models/RNN.h5\n",
      "Epoch 18/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 122.5310 - ler: 0.7986 - val_loss: 122.9366 - val_ler: 0.8020\n",
      "\n",
      "Epoch 00018: ler did not improve from 0.79762\n",
      "Epoch 19/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 122.8235 - ler: 0.7964 - val_loss: 123.0850 - val_ler: 0.7820\n",
      "\n",
      "Epoch 00019: ler improved from 0.79762 to 0.79636, saving model to ../models/RNN.h5\n",
      "Epoch 20/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 125.5909 - ler: 0.7962 - val_loss: 122.0112 - val_ler: 0.7850\n",
      "\n",
      "Epoch 00020: ler improved from 0.79636 to 0.79617, saving model to ../models/RNN.h5\n",
      "Epoch 21/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 122.9394 - ler: 0.7926 - val_loss: 122.8846 - val_ler: 0.8046\n",
      "\n",
      "Epoch 00021: ler improved from 0.79617 to 0.79257, saving model to ../models/RNN.h5\n",
      "Epoch 22/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 121.6992 - ler: 0.7948 - val_loss: 121.6252 - val_ler: 0.8102\n",
      "\n",
      "Epoch 00022: ler did not improve from 0.79257\n",
      "Epoch 23/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 123.3494 - ler: 0.7966 - val_loss: 121.0118 - val_ler: 0.7912\n",
      "\n",
      "Epoch 00023: ler did not improve from 0.79257\n",
      "Epoch 24/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 120.0385 - ler: 0.7933 - val_loss: 120.6652 - val_ler: 0.8047\n",
      "\n",
      "Epoch 00024: ler did not improve from 0.79257\n",
      "Epoch 25/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 122.8848 - ler: 0.7951 - val_loss: 120.6653 - val_ler: 0.7985\n",
      "\n",
      "Epoch 00025: ler did not improve from 0.79257\n",
      "Epoch 26/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 121.9262 - ler: 0.7902 - val_loss: 119.9365 - val_ler: 0.7882\n",
      "\n",
      "Epoch 00026: ler improved from 0.79257 to 0.79020, saving model to ../models/RNN.h5\n",
      "Epoch 27/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 120.5532 - ler: 0.7931 - val_loss: 120.6729 - val_ler: 0.8092\n",
      "\n",
      "Epoch 00027: ler did not improve from 0.79020\n",
      "Epoch 28/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 120.2747 - ler: 0.7895 - val_loss: 119.4343 - val_ler: 0.7906\n",
      "\n",
      "Epoch 00028: ler improved from 0.79020 to 0.78947, saving model to ../models/RNN.h5\n",
      "Epoch 29/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 118.3503 - ler: 0.7910 - val_loss: 118.9902 - val_ler: 0.7912\n",
      "\n",
      "Epoch 00029: ler did not improve from 0.78947\n",
      "Epoch 30/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 119.4160 - ler: 0.7896 - val_loss: 118.6760 - val_ler: 0.7908\n",
      "\n",
      "Epoch 00030: ler did not improve from 0.78947\n",
      "Epoch 31/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 119.2596 - ler: 0.7892 - val_loss: 118.6132 - val_ler: 0.7887\n",
      "\n",
      "Epoch 00031: ler improved from 0.78947 to 0.78921, saving model to ../models/RNN.h5\n",
      "Epoch 32/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 119.4523 - ler: 0.7894 - val_loss: 117.9069 - val_ler: 0.7842\n",
      "\n",
      "Epoch 00032: ler did not improve from 0.78921\n",
      "Epoch 33/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 117.7085 - ler: 0.7872 - val_loss: 117.5247 - val_ler: 0.7829\n",
      "\n",
      "Epoch 00033: ler improved from 0.78921 to 0.78723, saving model to ../models/RNN.h5\n",
      "Epoch 34/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 117.3116 - ler: 0.7862 - val_loss: 117.6750 - val_ler: 0.7771\n",
      "\n",
      "Epoch 00034: ler improved from 0.78723 to 0.78616, saving model to ../models/RNN.h5\n",
      "Epoch 35/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 117.3676 - ler: 0.7870 - val_loss: 117.3034 - val_ler: 0.7807\n",
      "\n",
      "Epoch 00035: ler did not improve from 0.78616\n",
      "Epoch 36/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 116.6329 - ler: 0.7843 - val_loss: 117.7195 - val_ler: 0.7666\n",
      "\n",
      "Epoch 00036: ler improved from 0.78616 to 0.78429, saving model to ../models/RNN.h5\n",
      "Epoch 37/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 117.7058 - ler: 0.7819 - val_loss: 117.6154 - val_ler: 0.7758\n",
      "\n",
      "Epoch 00037: ler improved from 0.78429 to 0.78189, saving model to ../models/RNN.h5\n",
      "Epoch 38/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 117.2999 - ler: 0.7833 - val_loss: 116.1677 - val_ler: 0.7715\n",
      "\n",
      "Epoch 00038: ler did not improve from 0.78189\n",
      "Epoch 39/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 116.5929 - ler: 0.7816 - val_loss: 116.3492 - val_ler: 0.8022\n",
      "\n",
      "Epoch 00039: ler improved from 0.78189 to 0.78161, saving model to ../models/RNN.h5\n",
      "Epoch 40/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 115.0586 - ler: 0.7813 - val_loss: 115.7056 - val_ler: 0.7753\n",
      "\n",
      "Epoch 00040: ler improved from 0.78161 to 0.78127, saving model to ../models/RNN.h5\n",
      "Epoch 41/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 116.6197 - ler: 0.7806 - val_loss: 114.8730 - val_ler: 0.7852\n",
      "\n",
      "Epoch 00041: ler improved from 0.78127 to 0.78059, saving model to ../models/RNN.h5\n",
      "Epoch 42/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 112.5855 - ler: 0.7796 - val_loss: 114.9836 - val_ler: 0.7723\n",
      "\n",
      "Epoch 00042: ler improved from 0.78059 to 0.77964, saving model to ../models/RNN.h5\n",
      "Epoch 43/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 115.6638 - ler: 0.7757 - val_loss: 114.9224 - val_ler: 0.7777\n",
      "\n",
      "Epoch 00043: ler improved from 0.77964 to 0.77570, saving model to ../models/RNN.h5\n",
      "Epoch 44/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 115.6832 - ler: 0.7755 - val_loss: 113.8112 - val_ler: 0.7757\n",
      "\n",
      "Epoch 00044: ler improved from 0.77570 to 0.77551, saving model to ../models/RNN.h5\n",
      "Epoch 45/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 113.8621 - ler: 0.7744 - val_loss: 113.5907 - val_ler: 0.7755\n",
      "\n",
      "Epoch 00045: ler improved from 0.77551 to 0.77443, saving model to ../models/RNN.h5\n",
      "Epoch 46/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 114.6511 - ler: 0.7739 - val_loss: 113.4207 - val_ler: 0.7728\n",
      "\n",
      "Epoch 00046: ler improved from 0.77443 to 0.77388, saving model to ../models/RNN.h5\n",
      "Epoch 47/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 115.8894 - ler: 0.7717 - val_loss: 113.3779 - val_ler: 0.7660\n",
      "\n",
      "Epoch 00047: ler improved from 0.77388 to 0.77171, saving model to ../models/RNN.h5\n",
      "Epoch 48/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 114.6475 - ler: 0.7719 - val_loss: 113.2228 - val_ler: 0.7552\n",
      "\n",
      "Epoch 00048: ler did not improve from 0.77171\n",
      "Epoch 49/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 111.4477 - ler: 0.7705 - val_loss: 112.8859 - val_ler: 0.7634\n",
      "\n",
      "Epoch 00049: ler improved from 0.77171 to 0.77045, saving model to ../models/RNN.h5\n",
      "Epoch 50/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 111.7909 - ler: 0.7663 - val_loss: 112.6991 - val_ler: 0.7844\n",
      "\n",
      "Epoch 00050: ler improved from 0.77045 to 0.76627, saving model to ../models/RNN.h5\n",
      "Epoch 51/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 113.0781 - ler: 0.7678 - val_loss: 112.1298 - val_ler: 0.7734\n",
      "\n",
      "Epoch 00051: ler did not improve from 0.76627\n",
      "Epoch 52/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 112.9150 - ler: 0.7661 - val_loss: 111.9248 - val_ler: 0.7802\n",
      "\n",
      "Epoch 00052: ler improved from 0.76627 to 0.76610, saving model to ../models/RNN.h5\n",
      "Epoch 53/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 111.1673 - ler: 0.7637 - val_loss: 111.7962 - val_ler: 0.7488\n",
      "\n",
      "Epoch 00053: ler improved from 0.76610 to 0.76374, saving model to ../models/RNN.h5\n",
      "Epoch 54/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 109.9401 - ler: 0.7630 - val_loss: 110.5482 - val_ler: 0.7535\n",
      "\n",
      "Epoch 00054: ler improved from 0.76374 to 0.76298, saving model to ../models/RNN.h5\n",
      "Epoch 55/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 112.2202 - ler: 0.7626 - val_loss: 111.0286 - val_ler: 0.7481\n",
      "\n",
      "Epoch 00055: ler improved from 0.76298 to 0.76261, saving model to ../models/RNN.h5\n",
      "Epoch 56/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 111.0058 - ler: 0.7610 - val_loss: 110.3060 - val_ler: 0.7457\n",
      "\n",
      "Epoch 00056: ler improved from 0.76261 to 0.76096, saving model to ../models/RNN.h5\n",
      "Epoch 57/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 109.8529 - ler: 0.7582 - val_loss: 109.5781 - val_ler: 0.7512\n",
      "\n",
      "Epoch 00057: ler improved from 0.76096 to 0.75817, saving model to ../models/RNN.h5\n",
      "Epoch 58/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 109.9848 - ler: 0.7550 - val_loss: 109.1024 - val_ler: 0.7435\n",
      "\n",
      "Epoch 00058: ler improved from 0.75817 to 0.75501, saving model to ../models/RNN.h5\n",
      "Epoch 59/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 110.3069 - ler: 0.7548 - val_loss: 109.4181 - val_ler: 0.7640\n",
      "\n",
      "Epoch 00059: ler improved from 0.75501 to 0.75484, saving model to ../models/RNN.h5\n",
      "Epoch 60/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 110.7621 - ler: 0.7536 - val_loss: 109.6098 - val_ler: 0.7657\n",
      "\n",
      "Epoch 00060: ler improved from 0.75484 to 0.75363, saving model to ../models/RNN.h5\n",
      "Epoch 61/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 110.0916 - ler: 0.7523 - val_loss: 108.2894 - val_ler: 0.7660\n",
      "\n",
      "Epoch 00061: ler improved from 0.75363 to 0.75232, saving model to ../models/RNN.h5\n",
      "Epoch 62/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 108.5841 - ler: 0.7511 - val_loss: 107.7586 - val_ler: 0.7456\n",
      "\n",
      "Epoch 00062: ler improved from 0.75232 to 0.75112, saving model to ../models/RNN.h5\n",
      "Epoch 63/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 105.9962 - ler: 0.7516 - val_loss: 107.0020 - val_ler: 0.7581\n",
      "\n",
      "Epoch 00063: ler did not improve from 0.75112\n",
      "Epoch 64/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 107.8767 - ler: 0.7492 - val_loss: 106.7041 - val_ler: 0.7421\n",
      "\n",
      "Epoch 00064: ler improved from 0.75112 to 0.74918, saving model to ../models/RNN.h5\n",
      "Epoch 65/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 107.8349 - ler: 0.7454 - val_loss: 106.3847 - val_ler: 0.7556\n",
      "\n",
      "Epoch 00065: ler improved from 0.74918 to 0.74539, saving model to ../models/RNN.h5\n",
      "Epoch 66/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 107.5235 - ler: 0.7460 - val_loss: 106.2926 - val_ler: 0.7431\n",
      "\n",
      "Epoch 00066: ler did not improve from 0.74539\n",
      "Epoch 67/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 106.5593 - ler: 0.7459 - val_loss: 105.9186 - val_ler: 0.7297\n",
      "\n",
      "Epoch 00067: ler did not improve from 0.74539\n",
      "Epoch 68/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 106.8966 - ler: 0.7415 - val_loss: 105.6359 - val_ler: 0.7369\n",
      "\n",
      "Epoch 00068: ler improved from 0.74539 to 0.74147, saving model to ../models/RNN.h5\n",
      "Epoch 69/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 105.6591 - ler: 0.7415 - val_loss: 105.2659 - val_ler: 0.7346\n",
      "\n",
      "Epoch 00069: ler did not improve from 0.74147\n",
      "Epoch 70/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 106.4532 - ler: 0.7407 - val_loss: 104.4737 - val_ler: 0.7371\n",
      "\n",
      "Epoch 00070: ler improved from 0.74147 to 0.74074, saving model to ../models/RNN.h5\n",
      "Epoch 71/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 104.3271 - ler: 0.7388 - val_loss: 104.7427 - val_ler: 0.7206\n",
      "\n",
      "Epoch 00071: ler improved from 0.74074 to 0.73885, saving model to ../models/RNN.h5\n",
      "Epoch 72/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 105.9783 - ler: 0.7365 - val_loss: 103.4008 - val_ler: 0.7304\n",
      "\n",
      "Epoch 00072: ler improved from 0.73885 to 0.73646, saving model to ../models/RNN.h5\n",
      "Epoch 73/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 102.2638 - ler: 0.7338 - val_loss: 102.9882 - val_ler: 0.7330\n",
      "\n",
      "Epoch 00073: ler improved from 0.73646 to 0.73376, saving model to ../models/RNN.h5\n",
      "Epoch 74/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 104.7148 - ler: 0.7336 - val_loss: 102.8181 - val_ler: 0.7277\n",
      "\n",
      "Epoch 00074: ler improved from 0.73376 to 0.73364, saving model to ../models/RNN.h5\n",
      "Epoch 75/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 102.0041 - ler: 0.7284 - val_loss: 102.2784 - val_ler: 0.7292\n",
      "\n",
      "Epoch 00075: ler improved from 0.73364 to 0.72839, saving model to ../models/RNN.h5\n",
      "Epoch 76/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 103.4511 - ler: 0.7294 - val_loss: 101.6022 - val_ler: 0.7347\n",
      "\n",
      "Epoch 00076: ler did not improve from 0.72839\n",
      "Epoch 77/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 102.1421 - ler: 0.7272 - val_loss: 101.0130 - val_ler: 0.7281\n",
      "\n",
      "Epoch 00077: ler improved from 0.72839 to 0.72718, saving model to ../models/RNN.h5\n",
      "Epoch 78/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 103.9860 - ler: 0.7261 - val_loss: 101.2004 - val_ler: 0.7280\n",
      "\n",
      "Epoch 00078: ler improved from 0.72718 to 0.72606, saving model to ../models/RNN.h5\n",
      "Epoch 79/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 101.3573 - ler: 0.7227 - val_loss: 100.0885 - val_ler: 0.7294\n",
      "\n",
      "Epoch 00079: ler improved from 0.72606 to 0.72267, saving model to ../models/RNN.h5\n",
      "Epoch 80/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 100.8516 - ler: 0.7209 - val_loss: 99.7445 - val_ler: 0.7254\n",
      "\n",
      "Epoch 00080: ler improved from 0.72267 to 0.72090, saving model to ../models/RNN.h5\n",
      "Epoch 81/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 99.3012 - ler: 0.7186 - val_loss: 100.1089 - val_ler: 0.7187\n",
      "\n",
      "Epoch 00081: ler improved from 0.72090 to 0.71861, saving model to ../models/RNN.h5\n",
      "Epoch 82/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 101.0927 - ler: 0.7208 - val_loss: 99.4317 - val_ler: 0.7098\n",
      "\n",
      "Epoch 00082: ler did not improve from 0.71861\n",
      "Epoch 83/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 100.5160 - ler: 0.7169 - val_loss: 99.7278 - val_ler: 0.7033\n",
      "\n",
      "Epoch 00083: ler improved from 0.71861 to 0.71688, saving model to ../models/RNN.h5\n",
      "Epoch 84/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 98.2520 - ler: 0.7140 - val_loss: 98.5107 - val_ler: 0.7236\n",
      "\n",
      "Epoch 00084: ler improved from 0.71688 to 0.71398, saving model to ../models/RNN.h5\n",
      "Epoch 85/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 102.4644 - ler: 0.7141 - val_loss: 97.9016 - val_ler: 0.7080\n",
      "\n",
      "Epoch 00085: ler did not improve from 0.71398\n",
      "Epoch 86/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 98.4281 - ler: 0.7063 - val_loss: 97.3103 - val_ler: 0.7008\n",
      "\n",
      "Epoch 00086: ler improved from 0.71398 to 0.70633, saving model to ../models/RNN.h5\n",
      "Epoch 87/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 96.8345 - ler: 0.7105 - val_loss: 99.0161 - val_ler: 0.7260\n",
      "\n",
      "Epoch 00087: ler did not improve from 0.70633\n",
      "Epoch 88/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 97.4745 - ler: 0.7069 - val_loss: 96.4961 - val_ler: 0.7047\n",
      "\n",
      "Epoch 00088: ler did not improve from 0.70633\n",
      "Epoch 89/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 97.2945 - ler: 0.7046 - val_loss: 95.9401 - val_ler: 0.6991\n",
      "\n",
      "Epoch 00089: ler improved from 0.70633 to 0.70464, saving model to ../models/RNN.h5\n",
      "Epoch 90/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 96.0272 - ler: 0.7018 - val_loss: 95.7164 - val_ler: 0.6960\n",
      "\n",
      "Epoch 00090: ler improved from 0.70464 to 0.70178, saving model to ../models/RNN.h5\n",
      "Epoch 91/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 94.4163 - ler: 0.6982 - val_loss: 95.1927 - val_ler: 0.7036\n",
      "\n",
      "Epoch 00091: ler improved from 0.70178 to 0.69818, saving model to ../models/RNN.h5\n",
      "Epoch 92/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 98.1869 - ler: 0.6975 - val_loss: 95.2591 - val_ler: 0.6898\n",
      "\n",
      "Epoch 00092: ler improved from 0.69818 to 0.69746, saving model to ../models/RNN.h5\n",
      "Epoch 93/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 94.8773 - ler: 0.6977 - val_loss: 94.0799 - val_ler: 0.6884\n",
      "\n",
      "Epoch 00093: ler did not improve from 0.69746\n",
      "Epoch 94/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 95.5409 - ler: 0.6943 - val_loss: 94.5148 - val_ler: 0.6882\n",
      "\n",
      "Epoch 00094: ler improved from 0.69746 to 0.69433, saving model to ../models/RNN.h5\n",
      "Epoch 95/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 94.7695 - ler: 0.6908 - val_loss: 93.5922 - val_ler: 0.6985\n",
      "\n",
      "Epoch 00095: ler improved from 0.69433 to 0.69080, saving model to ../models/RNN.h5\n",
      "Epoch 96/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 92.9931 - ler: 0.6910 - val_loss: 92.5518 - val_ler: 0.6852\n",
      "\n",
      "Epoch 00096: ler did not improve from 0.69080\n",
      "Epoch 97/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 92.1035 - ler: 0.6880 - val_loss: 92.4298 - val_ler: 0.6788\n",
      "\n",
      "Epoch 00097: ler improved from 0.69080 to 0.68804, saving model to ../models/RNN.h5\n",
      "Epoch 98/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 91.9771 - ler: 0.6857 - val_loss: 91.5363 - val_ler: 0.6713\n",
      "\n",
      "Epoch 00098: ler improved from 0.68804 to 0.68573, saving model to ../models/RNN.h5\n",
      "Epoch 99/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 91.3409 - ler: 0.6839 - val_loss: 91.0553 - val_ler: 0.6772\n",
      "\n",
      "Epoch 00099: ler improved from 0.68573 to 0.68395, saving model to ../models/RNN.h5\n",
      "Epoch 100/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 89.6661 - ler: 0.6795 - val_loss: 90.7758 - val_ler: 0.6821\n",
      "\n",
      "Epoch 00100: ler improved from 0.68395 to 0.67953, saving model to ../models/RNN.h5\n",
      "Epoch 101/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 90.1060 - ler: 0.6770 - val_loss: 89.9518 - val_ler: 0.6778\n",
      "\n",
      "Epoch 00101: ler improved from 0.67953 to 0.67697, saving model to ../models/RNN.h5\n",
      "Epoch 102/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 90.4880 - ler: 0.6744 - val_loss: 90.1199 - val_ler: 0.6819\n",
      "\n",
      "Epoch 00102: ler improved from 0.67697 to 0.67440, saving model to ../models/RNN.h5\n",
      "Epoch 103/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 90.7547 - ler: 0.6713 - val_loss: 89.3406 - val_ler: 0.6746\n",
      "\n",
      "Epoch 00103: ler improved from 0.67440 to 0.67133, saving model to ../models/RNN.h5\n",
      "Epoch 104/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 89.0828 - ler: 0.6688 - val_loss: 89.5050 - val_ler: 0.6688\n",
      "\n",
      "Epoch 00104: ler improved from 0.67133 to 0.66881, saving model to ../models/RNN.h5\n",
      "Epoch 105/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 90.1980 - ler: 0.6692 - val_loss: 88.3044 - val_ler: 0.6578\n",
      "\n",
      "Epoch 00105: ler did not improve from 0.66881\n",
      "Epoch 106/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 89.1100 - ler: 0.6679 - val_loss: 88.4910 - val_ler: 0.6628\n",
      "\n",
      "Epoch 00106: ler improved from 0.66881 to 0.66790, saving model to ../models/RNN.h5\n",
      "Epoch 107/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 87.4435 - ler: 0.6638 - val_loss: 88.0858 - val_ler: 0.6654\n",
      "\n",
      "Epoch 00107: ler improved from 0.66790 to 0.66383, saving model to ../models/RNN.h5\n",
      "Epoch 108/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 89.1771 - ler: 0.6595 - val_loss: 87.1155 - val_ler: 0.6567\n",
      "\n",
      "Epoch 00108: ler improved from 0.66383 to 0.65949, saving model to ../models/RNN.h5\n",
      "Epoch 109/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 86.6539 - ler: 0.6579 - val_loss: 86.8907 - val_ler: 0.6538\n",
      "\n",
      "Epoch 00109: ler improved from 0.65949 to 0.65786, saving model to ../models/RNN.h5\n",
      "Epoch 110/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 87.6420 - ler: 0.6551 - val_loss: 86.3281 - val_ler: 0.6579\n",
      "\n",
      "Epoch 00110: ler improved from 0.65786 to 0.65510, saving model to ../models/RNN.h5\n",
      "Epoch 111/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 85.1293 - ler: 0.6529 - val_loss: 85.2798 - val_ler: 0.6418\n",
      "\n",
      "Epoch 00111: ler improved from 0.65510 to 0.65293, saving model to ../models/RNN.h5\n",
      "Epoch 112/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 86.8220 - ler: 0.6511 - val_loss: 85.2643 - val_ler: 0.6500\n",
      "\n",
      "Epoch 00112: ler improved from 0.65293 to 0.65106, saving model to ../models/RNN.h5\n",
      "Epoch 113/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 83.8719 - ler: 0.6484 - val_loss: 84.8072 - val_ler: 0.6473\n",
      "\n",
      "Epoch 00113: ler improved from 0.65106 to 0.64836, saving model to ../models/RNN.h5\n",
      "Epoch 114/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 84.6514 - ler: 0.6464 - val_loss: 84.3652 - val_ler: 0.6347\n",
      "\n",
      "Epoch 00114: ler improved from 0.64836 to 0.64641, saving model to ../models/RNN.h5\n",
      "Epoch 115/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 85.3783 - ler: 0.6438 - val_loss: 84.3533 - val_ler: 0.6276\n",
      "\n",
      "Epoch 00115: ler improved from 0.64641 to 0.64377, saving model to ../models/RNN.h5\n",
      "Epoch 116/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 84.1893 - ler: 0.6398 - val_loss: 83.7715 - val_ler: 0.6427\n",
      "\n",
      "Epoch 00116: ler improved from 0.64377 to 0.63981, saving model to ../models/RNN.h5\n",
      "Epoch 117/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 84.8996 - ler: 0.6399 - val_loss: 82.9750 - val_ler: 0.6318\n",
      "\n",
      "Epoch 00117: ler did not improve from 0.63981\n",
      "Epoch 118/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 83.2204 - ler: 0.6355 - val_loss: 82.2845 - val_ler: 0.6300\n",
      "\n",
      "Epoch 00118: ler improved from 0.63981 to 0.63547, saving model to ../models/RNN.h5\n",
      "Epoch 119/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 83.5732 - ler: 0.6315 - val_loss: 82.0833 - val_ler: 0.6287\n",
      "\n",
      "Epoch 00119: ler improved from 0.63547 to 0.63149, saving model to ../models/RNN.h5\n",
      "Epoch 120/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 82.5363 - ler: 0.6304 - val_loss: 82.1142 - val_ler: 0.6359\n",
      "\n",
      "Epoch 00120: ler improved from 0.63149 to 0.63041, saving model to ../models/RNN.h5\n",
      "Epoch 121/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 85.3718 - ler: 0.6318 - val_loss: 82.5273 - val_ler: 0.6193\n",
      "\n",
      "Epoch 00121: ler did not improve from 0.63041\n",
      "Epoch 122/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 82.3248 - ler: 0.6287 - val_loss: 81.0669 - val_ler: 0.6191\n",
      "\n",
      "Epoch 00122: ler improved from 0.63041 to 0.62866, saving model to ../models/RNN.h5\n",
      "Epoch 123/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 79.2346 - ler: 0.6253 - val_loss: 81.6272 - val_ler: 0.6223\n",
      "\n",
      "Epoch 00123: ler improved from 0.62866 to 0.62525, saving model to ../models/RNN.h5\n",
      "Epoch 124/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 80.3861 - ler: 0.6231 - val_loss: 80.8668 - val_ler: 0.6073\n",
      "\n",
      "Epoch 00124: ler improved from 0.62525 to 0.62308, saving model to ../models/RNN.h5\n",
      "Epoch 125/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 82.8260 - ler: 0.6186 - val_loss: 79.3807 - val_ler: 0.6221\n",
      "\n",
      "Epoch 00125: ler improved from 0.62308 to 0.61865, saving model to ../models/RNN.h5\n",
      "Epoch 126/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 79.1200 - ler: 0.6145 - val_loss: 79.9998 - val_ler: 0.6092\n",
      "\n",
      "Epoch 00126: ler improved from 0.61865 to 0.61450, saving model to ../models/RNN.h5\n",
      "Epoch 127/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 81.4447 - ler: 0.6108 - val_loss: 78.5385 - val_ler: 0.6033\n",
      "\n",
      "Epoch 00127: ler improved from 0.61450 to 0.61083, saving model to ../models/RNN.h5\n",
      "Epoch 128/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 79.3740 - ler: 0.6110 - val_loss: 78.2171 - val_ler: 0.6001\n",
      "\n",
      "Epoch 00128: ler did not improve from 0.61083\n",
      "Epoch 129/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 81.7607 - ler: 0.6110 - val_loss: 77.6241 - val_ler: 0.5998\n",
      "\n",
      "Epoch 00129: ler did not improve from 0.61083\n",
      "Epoch 130/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 80.1348 - ler: 0.6009 - val_loss: 76.9140 - val_ler: 0.5964\n",
      "\n",
      "Epoch 00130: ler improved from 0.61083 to 0.60087, saving model to ../models/RNN.h5\n",
      "Epoch 131/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 78.3887 - ler: 0.6011 - val_loss: 77.2948 - val_ler: 0.5903\n",
      "\n",
      "Epoch 00131: ler did not improve from 0.60087\n",
      "Epoch 132/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 79.0297 - ler: 0.5987 - val_loss: 76.4186 - val_ler: 0.5938\n",
      "\n",
      "Epoch 00132: ler improved from 0.60087 to 0.59868, saving model to ../models/RNN.h5\n",
      "Epoch 133/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 77.4335 - ler: 0.5916 - val_loss: 76.3274 - val_ler: 0.5901\n",
      "\n",
      "Epoch 00133: ler improved from 0.59868 to 0.59163, saving model to ../models/RNN.h5\n",
      "Epoch 134/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 78.1940 - ler: 0.5936 - val_loss: 75.6287 - val_ler: 0.5887\n",
      "\n",
      "Epoch 00134: ler did not improve from 0.59163\n",
      "Epoch 135/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 75.2310 - ler: 0.5924 - val_loss: 76.1117 - val_ler: 0.5842\n",
      "\n",
      "Epoch 00135: ler did not improve from 0.59163\n",
      "Epoch 136/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 76.6561 - ler: 0.5922 - val_loss: 75.4883 - val_ler: 0.5705\n",
      "\n",
      "Epoch 00136: ler did not improve from 0.59163\n",
      "Epoch 137/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 75.5380 - ler: 0.5830 - val_loss: 74.7491 - val_ler: 0.5875\n",
      "\n",
      "Epoch 00137: ler improved from 0.59163 to 0.58301, saving model to ../models/RNN.h5\n",
      "Epoch 138/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 76.3510 - ler: 0.5867 - val_loss: 73.7919 - val_ler: 0.5730\n",
      "\n",
      "Epoch 00138: ler did not improve from 0.58301\n",
      "Epoch 139/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 75.2762 - ler: 0.5772 - val_loss: 73.1342 - val_ler: 0.5686\n",
      "\n",
      "Epoch 00139: ler improved from 0.58301 to 0.57715, saving model to ../models/RNN.h5\n",
      "Epoch 140/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 74.0517 - ler: 0.5719 - val_loss: 72.5995 - val_ler: 0.5660\n",
      "\n",
      "Epoch 00140: ler improved from 0.57715 to 0.57194, saving model to ../models/RNN.h5\n",
      "Epoch 141/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 74.6828 - ler: 0.5690 - val_loss: 71.7682 - val_ler: 0.5641\n",
      "\n",
      "Epoch 00141: ler improved from 0.57194 to 0.56895, saving model to ../models/RNN.h5\n",
      "Epoch 142/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 71.0607 - ler: 0.5643 - val_loss: 72.3224 - val_ler: 0.5576\n",
      "\n",
      "Epoch 00142: ler improved from 0.56895 to 0.56428, saving model to ../models/RNN.h5\n",
      "Epoch 143/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 70.7821 - ler: 0.5696 - val_loss: 71.4348 - val_ler: 0.5522\n",
      "\n",
      "Epoch 00143: ler did not improve from 0.56428\n",
      "Epoch 144/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 74.0966 - ler: 0.5640 - val_loss: 70.9869 - val_ler: 0.5572\n",
      "\n",
      "Epoch 00144: ler improved from 0.56428 to 0.56398, saving model to ../models/RNN.h5\n",
      "Epoch 145/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 71.2474 - ler: 0.5632 - val_loss: 70.9660 - val_ler: 0.5490\n",
      "\n",
      "Epoch 00145: ler improved from 0.56398 to 0.56318, saving model to ../models/RNN.h5\n",
      "Epoch 146/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 69.2193 - ler: 0.5570 - val_loss: 70.2124 - val_ler: 0.5462\n",
      "\n",
      "Epoch 00146: ler improved from 0.56318 to 0.55702, saving model to ../models/RNN.h5\n",
      "Epoch 147/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 70.5593 - ler: 0.5595 - val_loss: 70.9833 - val_ler: 0.5449\n",
      "\n",
      "Epoch 00147: ler did not improve from 0.55702\n",
      "Epoch 148/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 70.7720 - ler: 0.5570 - val_loss: 70.0161 - val_ler: 0.5357\n",
      "\n",
      "Epoch 00148: ler improved from 0.55702 to 0.55698, saving model to ../models/RNN.h5\n",
      "Epoch 149/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 71.6432 - ler: 0.5549 - val_loss: 69.2338 - val_ler: 0.5408\n",
      "\n",
      "Epoch 00149: ler improved from 0.55698 to 0.55489, saving model to ../models/RNN.h5\n",
      "Epoch 150/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 69.8867 - ler: 0.5516 - val_loss: 69.5953 - val_ler: 0.5386\n",
      "\n",
      "Epoch 00150: ler improved from 0.55489 to 0.55163, saving model to ../models/RNN.h5\n",
      "Epoch 151/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 69.5441 - ler: 0.5507 - val_loss: 69.3685 - val_ler: 0.5519\n",
      "\n",
      "Epoch 00151: ler improved from 0.55163 to 0.55067, saving model to ../models/RNN.h5\n",
      "Epoch 152/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 69.3454 - ler: 0.5443 - val_loss: 68.3815 - val_ler: 0.5225\n",
      "\n",
      "Epoch 00152: ler improved from 0.55067 to 0.54430, saving model to ../models/RNN.h5\n",
      "Epoch 153/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 67.2885 - ler: 0.5398 - val_loss: 67.6073 - val_ler: 0.5282\n",
      "\n",
      "Epoch 00153: ler improved from 0.54430 to 0.53985, saving model to ../models/RNN.h5\n",
      "Epoch 154/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 68.6076 - ler: 0.5383 - val_loss: 67.5967 - val_ler: 0.5270\n",
      "\n",
      "Epoch 00154: ler improved from 0.53985 to 0.53832, saving model to ../models/RNN.h5\n",
      "Epoch 155/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 66.3484 - ler: 0.5312 - val_loss: 66.7905 - val_ler: 0.5207\n",
      "\n",
      "Epoch 00155: ler improved from 0.53832 to 0.53120, saving model to ../models/RNN.h5\n",
      "Epoch 156/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 67.3597 - ler: 0.5281 - val_loss: 65.5466 - val_ler: 0.5179\n",
      "\n",
      "Epoch 00156: ler improved from 0.53120 to 0.52805, saving model to ../models/RNN.h5\n",
      "Epoch 157/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 66.5197 - ler: 0.5274 - val_loss: 66.0169 - val_ler: 0.5237\n",
      "\n",
      "Epoch 00157: ler improved from 0.52805 to 0.52738, saving model to ../models/RNN.h5\n",
      "Epoch 158/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 66.5507 - ler: 0.5256 - val_loss: 65.9159 - val_ler: 0.5102\n",
      "\n",
      "Epoch 00158: ler improved from 0.52738 to 0.52564, saving model to ../models/RNN.h5\n",
      "Epoch 159/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 67.8142 - ler: 0.5238 - val_loss: 66.1439 - val_ler: 0.5256\n",
      "\n",
      "Epoch 00159: ler improved from 0.52564 to 0.52383, saving model to ../models/RNN.h5\n",
      "Epoch 160/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 67.1595 - ler: 0.5247 - val_loss: 64.4901 - val_ler: 0.5072\n",
      "\n",
      "Epoch 00160: ler did not improve from 0.52383\n",
      "Epoch 161/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 66.5103 - ler: 0.5187 - val_loss: 64.5624 - val_ler: 0.5093\n",
      "\n",
      "Epoch 00161: ler improved from 0.52383 to 0.51871, saving model to ../models/RNN.h5\n",
      "Epoch 162/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 67.3451 - ler: 0.5177 - val_loss: 63.9251 - val_ler: 0.4972\n",
      "\n",
      "Epoch 00162: ler improved from 0.51871 to 0.51766, saving model to ../models/RNN.h5\n",
      "Epoch 163/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 67.5974 - ler: 0.5136 - val_loss: 64.6386 - val_ler: 0.5117\n",
      "\n",
      "Epoch 00163: ler improved from 0.51766 to 0.51363, saving model to ../models/RNN.h5\n",
      "Epoch 164/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 65.2001 - ler: 0.5108 - val_loss: 63.6816 - val_ler: 0.5004\n",
      "\n",
      "Epoch 00164: ler improved from 0.51363 to 0.51081, saving model to ../models/RNN.h5\n",
      "Epoch 165/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 63.7693 - ler: 0.5122 - val_loss: 63.2465 - val_ler: 0.4890\n",
      "\n",
      "Epoch 00165: ler did not improve from 0.51081\n",
      "Epoch 166/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 63.6215 - ler: 0.5007 - val_loss: 62.2253 - val_ler: 0.4961\n",
      "\n",
      "Epoch 00166: ler improved from 0.51081 to 0.50070, saving model to ../models/RNN.h5\n",
      "Epoch 167/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 62.7864 - ler: 0.5038 - val_loss: 62.3764 - val_ler: 0.4937\n",
      "\n",
      "Epoch 00167: ler did not improve from 0.50070\n",
      "Epoch 168/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 62.6509 - ler: 0.4980 - val_loss: 62.1168 - val_ler: 0.4867\n",
      "\n",
      "Epoch 00168: ler improved from 0.50070 to 0.49796, saving model to ../models/RNN.h5\n",
      "Epoch 169/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 63.8298 - ler: 0.5006 - val_loss: 61.9523 - val_ler: 0.4856\n",
      "\n",
      "Epoch 00169: ler did not improve from 0.49796\n",
      "Epoch 170/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 62.2786 - ler: 0.4990 - val_loss: 61.3539 - val_ler: 0.4767\n",
      "\n",
      "Epoch 00170: ler did not improve from 0.49796\n",
      "Epoch 171/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 61.4179 - ler: 0.4887 - val_loss: 61.7680 - val_ler: 0.4910\n",
      "\n",
      "Epoch 00171: ler improved from 0.49796 to 0.48873, saving model to ../models/RNN.h5\n",
      "Epoch 172/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 62.3874 - ler: 0.4919 - val_loss: 60.2806 - val_ler: 0.4625\n",
      "\n",
      "Epoch 00172: ler did not improve from 0.48873\n",
      "Epoch 173/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 60.9798 - ler: 0.4965 - val_loss: 60.7943 - val_ler: 0.4790\n",
      "\n",
      "Epoch 00173: ler did not improve from 0.48873\n",
      "Epoch 174/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 62.0827 - ler: 0.4896 - val_loss: 59.9528 - val_ler: 0.4805\n",
      "\n",
      "Epoch 00174: ler did not improve from 0.48873\n",
      "Epoch 175/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 61.0030 - ler: 0.4887 - val_loss: 60.3936 - val_ler: 0.4912\n",
      "\n",
      "Epoch 00175: ler improved from 0.48873 to 0.48866, saving model to ../models/RNN.h5\n",
      "Epoch 176/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 59.6050 - ler: 0.4783 - val_loss: 58.8443 - val_ler: 0.4637\n",
      "\n",
      "Epoch 00176: ler improved from 0.48866 to 0.47829, saving model to ../models/RNN.h5\n",
      "Epoch 177/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 61.6196 - ler: 0.4787 - val_loss: 58.3891 - val_ler: 0.4579\n",
      "\n",
      "Epoch 00177: ler did not improve from 0.47829\n",
      "Epoch 178/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 57.1268 - ler: 0.4717 - val_loss: 59.0737 - val_ler: 0.4747\n",
      "\n",
      "Epoch 00178: ler improved from 0.47829 to 0.47167, saving model to ../models/RNN.h5\n",
      "Epoch 179/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 61.2209 - ler: 0.4786 - val_loss: 58.7253 - val_ler: 0.4628\n",
      "\n",
      "Epoch 00179: ler did not improve from 0.47167\n",
      "Epoch 180/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 58.7287 - ler: 0.4680 - val_loss: 57.3083 - val_ler: 0.4498\n",
      "\n",
      "Epoch 00180: ler improved from 0.47167 to 0.46800, saving model to ../models/RNN.h5\n",
      "Epoch 181/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 57.9652 - ler: 0.4646 - val_loss: 57.8871 - val_ler: 0.4530\n",
      "\n",
      "Epoch 00181: ler improved from 0.46800 to 0.46459, saving model to ../models/RNN.h5\n",
      "Epoch 182/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 58.8925 - ler: 0.4647 - val_loss: 56.6235 - val_ler: 0.4420\n",
      "\n",
      "Epoch 00182: ler did not improve from 0.46459\n",
      "Epoch 183/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 57.9081 - ler: 0.4560 - val_loss: 56.6035 - val_ler: 0.4430\n",
      "\n",
      "Epoch 00183: ler improved from 0.46459 to 0.45601, saving model to ../models/RNN.h5\n",
      "Epoch 184/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 56.2458 - ler: 0.4568 - val_loss: 55.6489 - val_ler: 0.4432\n",
      "\n",
      "Epoch 00184: ler did not improve from 0.45601\n",
      "Epoch 185/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 56.7871 - ler: 0.4505 - val_loss: 55.3746 - val_ler: 0.4357\n",
      "\n",
      "Epoch 00185: ler improved from 0.45601 to 0.45045, saving model to ../models/RNN.h5\n",
      "Epoch 186/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 56.6628 - ler: 0.4541 - val_loss: 55.4940 - val_ler: 0.4433\n",
      "\n",
      "Epoch 00186: ler did not improve from 0.45045\n",
      "Epoch 187/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 58.9207 - ler: 0.4564 - val_loss: 55.5080 - val_ler: 0.4378\n",
      "\n",
      "Epoch 00187: ler did not improve from 0.45045\n",
      "Epoch 188/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 56.8071 - ler: 0.4453 - val_loss: 55.0873 - val_ler: 0.4399\n",
      "\n",
      "Epoch 00188: ler improved from 0.45045 to 0.44534, saving model to ../models/RNN.h5\n",
      "Epoch 189/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 56.2802 - ler: 0.4443 - val_loss: 54.8287 - val_ler: 0.4300\n",
      "\n",
      "Epoch 00189: ler improved from 0.44534 to 0.44429, saving model to ../models/RNN.h5\n",
      "Epoch 190/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 54.7148 - ler: 0.4484 - val_loss: 54.7589 - val_ler: 0.4295\n",
      "\n",
      "Epoch 00190: ler did not improve from 0.44429\n",
      "Epoch 191/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 56.5955 - ler: 0.4518 - val_loss: 54.9641 - val_ler: 0.4334\n",
      "\n",
      "Epoch 00191: ler did not improve from 0.44429\n",
      "Epoch 192/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 57.3244 - ler: 0.4466 - val_loss: 54.5890 - val_ler: 0.4352\n",
      "\n",
      "Epoch 00192: ler did not improve from 0.44429\n",
      "Epoch 193/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 55.6530 - ler: 0.4408 - val_loss: 54.4685 - val_ler: 0.4267\n",
      "\n",
      "Epoch 00193: ler improved from 0.44429 to 0.44076, saving model to ../models/RNN.h5\n",
      "Epoch 194/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 55.2101 - ler: 0.4396 - val_loss: 53.5686 - val_ler: 0.4233\n",
      "\n",
      "Epoch 00194: ler improved from 0.44076 to 0.43961, saving model to ../models/RNN.h5\n",
      "Epoch 195/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 54.9809 - ler: 0.4375 - val_loss: 53.0760 - val_ler: 0.4179\n",
      "\n",
      "Epoch 00195: ler improved from 0.43961 to 0.43750, saving model to ../models/RNN.h5\n",
      "Epoch 196/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 54.4305 - ler: 0.4298 - val_loss: 52.9706 - val_ler: 0.4221\n",
      "\n",
      "Epoch 00196: ler improved from 0.43750 to 0.42975, saving model to ../models/RNN.h5\n",
      "Epoch 197/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 54.5513 - ler: 0.4377 - val_loss: 53.0297 - val_ler: 0.4234\n",
      "\n",
      "Epoch 00197: ler did not improve from 0.42975\n",
      "Epoch 198/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 54.2549 - ler: 0.4264 - val_loss: 51.5579 - val_ler: 0.4026\n",
      "\n",
      "Epoch 00198: ler improved from 0.42975 to 0.42637, saving model to ../models/RNN.h5\n",
      "Epoch 199/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 52.9510 - ler: 0.4192 - val_loss: 51.3762 - val_ler: 0.4057\n",
      "\n",
      "Epoch 00199: ler improved from 0.42637 to 0.41917, saving model to ../models/RNN.h5\n",
      "Epoch 200/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 52.7368 - ler: 0.4158 - val_loss: 51.8264 - val_ler: 0.4044\n",
      "\n",
      "Epoch 00200: ler improved from 0.41917 to 0.41583, saving model to ../models/RNN.h5\n",
      "Epoch 201/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 52.0117 - ler: 0.4237 - val_loss: 51.5646 - val_ler: 0.4089\n",
      "\n",
      "Epoch 00201: ler did not improve from 0.41583\n",
      "Epoch 202/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 53.4938 - ler: 0.4166 - val_loss: 51.0289 - val_ler: 0.3950\n",
      "\n",
      "Epoch 00202: ler did not improve from 0.41583\n",
      "Epoch 203/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 52.3054 - ler: 0.4149 - val_loss: 50.7695 - val_ler: 0.3988\n",
      "\n",
      "Epoch 00203: ler improved from 0.41583 to 0.41490, saving model to ../models/RNN.h5\n",
      "Epoch 204/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 52.1115 - ler: 0.4125 - val_loss: 50.8201 - val_ler: 0.3962\n",
      "\n",
      "Epoch 00204: ler improved from 0.41490 to 0.41253, saving model to ../models/RNN.h5\n",
      "Epoch 205/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 52.2806 - ler: 0.4117 - val_loss: 50.6818 - val_ler: 0.3895\n",
      "\n",
      "Epoch 00205: ler improved from 0.41253 to 0.41168, saving model to ../models/RNN.h5\n",
      "Epoch 206/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 51.6400 - ler: 0.4097 - val_loss: 50.6701 - val_ler: 0.3996\n",
      "\n",
      "Epoch 00206: ler improved from 0.41168 to 0.40969, saving model to ../models/RNN.h5\n",
      "Epoch 207/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 52.8984 - ler: 0.4186 - val_loss: 50.1785 - val_ler: 0.3956\n",
      "\n",
      "Epoch 00207: ler did not improve from 0.40969\n",
      "Epoch 208/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 50.4807 - ler: 0.4109 - val_loss: 49.8805 - val_ler: 0.3921\n",
      "\n",
      "Epoch 00208: ler did not improve from 0.40969\n",
      "Epoch 209/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 51.2489 - ler: 0.4068 - val_loss: 48.6480 - val_ler: 0.3825\n",
      "\n",
      "Epoch 00209: ler improved from 0.40969 to 0.40676, saving model to ../models/RNN.h5\n",
      "Epoch 210/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 50.7374 - ler: 0.4005 - val_loss: 49.2679 - val_ler: 0.3866\n",
      "\n",
      "Epoch 00210: ler improved from 0.40676 to 0.40050, saving model to ../models/RNN.h5\n",
      "Epoch 211/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 50.1097 - ler: 0.3997 - val_loss: 49.8670 - val_ler: 0.3948\n",
      "\n",
      "Epoch 00211: ler improved from 0.40050 to 0.39966, saving model to ../models/RNN.h5\n",
      "Epoch 212/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 51.2801 - ler: 0.4131 - val_loss: 49.0746 - val_ler: 0.3799\n",
      "\n",
      "Epoch 00212: ler did not improve from 0.39966\n",
      "Epoch 213/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 51.1443 - ler: 0.3994 - val_loss: 48.1742 - val_ler: 0.3785\n",
      "\n",
      "Epoch 00213: ler improved from 0.39966 to 0.39940, saving model to ../models/RNN.h5\n",
      "Epoch 214/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 50.3141 - ler: 0.3922 - val_loss: 48.3246 - val_ler: 0.3821\n",
      "\n",
      "Epoch 00214: ler improved from 0.39940 to 0.39218, saving model to ../models/RNN.h5\n",
      "Epoch 215/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 46.7787 - ler: 0.3906 - val_loss: 47.2490 - val_ler: 0.3684\n",
      "\n",
      "Epoch 00215: ler improved from 0.39218 to 0.39057, saving model to ../models/RNN.h5\n",
      "Epoch 216/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 47.3717 - ler: 0.3861 - val_loss: 46.8858 - val_ler: 0.3708\n",
      "\n",
      "Epoch 00216: ler improved from 0.39057 to 0.38608, saving model to ../models/RNN.h5\n",
      "Epoch 217/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 49.3152 - ler: 0.3841 - val_loss: 46.6349 - val_ler: 0.3674\n",
      "\n",
      "Epoch 00217: ler improved from 0.38608 to 0.38409, saving model to ../models/RNN.h5\n",
      "Epoch 218/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 47.0286 - ler: 0.3868 - val_loss: 47.4648 - val_ler: 0.3762\n",
      "\n",
      "Epoch 00218: ler did not improve from 0.38409\n",
      "Epoch 219/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 49.3507 - ler: 0.3912 - val_loss: 48.4066 - val_ler: 0.3913\n",
      "\n",
      "Epoch 00219: ler did not improve from 0.38409\n",
      "Epoch 220/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 48.6826 - ler: 0.3892 - val_loss: 46.3014 - val_ler: 0.3670\n",
      "\n",
      "Epoch 00220: ler did not improve from 0.38409\n",
      "Epoch 221/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 46.9889 - ler: 0.3840 - val_loss: 46.0845 - val_ler: 0.3599\n",
      "\n",
      "Epoch 00221: ler improved from 0.38409 to 0.38397, saving model to ../models/RNN.h5\n",
      "Epoch 222/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 48.7364 - ler: 0.3757 - val_loss: 46.2412 - val_ler: 0.3648\n",
      "\n",
      "Epoch 00222: ler improved from 0.38397 to 0.37571, saving model to ../models/RNN.h5\n",
      "Epoch 223/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 47.1969 - ler: 0.3764 - val_loss: 45.6085 - val_ler: 0.3591\n",
      "\n",
      "Epoch 00223: ler did not improve from 0.37571\n",
      "Epoch 224/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 48.0239 - ler: 0.3754 - val_loss: 45.6239 - val_ler: 0.3473\n",
      "\n",
      "Epoch 00224: ler improved from 0.37571 to 0.37543, saving model to ../models/RNN.h5\n",
      "Epoch 225/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 46.8329 - ler: 0.3702 - val_loss: 45.9990 - val_ler: 0.3648\n",
      "\n",
      "Epoch 00225: ler improved from 0.37543 to 0.37020, saving model to ../models/RNN.h5\n",
      "Epoch 226/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 46.5752 - ler: 0.3742 - val_loss: 46.1847 - val_ler: 0.3609\n",
      "\n",
      "Epoch 00226: ler did not improve from 0.37020\n",
      "Epoch 227/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 45.1625 - ler: 0.3669 - val_loss: 44.1623 - val_ler: 0.3554\n",
      "\n",
      "Epoch 00227: ler improved from 0.37020 to 0.36689, saving model to ../models/RNN.h5\n",
      "Epoch 228/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 46.5206 - ler: 0.3670 - val_loss: 44.6063 - val_ler: 0.3484\n",
      "\n",
      "Epoch 00228: ler did not improve from 0.36689\n",
      "Epoch 229/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 45.9596 - ler: 0.3592 - val_loss: 43.6888 - val_ler: 0.3388\n",
      "\n",
      "Epoch 00229: ler improved from 0.36689 to 0.35916, saving model to ../models/RNN.h5\n",
      "Epoch 230/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 45.6781 - ler: 0.3599 - val_loss: 43.6038 - val_ler: 0.3348\n",
      "\n",
      "Epoch 00230: ler did not improve from 0.35916\n",
      "Epoch 231/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 45.4051 - ler: 0.3595 - val_loss: 44.2489 - val_ler: 0.3467\n",
      "\n",
      "Epoch 00231: ler did not improve from 0.35916\n",
      "Epoch 232/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 46.2344 - ler: 0.3554 - val_loss: 43.5176 - val_ler: 0.3362\n",
      "\n",
      "Epoch 00232: ler improved from 0.35916 to 0.35543, saving model to ../models/RNN.h5\n",
      "Epoch 233/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 44.6043 - ler: 0.3540 - val_loss: 42.7843 - val_ler: 0.3327\n",
      "\n",
      "Epoch 00233: ler improved from 0.35543 to 0.35402, saving model to ../models/RNN.h5\n",
      "Epoch 234/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 42.8022 - ler: 0.3491 - val_loss: 43.3213 - val_ler: 0.3353\n",
      "\n",
      "Epoch 00234: ler improved from 0.35402 to 0.34913, saving model to ../models/RNN.h5\n",
      "Epoch 235/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 43.2099 - ler: 0.3511 - val_loss: 43.0709 - val_ler: 0.3324\n",
      "\n",
      "Epoch 00235: ler did not improve from 0.34913\n",
      "Epoch 236/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 42.4100 - ler: 0.3478 - val_loss: 42.0886 - val_ler: 0.3265\n",
      "\n",
      "Epoch 00236: ler improved from 0.34913 to 0.34784, saving model to ../models/RNN.h5\n",
      "Epoch 237/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 44.2050 - ler: 0.3415 - val_loss: 43.1449 - val_ler: 0.3405\n",
      "\n",
      "Epoch 00237: ler improved from 0.34784 to 0.34150, saving model to ../models/RNN.h5\n",
      "Epoch 238/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 43.8382 - ler: 0.3480 - val_loss: 42.0855 - val_ler: 0.3297\n",
      "\n",
      "Epoch 00238: ler did not improve from 0.34150\n",
      "Epoch 239/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 43.3952 - ler: 0.3392 - val_loss: 41.4678 - val_ler: 0.3229\n",
      "\n",
      "Epoch 00239: ler improved from 0.34150 to 0.33924, saving model to ../models/RNN.h5\n",
      "Epoch 240/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 42.7277 - ler: 0.3374 - val_loss: 41.5175 - val_ler: 0.3263\n",
      "\n",
      "Epoch 00240: ler improved from 0.33924 to 0.33735, saving model to ../models/RNN.h5\n",
      "Epoch 241/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 42.8436 - ler: 0.3418 - val_loss: 41.4821 - val_ler: 0.3303\n",
      "\n",
      "Epoch 00241: ler did not improve from 0.33735\n",
      "Epoch 242/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 44.2608 - ler: 0.3398 - val_loss: 41.3558 - val_ler: 0.3226\n",
      "\n",
      "Epoch 00242: ler did not improve from 0.33735\n",
      "Epoch 243/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 42.2979 - ler: 0.3397 - val_loss: 40.8053 - val_ler: 0.3107\n",
      "\n",
      "Epoch 00243: ler did not improve from 0.33735\n",
      "Epoch 244/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 43.6484 - ler: 0.3371 - val_loss: 40.8461 - val_ler: 0.3231\n",
      "\n",
      "Epoch 00244: ler improved from 0.33735 to 0.33705, saving model to ../models/RNN.h5\n",
      "Epoch 245/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 42.9155 - ler: 0.3466 - val_loss: 41.4440 - val_ler: 0.3219\n",
      "\n",
      "Epoch 00245: ler did not improve from 0.33705\n",
      "Epoch 246/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 43.0676 - ler: 0.3369 - val_loss: 40.6270 - val_ler: 0.3215\n",
      "\n",
      "Epoch 00246: ler improved from 0.33705 to 0.33693, saving model to ../models/RNN.h5\n",
      "Epoch 247/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 40.9307 - ler: 0.3344 - val_loss: 40.1697 - val_ler: 0.3122\n",
      "\n",
      "Epoch 00247: ler improved from 0.33693 to 0.33435, saving model to ../models/RNN.h5\n",
      "Epoch 248/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 41.9867 - ler: 0.3247 - val_loss: 40.0525 - val_ler: 0.3132\n",
      "\n",
      "Epoch 00248: ler improved from 0.33435 to 0.32465, saving model to ../models/RNN.h5\n",
      "Epoch 249/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 40.5191 - ler: 0.3220 - val_loss: 39.3247 - val_ler: 0.3039\n",
      "\n",
      "Epoch 00249: ler improved from 0.32465 to 0.32201, saving model to ../models/RNN.h5\n",
      "Epoch 250/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 40.7180 - ler: 0.3191 - val_loss: 39.6328 - val_ler: 0.3153\n",
      "\n",
      "Epoch 00250: ler improved from 0.32201 to 0.31909, saving model to ../models/RNN.h5\n",
      "Epoch 251/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 40.9861 - ler: 0.3357 - val_loss: 41.7813 - val_ler: 0.3275\n",
      "\n",
      "Epoch 00251: ler did not improve from 0.31909\n",
      "Epoch 252/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 43.0661 - ler: 0.3519 - val_loss: 42.4431 - val_ler: 0.3419\n",
      "\n",
      "Epoch 00252: ler did not improve from 0.31909\n",
      "Epoch 253/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 42.8337 - ler: 0.3440 - val_loss: 40.9495 - val_ler: 0.3226\n",
      "\n",
      "Epoch 00253: ler did not improve from 0.31909\n",
      "Epoch 254/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 43.1273 - ler: 0.3398 - val_loss: 40.7273 - val_ler: 0.3093\n",
      "\n",
      "Epoch 00254: ler did not improve from 0.31909\n",
      "Epoch 255/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 41.1538 - ler: 0.3256 - val_loss: 39.2115 - val_ler: 0.3003\n",
      "\n",
      "Epoch 00255: ler did not improve from 0.31909\n",
      "Epoch 256/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 40.7457 - ler: 0.3219 - val_loss: 39.0418 - val_ler: 0.3100\n",
      "\n",
      "Epoch 00256: ler did not improve from 0.31909\n",
      "Epoch 257/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 40.6704 - ler: 0.3237 - val_loss: 39.5925 - val_ler: 0.3024\n",
      "\n",
      "Epoch 00257: ler did not improve from 0.31909\n",
      "Epoch 258/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 40.6783 - ler: 0.3195 - val_loss: 39.0978 - val_ler: 0.3119\n",
      "\n",
      "Epoch 00258: ler did not improve from 0.31909\n",
      "Epoch 259/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 40.9350 - ler: 0.3179 - val_loss: 37.9667 - val_ler: 0.2924\n",
      "\n",
      "Epoch 00259: ler improved from 0.31909 to 0.31785, saving model to ../models/RNN.h5\n",
      "Epoch 260/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 39.0643 - ler: 0.3148 - val_loss: 37.8121 - val_ler: 0.2921\n",
      "\n",
      "Epoch 00260: ler improved from 0.31785 to 0.31484, saving model to ../models/RNN.h5\n",
      "Epoch 261/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 41.0912 - ler: 0.3182 - val_loss: 38.1057 - val_ler: 0.2939\n",
      "\n",
      "Epoch 00261: ler did not improve from 0.31484\n",
      "Epoch 262/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 38.7040 - ler: 0.3138 - val_loss: 37.3791 - val_ler: 0.2882\n",
      "\n",
      "Epoch 00262: ler improved from 0.31484 to 0.31380, saving model to ../models/RNN.h5\n",
      "Epoch 263/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 39.0774 - ler: 0.3069 - val_loss: 37.4678 - val_ler: 0.2920\n",
      "\n",
      "Epoch 00263: ler improved from 0.31380 to 0.30694, saving model to ../models/RNN.h5\n",
      "Epoch 264/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 38.3464 - ler: 0.3058 - val_loss: 37.1758 - val_ler: 0.2872\n",
      "\n",
      "Epoch 00264: ler improved from 0.30694 to 0.30584, saving model to ../models/RNN.h5\n",
      "Epoch 265/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 38.1460 - ler: 0.3095 - val_loss: 37.8324 - val_ler: 0.2909\n",
      "\n",
      "Epoch 00265: ler did not improve from 0.30584\n",
      "Epoch 266/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 39.0783 - ler: 0.3096 - val_loss: 37.5133 - val_ler: 0.2914\n",
      "\n",
      "Epoch 00266: ler did not improve from 0.30584\n",
      "Epoch 267/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 39.3484 - ler: 0.3060 - val_loss: 37.5646 - val_ler: 0.2861\n",
      "\n",
      "Epoch 00267: ler did not improve from 0.30584\n",
      "Epoch 268/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 38.7266 - ler: 0.3020 - val_loss: 36.9716 - val_ler: 0.2842\n",
      "\n",
      "Epoch 00268: ler improved from 0.30584 to 0.30197, saving model to ../models/RNN.h5\n",
      "Epoch 269/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 38.1810 - ler: 0.2950 - val_loss: 36.2502 - val_ler: 0.2809\n",
      "\n",
      "Epoch 00269: ler improved from 0.30197 to 0.29498, saving model to ../models/RNN.h5\n",
      "Epoch 270/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 37.3975 - ler: 0.2909 - val_loss: 35.6795 - val_ler: 0.2763\n",
      "\n",
      "Epoch 00270: ler improved from 0.29498 to 0.29093, saving model to ../models/RNN.h5\n",
      "Epoch 271/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 37.6742 - ler: 0.2891 - val_loss: 36.3674 - val_ler: 0.2837\n",
      "\n",
      "Epoch 00271: ler improved from 0.29093 to 0.28915, saving model to ../models/RNN.h5\n",
      "Epoch 272/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 37.9304 - ler: 0.3068 - val_loss: 37.5495 - val_ler: 0.2944\n",
      "\n",
      "Epoch 00272: ler did not improve from 0.28915\n",
      "Epoch 273/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 40.5606 - ler: 0.3161 - val_loss: 37.6093 - val_ler: 0.2857\n",
      "\n",
      "Epoch 00273: ler did not improve from 0.28915\n",
      "Epoch 274/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 38.4226 - ler: 0.3104 - val_loss: 36.8657 - val_ler: 0.2885\n",
      "\n",
      "Epoch 00274: ler did not improve from 0.28915\n",
      "Epoch 275/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 38.1055 - ler: 0.3007 - val_loss: 36.1141 - val_ler: 0.2799\n",
      "\n",
      "Epoch 00275: ler did not improve from 0.28915\n",
      "Epoch 276/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 37.8150 - ler: 0.2995 - val_loss: 36.2223 - val_ler: 0.2807\n",
      "\n",
      "Epoch 00276: ler did not improve from 0.28915\n",
      "Epoch 277/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 36.9549 - ler: 0.2899 - val_loss: 35.0569 - val_ler: 0.2700\n",
      "\n",
      "Epoch 00277: ler did not improve from 0.28915\n",
      "Epoch 278/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 35.4431 - ler: 0.2818 - val_loss: 34.5021 - val_ler: 0.2622\n",
      "\n",
      "Epoch 00278: ler improved from 0.28915 to 0.28181, saving model to ../models/RNN.h5\n",
      "Epoch 279/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 35.8599 - ler: 0.2836 - val_loss: 34.9286 - val_ler: 0.2656\n",
      "\n",
      "Epoch 00279: ler did not improve from 0.28181\n",
      "Epoch 280/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 36.9565 - ler: 0.2897 - val_loss: 35.2657 - val_ler: 0.2727\n",
      "\n",
      "Epoch 00280: ler did not improve from 0.28181\n",
      "Epoch 281/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 36.4972 - ler: 0.2788 - val_loss: 34.5186 - val_ler: 0.2621\n",
      "\n",
      "Epoch 00281: ler improved from 0.28181 to 0.27878, saving model to ../models/RNN.h5\n",
      "Epoch 282/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 36.3969 - ler: 0.2763 - val_loss: 34.0846 - val_ler: 0.2624\n",
      "\n",
      "Epoch 00282: ler improved from 0.27878 to 0.27628, saving model to ../models/RNN.h5\n",
      "Epoch 283/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 34.6392 - ler: 0.2690 - val_loss: 33.4241 - val_ler: 0.2537\n",
      "\n",
      "Epoch 00283: ler improved from 0.27628 to 0.26898, saving model to ../models/RNN.h5\n",
      "Epoch 284/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 35.2184 - ler: 0.2654 - val_loss: 33.4317 - val_ler: 0.2531\n",
      "\n",
      "Epoch 00284: ler improved from 0.26898 to 0.26542, saving model to ../models/RNN.h5\n",
      "Epoch 285/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 34.1270 - ler: 0.2652 - val_loss: 33.1117 - val_ler: 0.2538\n",
      "\n",
      "Epoch 00285: ler improved from 0.26542 to 0.26517, saving model to ../models/RNN.h5\n",
      "Epoch 286/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 34.3207 - ler: 0.2685 - val_loss: 33.1368 - val_ler: 0.2483\n",
      "\n",
      "Epoch 00286: ler did not improve from 0.26517\n",
      "Epoch 287/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 35.1288 - ler: 0.2739 - val_loss: 33.2491 - val_ler: 0.2532\n",
      "\n",
      "Epoch 00287: ler did not improve from 0.26517\n",
      "Epoch 288/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 34.5427 - ler: 0.2680 - val_loss: 33.2381 - val_ler: 0.2503\n",
      "\n",
      "Epoch 00288: ler did not improve from 0.26517\n",
      "Epoch 289/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 34.8283 - ler: 0.2745 - val_loss: 33.8865 - val_ler: 0.2568\n",
      "\n",
      "Epoch 00289: ler did not improve from 0.26517\n",
      "Epoch 290/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 38.3433 - ler: 0.3124 - val_loss: 37.3274 - val_ler: 0.3001\n",
      "\n",
      "Epoch 00290: ler did not improve from 0.26517\n",
      "Epoch 291/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 39.3628 - ler: 0.3143 - val_loss: 36.3590 - val_ler: 0.2841\n",
      "\n",
      "Epoch 00291: ler did not improve from 0.26517\n",
      "Epoch 292/300\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 36.9251 - ler: 0.2864 - val_loss: 33.8599 - val_ler: 0.2625\n",
      "\n",
      "Epoch 00292: ler did not improve from 0.26517\n",
      "Epoch 293/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 34.9791 - ler: 0.2696 - val_loss: 33.3504 - val_ler: 0.2547\n",
      "\n",
      "Epoch 00293: ler did not improve from 0.26517\n",
      "Epoch 294/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 34.5426 - ler: 0.2702 - val_loss: 33.3358 - val_ler: 0.2535\n",
      "\n",
      "Epoch 00294: ler did not improve from 0.26517\n",
      "Epoch 295/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 34.0473 - ler: 0.2728 - val_loss: 33.3876 - val_ler: 0.2573\n",
      "\n",
      "Epoch 00295: ler did not improve from 0.26517\n",
      "Epoch 296/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 34.8251 - ler: 0.2709 - val_loss: 33.0002 - val_ler: 0.2484\n",
      "\n",
      "Epoch 00296: ler did not improve from 0.26517\n",
      "Epoch 297/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 35.1505 - ler: 0.2801 - val_loss: 33.4155 - val_ler: 0.2517\n",
      "\n",
      "Epoch 00297: ler did not improve from 0.26517\n",
      "Epoch 298/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 34.8927 - ler: 0.2687 - val_loss: 32.2690 - val_ler: 0.2389\n",
      "\n",
      "Epoch 00298: ler did not improve from 0.26517\n",
      "Epoch 299/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 34.4867 - ler: 0.2604 - val_loss: 31.9934 - val_ler: 0.2369\n",
      "\n",
      "Epoch 00299: ler improved from 0.26517 to 0.26039, saving model to ../models/RNN.h5\n",
      "Epoch 300/300\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 33.6551 - ler: 0.2591 - val_loss: 32.0820 - val_ler: 0.2436\n",
      "\n",
      "Epoch 00300: ler improved from 0.26039 to 0.25907, saving model to ../models/RNN.h5\n"
     ]
    }
   ],
   "source": [
    "# Compile Training Model with selected optimizer\n",
    "optimizer = tf.keras.optimizers.SGD(initial_learning_rate, momentum)\n",
    "model_train.compile(optimizer=optimizer)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='../models/'+\"RNN\"+'.h5',monitor='ler',verbose=1, save_best_only=True, mode='min')\n",
    "# ModelCheckpoint(filepath='../models/'+\"RNN\"+'.h5', verbose=0,)\n",
    "\n",
    "# Training, Our y is already defined so no need# mlflow.tensorflow.autolog()\n",
    "history = model_train.fit(x=[train_inputs, train_targets, train_seq_len, train_targets_len], y=None,\n",
    "                validation_data=([val_inputs, val_targets, val_seq_len, val_targets_len], None),\n",
    "                batch_size=batch_size, epochs=300,callbacks=[checkpointer])\n",
    "\n",
    "# try:\n",
    "#     experiment_id = mlflow.create_experiment(\"Stacked RNN(LSTM): 50 Cells\")\n",
    "#     experiment = mlflow.get_experiment(experiment_id)\n",
    "# except mlflow.exceptions.MlflowException:\n",
    "#     experiment = mlflow.get_experiment_by_name(\"Stacked RNN(LSTM): 50 Cells\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3297fc44-8655-439d-8442-87b8905793fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'ler', 'val_loss', 'val_ler'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAwhklEQVR4nO3deXhV5bn+8e+zM5MBAoQxQAjzpMwqOIDzVHGsemwrtT+1ra1VO6g9baX1WK3H2tZT7amtVk+roq3VUmfFAWdkVEZFAQlggAhkgEx7P78/9iIGEkIYdnaSfX+uK1f2XtN+Fovkzvuutd5l7o6IiAhAKN4FiIhI66FQEBGROgoFERGpo1AQEZE6CgUREamjUBARkToKBZH9ZGYPmNl/NXPZNWZ2YqxrEjlUFAoicbI/4SLSUhQKIiJSR6Eg7VLQbfNDM3vfzCrM7D4z625mz5pZmZm9ZGa59ZY/y8yWmtk2M3vVzIbVmzfGzBYE6z0KpO/xWWea2aJg3bfM7LBDUP/lZrbKzD43s1lm1iuYbmb2GzPbZGbbg/0bGcw73cyWBXWuN7MfHGwdkngUCtKenQecBAwGvgQ8C/wY6Er0//7VAGY2GHgEuAbIA54B/m1mqWaWCjwJ/BXoDPw92C7BumOB+4ErgS7AH4FZZpZ2oEWb2fHArcCXgZ7AWmBmMPtk4NhgnzoBFwIlwbz7gCvdPRsYCbx8oDVI4lIoSHv2P+5e7O7rgdeBd919obtXAU8AY4LlLgSedvcX3b0GuAPIACYBRwIpwG/dvcbd/wG8V+8zLgf+6O7vunvY3R8EqoL1DtQlwP3uviCo9UbgKDMrAGqAbGAoYO6+3N03BuvVAMPNLMfdt7r7goOoQRKUQkHas+J6r3c28j4reN2L6F/jALh7BFgH9A7mrffdR45cW+91P+D7QdfRNjPbBvQJ1jtQe9ZTTrQ10NvdXwZ+D9wNFJvZvWaWEyx6HnA6sNbMXjOzow6iBklQCgUR2ED0lzsQ7bcn+ot9PbAR6B1M26VvvdfrgFvcvVO9rw7u/sghrCeTaNfUegB3v8vdxwEjiHYj/TCY/p67TwO6Ee3yeuwgapAEpVAQif7yPMPMTjCzFOD7RLuA3gLeBmqBq80s2czOBSbWW/dPwDfN7IjgJHCmmZ1hZtnN/OwkM0uv95UKPAx83cxGB+cmfkm062uNmU0IPisFqAAqgXBw/uMSM+sYdIGVAuGD/6eRRKNQkITn7iuBrwD/A2whelL6S+5e7e7VwLnAdGAr0fMP/6y37jyi5xV+H8xfFSzbXDcQ7cra9fWyu88Gfgo8TrSlMgC4KFg+h2gQbSXaxVRC9BwIwFeBNWZWCnwz2CeR/WJ6yI6IiOyiloKIiNRRKIiISB2FgoiI1FEoiIhIneR4F3Awunbt6gUFBfEuQ0SkTZk/f/4Wd89rbF6bDoWCggLmzZsX7zJERNoUM1u7t3nqPhIRkToKBRERqaNQEBGROm36nEJjampqKCoqorKyMt6lyH5IT08nPz+flJSUeJciktDaXSgUFRWRnZ1NQUEBuw9sKa2Vu1NSUkJRURH9+/ePdzkiCa3ddR9VVlbSpUsXBUIbYmZ06dJFrTuRVqDdhQKgQGiDdMxEWod2GQr7Ul0b4bPtlVTVaLh5EZH6EjIUaiMRNpVVUlUbOeTbLikpYfTo0YwePZoePXrQu3fvuvfV1dVNrjtv3jyuvvrqfX7GpEmTDkmtr776KmeeeeYh2ZaItA/t7kRzvHXp0oVFixYBMGPGDLKysvjBD35QN7+2tpbk5Mb/2cePH8/48eP3+RlvvfXWIalVRGRPMWspBI8WnGtmi81sqZn9PJje2cxeNLOPgu+59da50cxWmdlKMzslZrUF31vq8ULTp0/nuuuuY+rUqVx//fXMnTuXSZMmMWbMGCZNmsTKlSuB3f9ynzFjBpdddhlTpkyhsLCQu+66q257WVlZdctPmTKF888/n6FDh3LJJZew66FJzzzzDEOHDuXoo4/m6quv3q8WwSOPPMKoUaMYOXIk119/PQDhcJjp06czcuRIRo0axW9+8xsA7rrrLoYPH85hhx3GRRdd1NRmRaQNiGVLoQo43t3Lg+fJvmFmzxJ9tOFsd7/NzG4g+jjC681sONFHDo4AegEvmdlgdz/gjv+f/3spyzaUNpgecWdndZj0lCSSQvt3gnN4rxxu+tKI/a7lww8/5KWXXiIpKYnS0lLmzJlDcnIyL730Ej/+8Y95/PHHG6yzYsUKXnnlFcrKyhgyZAjf+ta3GlzHv3DhQpYuXUqvXr2YPHkyb775JuPHj+fKK69kzpw59O/fn4svvrjZdW7YsIHrr7+e+fPnk5uby8knn8yTTz5Jnz59WL9+PUuWLAFg27ZtANx2222sXr2atLS0umki0nbFrKXgUeXB25Tgy4FpwIPB9AeBs4PX04CZ7l7l7quJPuu2/gPS27QLLriApKQkALZv384FF1zAyJEjufbaa1m6dGmj65xxxhmkpaXRtWtXunXrRnFxcYNlJk6cSH5+PqFQiNGjR7NmzRpWrFhBYWFh3TX/+xMK7733HlOmTCEvL4/k5GQuueQS5syZQ2FhIZ988gnf/e53ee6558jJyQHgsMMO45JLLuFvf/vbXrvFRKTtiOlPsZklAfOBgcDd7v6umXV3940A7r7RzLoFi/cG3qm3elEwbc9tXgFcAdC3b98mP39vf9FX1oT5sLiMvp070KlD6v7t1AHKzMyse/3Tn/6UqVOn8sQTT7BmzRqmTJnS6DppaWl1r5OSkqitrW3WMgfz3O29rZubm8vixYt5/vnnufvuu3nssce4//77efrpp5kzZw6zZs3i5ptvZunSpQoHkTYsplcfuXvY3UcD+cBEMxvZxOKN9eM0+A3l7ve6+3h3H5+X1+hw4K3e9u3b6d07mncPPPDAId/+0KFD+eSTT1izZg0Ajz76aLPXPeKII3jttdfYsmUL4XCYRx55hOOOO44tW7YQiUQ477zzuPnmm1mwYAGRSIR169YxdepUbr/9drZt20Z5efm+P0REWq0W+ZPO3beZ2avAqUCxmfUMWgk9gU3BYkVAn3qr5QMbYlFPvG+T+tGPfsSll17KnXfeyfHHH3/It5+RkcE999zDqaeeSteuXZk4ce+9cLNnzyY/P7/u/d///nduvfVWpk6dirtz+umnM23aNBYvXszXv/51IpHoZby33nor4XCYr3zlK2zfvh1359prr6VTp06HfH9EpOXYwXQ1NLlhszygJgiEDOAF4FfAcUBJvRPNnd39R2Y2AniY6HmEXsBsYFBTJ5rHjx/vez5kZ/ny5QwbNqzJ2qpqwqwsLqNPbgdyM1um+6illZeXk5WVhbtz1VVXMWjQIK699tp4l9Wk5hw7ETl4Zjbf3Ru9/j2WLYWewIPBeYUQ8Ji7P2VmbwOPmdk3gE+BCwDcfamZPQYsA2qBqw7myqOm7BpRoaUuSY2HP/3pTzz44INUV1czZswYrrzyyniXJCJtQMxaCi3hQFsK1bVhVnxWRn5uBzq305ZCW6SWgkjLaKqlkJDDXLT87WsiIm1DQoaCIkFEpHEJGQpKBRGRxiVmKIiISKMSMhRi2VCYMmUKzz///G7Tfvvb3/Ltb3+7yXV2nTA//fTTGx1DaMaMGdxxxx1NfvaTTz7JsmXL6t7/7Gc/46WXXtqP6hunIbZFEkdChkIsXXzxxcycOXO3aTNnzmz2+EPPPPPMAd8Atmco/OIXv+DEE088oG2JSGJKzFDYdZ9CDJoK559/Pk899RRVVVUArFmzhg0bNnD00UfzrW99i/HjxzNixAhuuummRtcvKChgy5YtANxyyy0MGTKEE088sW54bYjegzBhwgQOP/xwzjvvPHbs2MFbb73FrFmz+OEPf8jo0aP5+OOPmT59Ov/4xz+A6J3LY8aMYdSoUVx22WV19RUUFHDTTTcxduxYRo0axYoVK5q9rxpiW6T9ad8jlz17A3z2QYPJSTiFVWFSk0OQtJ+52GMUnHbbXmd36dKFiRMn8txzzzFt2jRmzpzJhRdeiJlxyy230LlzZ8LhMCeccALvv/8+hx12WKPbmT9/PjNnzmThwoXU1tYyduxYxo0bB8C5557L5ZdfDsBPfvIT7rvvPr773e9y1llnceaZZ3L++efvtq3KykqmT5/O7NmzGTx4MF/72tf4wx/+wDXXXANA165dWbBgAffccw933HEHf/7zn/f5z6AhtkXap8RsKcRY/S6k+l1Hjz32GGPHjmXMmDEsXbp0t66ePb3++uucc845dOjQgZycHM4666y6eUuWLOGYY45h1KhRPPTQQ3sdenuXlStX0r9/fwYPHgzApZdeypw5c+rmn3vuuQCMGzeubhC9fdEQ2yLtU/v+6dzLX/QecT7ZsJ0eHdPplp1+yD/27LPP5rrrrmPBggXs3LmTsWPHsnr1au644w7ee+89cnNzmT59OpWVlU1ux6zxofumT5/Ok08+yeGHH84DDzzAq6++2uR29nXX+q7ht/c2PPf+bFNDbIu0bYnZUojxfQpZWVlMmTKFyy67rK6VUFpaSmZmJh07dqS4uJhnn322yW0ce+yxPPHEE+zcuZOysjL+/e9/180rKyujZ8+e1NTU8NBDD9VNz87OpqysrMG2hg4dypo1a1i1ahUAf/3rXznuuOMOah81xLZI+6Q/1WLk4osv5txzz63rRjr88MMZM2YMI0aMoLCwkMmTJze5/tixY7nwwgsZPXo0/fr145hjjqmbd/PNN3PEEUfQr18/Ro0aVRcEF110EZdffjl33XVX3QlmgPT0dP7yl79wwQUXUFtby4QJE/jmN7+5X/ujIbZFEkNCDojn7nywfjvdc9LpnnPou4/kwGhAPJGWoQHxRESkWRIyFHadwG3DjSQRkZhol6HQnC4xi/tDOaW+ttyNKdKetLtQSE9Pp6SkZN+/ZAxcw6S2Cu5OSUkJ6ek6vyMSb+3u6qP8/HyKiorYvHlzk8sVb9tJRVoy2zJSWqgyaUp6evpuVzeJSHy0u1BISUmhf//++1zu3J8+x1eP6sePT9fVLiIiu7S77qPmChlEIuo+EhGpL4FDwVAmiIjsLnFDIWREdMWLiMhuEjcUDIWCiMgeEjgU1FIQEdlTwoaC6ZyCiEgDCRsKIdNdtCIie0rYUEgKGWE1FUREdhOzUDCzPmb2ipktN7OlZva9YPoMM1tvZouCr9PrrXOjma0ys5VmdkqsagNdkioi0phY3tFcC3zf3ReYWTYw38xeDOb9xt3vqL+wmQ0HLgJGAL2Al8xssLuHY1Gc6eojEZEGYtZScPeN7r4geF0GLAd6N7HKNGCmu1e5+2pgFTAxVvWFzDR0tojIHlrknIKZFQBjgHeDSd8xs/fN7H4zyw2m9QbW1VutiEZCxMyuMLN5ZjZvX4PeNUXnFEREGop5KJhZFvA4cI27lwJ/AAYAo4GNwK93LdrI6g1+a7v7ve4+3t3H5+XlHURd6j4SEdlTTEPBzFKIBsJD7v5PAHcvdvewu0eAP/FFF1ER0Kfe6vnAhljVpu4jEZGGYnn1kQH3Acvd/c5603vWW+wcYEnwehZwkZmlmVl/YBAwN1b1aZgLEZGGYnn10WTgq8AHZrYomPZj4GIzG020a2gNcCWAuy81s8eAZUSvXLoqVlcegYa5EBFpTMxCwd3foPHzBM80sc4twC2xqqm+kBnhSEt8kohI25GwdzSHQhrmQkRkT4kbCuo+EhFpIGFDQaOkiog0lLChkKSrj0REGkjYUFD3kYhIQ4kdCrr6SERkNwkbChrmQkSkoYQNBQ1zISLSUMKGQlJI5xRERPaUsKFgBmGFgojIbhI2FPQ4ThGRhhI4FDTMhYjInhI4FHROQURkT4kbCiGNkioisqfEDQV1H4mINJDAoaDuIxGRPSV4KMS7ChGR1iVxQ0E3r4mINJC4oWAQUVNBRGQ3CRwK6j4SEdlTwoaCRkkVEWkoYUNBo6SKiDSUsKGQpEtSRUQaSNhQCIUgrJMKIiK7SdhQMJ1oFhFpIGFDQcNciIg0lLChoHMKIiINxSwUzKyPmb1iZsvNbKmZfS+Y3tnMXjSzj4LvufXWudHMVpnZSjM7JVa1BZ+lcwoiInuIZUuhFvi+uw8DjgSuMrPhwA3AbHcfBMwO3hPMuwgYAZwK3GNmSbEqTpekiog0FLNQcPeN7r4geF0GLAd6A9OAB4PFHgTODl5PA2a6e5W7rwZWARNjVV9IN6+JiDTQIucUzKwAGAO8C3R3940QDQ6gW7BYb2BdvdWKgml7busKM5tnZvM2b958wDVFB8Q74NVFRNqlmIeCmWUBjwPXuHtpU4s2Mq3Br213v9fdx7v7+Ly8vAOuS89TEBFpKKahYGYpRAPhIXf/ZzC52Mx6BvN7ApuC6UVAn3qr5wMbYlWbuo9ERBqK5dVHBtwHLHf3O+vNmgVcGry+FPhXvekXmVmamfUHBgFzY1WfRkkVEWkoOYbbngx8FfjAzBYF034M3AY8ZmbfAD4FLgBw96Vm9hiwjOiVS1e5ezhWxamlICLSUMxCwd3foPHzBAAn7GWdW4BbYlVTfRZckuruRBs1IiKSuHc0h6JBoMaCiMgXEjYUgkwgrFQQEamTsKGwq8tI5xVERL6QsKEQMnUfiYjsKWFDISnYc7UURES+kLChEKrrPopzISIirUjChsKucwoaPltE5AsJGwq7rj7S09dERL7QrFAws0wzCwWvB5vZWcG4Rm2Wuo9ERBpqbkthDpBuZr2JPhjn68ADsSqqJYRCuiRVRGRPzQ0Fc/cdwLnA/7j7OcDw2JUVe7u6jyJqKoiI1Gl2KJjZUcAlwNPBtFgOphdz6j4SEWmouaFwDXAj8EQwmmkh8ErMqmoBdS0FdR+JiNRp1l/77v4a8BpAcMJ5i7tfHcvCYi2kYS5ERBpo7tVHD5tZjpllEn3ewUoz+2FsS4stDXMhItJQc7uPhgfPVz4beAboS/QBOm1WKNhz3bwmIvKF5oZCSnBfwtnAv9y9BmjTv03VfSQi0lBzQ+GPwBogE5hjZv2A0lgV1RJMVx+JiDTQ3BPNdwF31Zu01symxqaklpFUd05BqSAisktzTzR3NLM7zWxe8PVroq2GNuuLS1LjW4eISGvS3O6j+4Ey4MvBVynwl1gV1RI0SqqISEPNvSt5gLufV+/9z81sUQzqaTG6eU1EpKHmthR2mtnRu96Y2WRgZ2xKahlJId2nICKyp+a2FL4J/J+ZdQzebwUujU1JLUOXpIqINNTcq48WA4ebWU7wvtTMrgHej2FtMWXqPhIRaWC/nrzm7qXBnc0A18WgnhajloKISEMH8zhOO2RVxIGGzhYRaehgQqHJX6dmdr+ZbTKzJfWmzTCz9Wa2KPg6vd68G81slZmtNLNTDqKuZtk19pEesiMi8oUmzymYWRmN//I3IGMf234A+D3wf3tM/42737HH5wwHLgJGAL2Al8xssLuH9/EZB0wtBRGRhpoMBXfPPtANu/scMyto5uLTgJnuXgWsNrNVwETg7QP9/CZVlpK7/lUuSnoLrx0dk48QEWmLDqb76EB9x8zeD7qXcoNpvYF19ZYpCqY1YGZX7BpuY/PmzQdWwZYPGTL7Mm5L+TO56148sG2IiLRDLR0KfwAGAKOBjcCvg+mNnbRutGPH3e919/HuPj4vL+/Aqug+gg9PjvZqpZV9emDbEBFph1o0FNy92N3D7h4B/kS0iwiiLYM+9RbNBzbErJCUDHb0OY4tnkN6eVHMPkZEpK1p0VAws5713p4D7LoyaRZwkZmlmVl/YBAwN5a1hAyKPI/08nX7XlhEJEE0d5iL/WZmjwBTgK5mVgTcBEwxs9FEu4bWAFcCuPtSM3uM6POfa4GrYnnlEUSvPlrreQyuUEtBRGSXmIWCu1/cyOT7mlj+FuCWWNWzp245aczxbqRVzINIGEJJLfXRIiKtVjyuPmoVumWnQ6d+JHktlMbu9IWISFuSsKEA0KdwKABb1q2McyUiIq1DQofC6AnHsMPTKJ/1I6rLt8a7HBGRuEvoUOjTpx/vHXEX+dWrWXrvZXgkEu+SRETiKqFDAeC40y/ivYJvMqb0ZZ574oF4lyMiElcJHwoAR37tZrYmdyVt8V9ZtqF03yuIiLRTCgXAkpLJGPcfHBtaxJ+fjc0YfCIibYFCIZA+4WskE+Gw1X/mg6Lt8S5HRCQuFAq7dB1E1bgrmZ78Av9+5G6qamN6Q7WISKukUKgn7ZQZbOsylh9X/IpXfnUhC5auiHdJIiItKmbDXLRJqR3o9M1nWPPo9Uxd9TAlj53GH7IuhO4jOd7n0q9nHulHXQHZ3eNdqYhITJh7230e5fjx433evHkx2fbOTxdS+fDXyK2MPm+h2pNIMmdT5lA+H/E1eo88lk59R8Tks0VEYsnM5rv7+EbnKRSa4A7b1uLrF7I0NJAXXniG67b9EoDNnsOzPb7J5L4dyBx8LD06ZkJGJ8juEbt6REQOAYXCIVQ99y+s21ZFj7m3kVkbHRqj2pNItgg7knN5b/wd5I08gRG9O2LW2APlRETiS6EQC9UVbCxaw4bSSjq989+sqUhhaOnb9LbNrI50Z0tKL2q7j6JbVip9e3bDjvk+yck6hSMi8adQaCHVO0ope+9hdi59lh0lRQys/ZiQRf9950cGsTBjEvnDj2TC+COpze5Ft+w0tSZEpMUpFOIkUrKa11dtgY9eYMSGx+m642MAaj3E85HxbEjuS6ecLDIyczi6Sxn0GkOnI78GCgoRiSGFQmtR9hmLF88ntPJpBhQ/T3p1CQAhnHJPJ8sqWZBzPDuz+pE68TJGjRhBSlKIpJBCQkQOHYVCa+QefQxoVSkfr9/E3M/T6ffOTYzb+jRJHiZMiKciR+GWRFLnAgZMu5FRBd3V3SQiB02h0Ja4s3PLWrY+dROd179MtaWSU7OFTyI9WJY0lIrMfPK69WRbKJdIzzGcNnkCmekp8a5aRNoQhUIbV7Hkacpn30la2Vo61W7ebV4xnVmffThzdvQls+cwbPBJXDChHx0zFBQi0jiFQnsSrqFi+xY67PyMde+/xvoPXqFfxQf0suj5iTfCI4gkp1OcfxrZEy/mqAHd6dhBASEiX1AoJIKKLbDwb0Re+SWlZNEpXMKqSC9mRSYxKKuawRnbST7me3Qecgy5manxrlZE4kihkEiC50zXLptF1Su/JrPkfSotnR2RZDKo5v7wqWwZPp3zjhtP704ZdOqQopPXIglGoZDIdm6FtI5sL9lI+T++Tc/iOVR5Mm9HhrMoMpAtSXl0HTCO3MIxDO7ZifEFuaQlJ8W7ahGJIYWCfOHz1WyffSehdW+TVboKI3r8Sz2D+ZHBPMEJHDFhIj37j2BY3zx6dsyIc8EicqgpFKRxVeVQXkz1p/OIrHkDX/UyGRVFACyJFDAj/Qb6DxpOx4wULpzQh0Hds+NcsIgcCnEJBTO7HzgT2OTuI4NpnYFHgQJgDfBld98azLsR+AYQBq529+f39RkKhUMsXIsvn8XKjz5k4Ad3khyposQ78qaP5P6aUygcfRyXTiqgMC+TbN0bIdJmxSsUjgXKgf+rFwq3A5+7+21mdgOQ6+7Xm9lw4BFgItALeAkY7O5NPihZoRBDn69mx/uzSC1ZTmjlU4Sqy3g/UsjH3pMPQsOoHTOd88b1YVNZFZlpSUwa0DXeFYtIM8Wt+8jMCoCn6oXCSmCKu280s57Aq+4+JGgl4O63Bss9D8xw97eb2r5CoYVUlcPiR6h6934oLyatqoQl3h/c+dyzWUE/uhceRsq4r3LKyJ6EcCxSC8m69FWkNWoqFFp6gP/u7r4RIAiGbsH03sA79ZYrCqY1YGZXAFcA9O3bN4alSp20LJh4OWkTL4+O2fTenxn6/j/YXBFmwI41HF21lNDap3jqk9lc9NiZ3JD6KINzasj+zhsKBpE2prU89aWxC+UbbcK4+73AvRBtKcSyKGmEGUy8nOSJl9MTooP6RWqJvH4np7zxO84MvwsRYBs8+cefMvbCn5GXk05acggzdE+ESCvX0qFQbGY963UfbQqmFwF96i2XD2xo4drkQISSIJREaOqNhI78Frz/KLVJHSh64yHO3vy/rL3rn7zgA3knMoyKDn05+Utf5pQRPUhJCsW7chFpREufU/hvoKTeiebO7v4jMxsBPMwXJ5pnA4N0orkNq65g85sPsGPFK3QreY+M2m0AzIsMJpKUzgt9rubNsh5ceWwhZx3ei5CeGSHSYuJ19dEjwBSgK1AM3AQ8CTwG9AU+BS5w98+D5f8TuAyoBa5x92f39RkKhTaithrKPyP89j3sXP4itWWb6RCp4B9pZ/NCeSHbeh3H9acNY2L/znqgkEgL0M1r0qpEyjbDU9cQWvkUAAtsOI9UH82H6Ydz2ZemMqGgM7066U5qkVhRKEjrtHMbfPB3Im/8hlDpeiIYr4RHs51M3ss5hb59+vKhFdAtO41vTxmoIcBFDhGFgrRukQhsWUl4wd+oWfIvrHIbabVlADyddDyrqnJZmzOO0844j2MG55GeogH7RA6GQkHalsrtsOYN/JNXsbn31k1+MTyWV2wi2/uexIRhAzhnbL6eMCdyABQK0nZVlQMQnvtn/LXbSa6toIpUbq/5Mh+kjCS3YAwflVTyo1OGcurIHnEuVqRtUChI+xCJQPEH8PJ/wUcvAFBKFu8kjWNtdTYbuk0hpXAyhXlZnDS8O12y0uJcsEjrpFCQ9iUSgXXvQul6+OhFIh+/TGTHVpK9hvmRIfyq5sssThpO54wkCn09Jx13NNOPGRzvqkVaDYWCtH/VO2Dxw/hr/42Vf0Z1KB3cSfUqXg0fzmc5o1gYGcC7NprvnDCY88flx7tikbhRKEjiqN4BS/4Bm1YAEAklE3rrd3Wzn047g6fKBzNs/BS69ipk8sAu9OuSGa9qReJCoSCJbcNCyOoOb/0e3rkbgPXelWurv8UCH8T5E/pz05dGkJGqS10lMSgURCA67PfCv0ZfvvATrHI721O7c1fFSexMyqI8ZxBV3Udz0vAeLFm/ncqaMP/vmP4M7KbHkEr7olAQ2dOOz2H1azD3T7D2zbrJH1p/3qwZzDayqQhlMyt0PD88cwyj8jsytEdOHAsWOXQUCiJNKV4KHoFl/8LXL8A/eQ3zMIazlRx+V3M2D4ZP5ozDevPLc0eRo+dTSxunUBDZH2XFYCH4/GPCr9xK0upXKc4cxk3bTmNOaAJTh/ZgQLcsAL4+qYDcTD1dTtoWhYLIgXKH9x+DV38JW9ewKb2AD3d2oipi/Dr8ZdalDOC8cfls31nD2pIKJvbvwjeO7k9etm6ck9ZLoSBysMK1sPQJePN3RCq3Q+V2QlXbqQhl8VFtDzaFupKfUs6MHefxQWg4J4/oTl5WGt89YZDGZ5JWR6EgcqhVlMDSf8LmFfhHL0LFFiy9I5RtoChtAElV21kQHsjtfJVOPfrzh0vG6hkR0mooFERiKRIOvmrgtduh6D3I7kl4xTPURmBm+HiKQr34tM80Jg/L55hBeXTKSCEjNYm05BBmetqctCyFgkg8lHwML/wEVj4DwHrrwQ+qvkEOFXWLvJ16JFccO5Bx/TpzZGFnBYS0CIWCSDxFIrDmdfjnFVD+2W6zXsg6m/tKRrHc+3JqXgmfpI+ge24WVx8/iCE9dNOcxIZCQaQ12L4eVr0IPUZFL3md9xdY8CAAEUKEiPBxymAerD2Rv1cfxZiCbvTr0oHnlxYzpHs2N501nKE9cthRXUtGSpJaFXLAFAoirVEkAhsXwta18Onb0HkAvP172L6O4g6DWF3diVVVHQnlDeHR7cPJDm+lMu9w5q0rY1Tvjlx70iCmDummcJD9plAQaSvcYcnjMOcOCCXh2z7FqkrrZr+TNpnKzsN4dOsgNm3fQVbheH50xuEM75nD5vIqumSmkRRSSEjTFAoibZU7fP4JrHwWyjZGWxL1zGEsl1dezYTkj9kUziK91whOG9WLoT2zmTygK6nJoTgVLq2ZQkGkvdiwEDK7wYqnoLwYXv81YUsmyWsBeMqm8Gb1AN6NDCMnfzhnHtaT4T1zGNIjm01lVfTr0oEOqcnx3QeJO4WCSHv18cuw8jnoPQ42LYM3fwtAdUoOM6sm83TNeN71YXWL9+6UwXeOH8jWHdU8Pr+IXp0y+O2Fo/U86wSjUBBJFCufg6RkeOWX+KblWM0OtuSOoTLUgTSvZN72HF6uHMR678qIzs6H20Msi/RjcEFfBnTLpk9uByYN7EJ+pw507KDhOdorhYJIIqreEW05rJ4DtVWQkoEXL8UqtzVY9ONQf26LXMLsyqFECJGdnszN00YybXQvdtaEqY24hgxvR1pdKJjZGqAMCAO17j7ezDoDjwIFwBrgy+6+tantKBRE9lMkHD1xXV4MqVlQvgk2L4d3/hfKNuAWImLJLE8awsVl36OgRxe2bN3O1kg654/Lp2tWGvm5HeiTm8FLy4t5/aMtXHfSYE4c1p1QcNVTZU2Y9BQ92rQ1a62hMN7dt9SbdjvwubvfZmY3ALnufn1T21EoiBwi1Tvgw2eheBlUleHz7mNnUg7UVtLBd7AxpR9PVI1lTTgPByo8nY3ehQ2Zwykur2FAXiY3fWkE73xSwl/eXMMDX5/AEYVd4r1XshdtJRRWAlPcfaOZ9QRedfchTW1HoSASIx+/DIsfheQ0yO0HH70UvcGO3X9feGY31nWexHVbzmBk6esMsvX81c6gKJTPpZP6cWRhFyYN6EpSyKioqmXu6s/p07kDA4OHFEl8tMZQWA1sJfo/7I/ufq+ZbXP3TvWW2eruuY2sewVwBUDfvn3HrV27toWqFklw1RVQsRmw6OviJfDRi9EhxCPRS2JrLYUkg9c7nMSiban8ufYMsjt1pXenDJI+W8CJta/zu9pzmX7CaL53wiDKKmvISU+p63qSltEaQ6GXu28ws27Ai8B3gVnNCYX61FIQaQVWz4Fl/4LR/wEd+8CLN8GSx/FIDZVpecxLGU91bZipO58nhDOv48n8R/EldEl3NlamkpYcoqBLJn07pXDBxP6M7ZdLV10iG1OtLhR2K8BsBlAOXI66j0TaB/focyVe+1X0e2UpTLwcklJ3uyt7fcdxVFgGPUqXkBPZxtXVVzErMplhPXMor6phYF4W543L58jCLnTJTNU4T4dIqwoFM8sEQu5eFrx+EfgFcAJQUu9Ec2d3/1FT21IoiLQBkQjUVEBadvTqp6VPRK+AClfDiqfBI9BrLF68lPCWjyhL7cbzNpnPcg6j16bXeXVnIc9GJpKZlkrfzh04dWQPjhucxxurttC/ayanjuixX91P23ZUU7R1JwO7ZSXsVVKtLRQKgSeCt8nAw+5+i5l1AR4D+gKfAhe4++dNbUuhINKObF0Dj34FkjOgaC4AbiHMI2zNLCS16nMqPI2HKo9mYmgF83wwd9WeS9+uORw3OI/NZVV8+vkOOnVIYeVnZeR2SOWG04cydUi3uo9YvG4btz7wd0p2RLd542nDOG9cfpx2OH5aVSgcSgoFkXbqsyXRBxL1Hg8fPgfv/hFyC2BHCax+jdqkDJLDOynP7MOScAHbd1ZTk5xJccfRLKnpzZTQIj6pzOTu7ZM4ekhPhvbIYUSvHMqf/D4X+zPUJmVwZ9b3+UtxIaePHcj54/IZ0iObzpmp8d7zFqFQEJH2wT16uWy34bBhAbzzh+gNeAA7t0LFpt0WL0/pzGIfzOtVAyiJZPLfKfdSOvQicjbPg5JVbEvtwVkVPyESCdOJMiq7jqJzVhqlO2tISQpx/NBuXHJEX3IzU1m1qZzkkDGoe8Mn4q34rJRn3t/IpZMKDmocqQ+Loy2cvOzYnmhXKIhI++ceDYryTdGn2xUvhUUPw6blsGUlADs6D6PDt+dAbSV8PBtmXY1XV2AeBqAotT+/y/kBoQ6dKd9ZxTNFqbhDekqIypowYJwzpjcnDe/OUYVdyM1M5dkPNvKdRxYSjjjdstO48rgBnDy8O306d9iv8otLK5l828s4cMcFh3HOmNh1aykURCSxrV8AFVugYDKkZn4x/bMl0fssUjpAVjd4aUa0iypQ2X0cm6uS8Zqd5O9YxudpvSnamcLM2ik8GTmagb26Urj5Fa5LeZxuWan8LXISt28+glqSOW1kD2acNYKd1WFeWPYZ54/r02T31J9e+5gdL97MpqxhvOLjee1HU0lJis3zMBQKIiLNUboheg4jEo62ONa8DjU7oWYHFE6Bso1ESj4htGkpO5I7sSJ5CGMr36Wm6zBS0jJh/TxqM/LYah25oezLvO6HUVtbSy8rIbVzP66cMoCjCrvSt8sXrYjKmjDu8PPf3cNtFT8B4Gc1lzLoS9/nK0f0pWjrTsxg/tqtDOyWxYheHQ96NxUKIiKHijuseQPevjt6ldToS2Dqf0aHBPnoRVj8CHz2AV6yirUdRtKjei3ptaUss4H8rfo4ZoWPomOnLvTr0oGtO2pY+VkpDtyd/FtOSP+Q1D6j2bl6LlOr7ySckceW8qq6j04OGT84ZQhXHFN4UHeBKxRERFpSVXl02PKPXoDuo6DrQHzB/2Gff0JNUgbbQrmstd5EktLpku6k12yjd/kSmPw9GH0Jfs9R7CCdbSndyEoxSjP7kuMVvF07mKs2nkpmehrnjOnNz6eNPKDyFAoiIvG260T4woeiV0ptXhG9cS8pFVIyYNDJcNRV0defvgsL/xpdDqInzZPTYPMKqlM6UkEGm7sfzeD/d98BldJUKOhhrSIiLcEs+tjU3uP2vWzfI6Jfe1r+FKkfvUBquJrcPo3MPwQUCiIibcWwM6NfMRSb651ERKRNUiiIiEgdhYKIiNRRKIiISB2FgoiI1FEoiIhIHYWCiIjUUSiIiEidNj3MhZltBtYexCa6AlsOUTnx1F72A7QvrZX2pXU60H3p5+55jc1o06FwsMxs3t7G/2hL2st+gPaltdK+tE6x2Bd1H4mISB2FgoiI1En0ULg33gUcIu1lP0D70lppX1qnQ74vCX1OQUREdpfoLQUREalHoSAiInUSMhTM7FQzW2lmq8zshnjXs7/MbI2ZfWBmi8xsXjCts5m9aGYfBd9z411nY8zsfjPbZGZL6k3ba+1mdmNwnFaa2Snxqbpxe9mXGWa2Pjg2i8zs9HrzWuW+mFkfM3vFzJab2VIz+14wvc0dlyb2pS0el3Qzm2tmi4N9+XkwPbbHxd0T6gtIAj4GCoFUYDEwPN517ec+rAG67jHtduCG4PUNwK/iXedeaj8WGAss2VftwPDg+KQB/YPjlhTvfdjHvswAftDIsq12X4CewNjgdTbwYVBvmzsuTexLWzwuBmQFr1OAd4EjY31cErGlMBFY5e6fuHs1MBOYFueaDoVpwIPB6weBs+NXyt65+xzg8z0m7632acBMd69y99XAKqLHr1XYy77sTavdF3ff6O4LgtdlwHKgN23wuDSxL3vTmvfF3b08eJsSfDkxPi6JGAq9gXX13hfR9H+a1siBF8xsvpldEUzr7u4bIfqDAXSLW3X7b2+1t9Vj9R0zez/oXtrVtG8T+2JmBcAYon+Vtunjsse+QBs8LmaWZGaLgE3Ai+4e8+OSiKFgjUxra9flTnb3scBpwFVmdmy8C4qRtnis/gAMAEYDG4FfB9Nb/b6YWRbwOHCNu5c2tWgj01r7vrTJ4+LuYXcfDeQDE81sZBOLH5J9ScRQKAL61HufD2yIUy0HxN03BN83AU8QbSIWm1lPgOD7pvhVuN/2VnubO1buXhz8IEeAP/FF871V74uZpRD9JfqQu/8zmNwmj0tj+9JWj8su7r4NeBU4lRgfl0QMhfeAQWbW38xSgYuAWXGuqdnMLNPMsne9Bk4GlhDdh0uDxS4F/hWfCg/I3mqfBVxkZmlm1h8YBMyNQ33NtuuHNXAO0WMDrXhfzMyA+4Dl7n5nvVlt7rjsbV/a6HHJM7NOwesM4ERgBbE+LvE+wx6ns/qnE70q4WPgP+Ndz37WXkj0CoPFwNJd9QNdgNnAR8H3zvGudS/1P0K0+V5D9C+bbzRVO/CfwXFaCZwW7/qbsS9/BT4A3g9+SHu29n0BjibazfA+sCj4Or0tHpcm9qUtHpfDgIVBzUuAnwXTY3pcNMyFiIjUScTuIxER2QuFgoiI1FEoiIhIHYWCiIjUUSiIiEgdhYJInJjZFDN7Kt51iNSnUBARkToKBZF9MLOvBOPaLzKzPwaDlJWb2a/NbIGZzTazvGDZ0Wb2TjDw2hO7Bl4zs4Fm9lIwNv4CMxsQbD7LzP5hZivM7KHgjlyRuFEoiDTBzIYBFxIdhHA0EAYuATKBBR4dmPA14KZglf8Drnf3w4jeQbtr+kPA3e5+ODCJ6J3QEB3F8xqiY+EXApNjvEsiTUqOdwEirdwJwDjgveCP+AyiA5BFgEeDZf4G/NPMOgKd3P21YPqDwN+Dsap6u/sTAO5eCRBsb667FwXvFwEFwBsx3yuRvVAoiDTNgAfd/cbdJpr9dI/lmhovpqkuoap6r8PoZ1LiTN1HIk2bDZxvZt2g7vm4/Yj+7JwfLPMfwBvuvh3YambHBNO/Crzm0fH8i8zs7GAbaWbWoSV3QqS59FeJSBPcfZmZ/YTok+5CREdEvQqoAEaY2XxgO9HzDhAdyvh/g1/6nwBfD6Z/Ffijmf0i2MYFLbgbIs2mUVJFDoCZlbt7VrzrEDnU1H0kIiJ11FIQEZE6aimIiEgdhYKIiNRRKIiISB2FgoiI1FEoiIhInf8P82eONIEmcqwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training Loss', 'Validation Loss'], loc='upper left')\n",
    "plt.show()\n",
    "# # summarize history for loss\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d2819bd-fbb4-43ee-8f1e-5bf82b0f89c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "     \n",
      "    \n",
      "        \n",
      "        \n",
      "Decoded:\n",
      "     \n",
      "    \n",
      "        \n",
      "       \n",
      "                \n",
      "            \n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "# Decoding\n",
    "print('Original:')\n",
    "print(original_list[0])\n",
    "print(original_list[1])\n",
    "print(original_list[2])\n",
    "print(original_list[3])\n",
    "print('Decoded:')\n",
    "\n",
    "\n",
    "train_inputs = tf.ragged.constant([i for i in inputs_list[:6]], dtype=np.float32)\n",
    "train_seq_len = tf.cast(train_inputs.row_lengths(), tf.int32)\n",
    "train_inputs = train_inputs.to_tensor(default_value=FEAT_MASK_VALUE)\n",
    "\n",
    "decoded, _ = tf.nn.ctc_greedy_decoder(tf.transpose(\n",
    "    model_predict.predict(train_inputs), (1, 0, 2)), train_seq_len)\n",
    "\n",
    "d = tf.sparse.to_dense(decoded[0], default_value=-1).numpy()\n",
    "str_decoded = [''.join([alphabets['num_to_char'][str(x)]\n",
    "                       for x in np.asarray(row) if x != -1]) for row in d]\n",
    "\n",
    "# print('decoded',str_decoded)\n",
    "for s in str_decoded:\n",
    "    # Replacing blank label to none\n",
    "    # s = s.replace(chr(ord('z') + 1), '')\n",
    "    # Replacing space label to space\n",
    "    s = s.replace(alphabets['num_to_char']['0'], ' ')\n",
    "    print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382d422e-0f52-4970-a7f3-d5a2aabe639a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
