{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65ba901e-04fd-4370-8349-5922a37763aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy.io.wavfile as wav\n",
    "import glob\n",
    "import numpy as np\n",
    "from six.moves import xrange as range\n",
    "import json\n",
    "from python_speech_features import mfcc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import (BatchNormalization, Conv1D, Dense, Input, \n",
    "    TimeDistributed, Activation, Bidirectional, SimpleRNN, GRU, LSTM)\n",
    "# from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import (Input, Lambda)\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint  \n",
    "import librosa \n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "import gc\n",
    "\n",
    "# import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27c17201-9ec8-4e7d-a59c-07d80a01a0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants \n",
    "SPACE_TOKEN = '<space>'\n",
    "SPACE_INDEX = 0\n",
    "FIRST_INDEX = 1\n",
    "FEAT_MASK_VALUE = 1e+10\n",
    "\n",
    "# Some configs\n",
    "# filters=200\n",
    "# kernel_size=11\n",
    "# conv_stride=2\n",
    "# conv_border_mode='valid'\n",
    "units=200\n",
    "num_features = 13\n",
    "num_units = 100\n",
    "num_classes = 222 + 1 # 285(including space) + blamk label = 286\n",
    "\n",
    "# Hyper-parameters\n",
    "num_epochs = 100\n",
    "num_layers = 1\n",
    "batch_size = 16\n",
    "initial_learning_rate = 0.0005\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe58f0c6-de98-40b6-ab43-3dd420eefc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "file_path = glob.glob('/home/dibora_gebreyohannes/AMH-STT/data/train/wav/*.wav')\n",
    "# file_path = file_path[28:32]\n",
    "audio_list = []\n",
    "fs_list = []\n",
    "dur_list = []\n",
    "dropped_file_path = []\n",
    "\n",
    "for file_name in file_path:\n",
    "    audio,fs = librosa.load(file_name,sr=16000)\n",
    "    dur = librosa.get_duration(audio,sr=16000)\n",
    "    if dur > 2 and dur < 6:\n",
    "        dropped_file_path.append(file_name)\n",
    "        audio_list.append(audio)\n",
    "        dur_list.append(dur)\n",
    "        fs_list.append(fs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ac71e41-e5c1-4ac1-9a88-b9716c5b393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loading the data\n",
    "# def load_audio(files='/home/dibora_gebreyohannes/AMH-STT/data/train/wav/*.wav')\n",
    "# file_path = glob.glob()\n",
    "# # file_path = file_path[28:32]\n",
    "# audio_list = []\n",
    "# fs_list = []\n",
    "# dur_list = []\n",
    "# dropped_file_path = []\n",
    "\n",
    "# for file_name in file_path:\n",
    "#     audio,fs = librosa.load(file_name,sr=16000)\n",
    "#     dur = librosa.get_duration(audio,sr=16000)\n",
    "#     if dur > 2 and dur < 6:\n",
    "#         dropped_file_path.append(file_name)\n",
    "#         audio_list.append(audio)\n",
    "#         dur_list.append(dur)\n",
    "#         fs_list.append(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53ef3f13-0679-4128-a785-46f813715e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "724"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(audio_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cdb52b7-cf76-4083-bbd3-288ad8cc3f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset composed of data with variable lengths\n",
    "inputs_list = []\n",
    "for index in range(len(audio_list)):\n",
    "    input_val = mfcc(audio_list[index], samplerate=fs_list[index])\n",
    "    input_val = (input_val - np.mean(input_val)) / np.std(input_val)\n",
    "    inputs_list.append(input_val)\n",
    "\n",
    "# Transform in 3D Array\n",
    "train_inputs = tf.ragged.constant([i for i in inputs_list], dtype=np.float32)\n",
    "train_seq_len = tf.cast(train_inputs.row_lengths(), tf.int32)\n",
    "train_inputs = train_inputs.to_tensor(default_value=FEAT_MASK_VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c773b459-59ae-44c1-8136-a366baa4bca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/train_labels.json', 'r', encoding='UTF-8') as train_label_file:\n",
    "    train_labels = json.load(train_label_file)\n",
    "with open('../data/test_labels.json', 'r', encoding='UTF-8') as test_label_file:\n",
    "    test_labels = json.load(test_label_file)\n",
    "with open('../data/alphabets_data.json', 'r', encoding='UTF-8') as language_file:\n",
    "    alphabets = json.load(language_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6866b469-9e4b-425e-817f-fc5b2a3f25bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Targets\n",
    "original_list = []\n",
    "targets_list = []\n",
    "\n",
    "for path in dropped_file_path:\n",
    "    file_name = path[:-4].split('wav')[1][1:]\n",
    "    # Read Label\n",
    "    label = train_labels[file_name]\n",
    "    original = \" \".join(label.strip().split(' '))\n",
    "    original_list.append(original)\n",
    "#     print(original)\n",
    "    target = original.replace(' ', '  ')\n",
    "    # print('step-1. ',target)\n",
    "    target = target.split(' ')\n",
    "    # print('step-2. ', target)\n",
    "    # Adding blank label\n",
    "    target = np.hstack([SPACE_TOKEN if x == '' else list(x) for x in target])\n",
    "    # print('step-3. ', target)\n",
    "    # Transform char into index\n",
    "    target = np.asarray([alphabets['char_to_num'][x] for x in target])\n",
    "    # print('step-4. ', target)\n",
    "    targets_list.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b00706-84e4-4b68-82fe-863431fa5dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a538fce2-5e7b-4a68-a1e8-c94bf3c75ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating sparse representation to feed the placeholder\n",
    "train_targets = tf.ragged.constant([i for i in targets_list], dtype=np.int32)\n",
    "train_targets_len = tf.cast(train_targets.row_lengths(), tf.int32)\n",
    "train_targets = train_targets.to_sparse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbd1d6c7-6281-4129-a4f5-6056ff0919d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_inputs, val_targets, val_seq_len, val_targets_len = train_inputs, train_targets, train_seq_len, train_targets_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b26420e6-239a-40d4-9169-ac3f1ec73681",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTCLossLayer(tf.keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        labels = inputs[0]\n",
    "        logits = inputs[1]\n",
    "        label_len = inputs[2]\n",
    "        logit_len = inputs[3]\n",
    "\n",
    "        logits_trans = tf.transpose(logits, (1,0,2))\n",
    "        label_len = tf.reshape(label_len, (-1,))\n",
    "        logit_len = tf.reshape(logit_len, (-1,))\n",
    "        loss = tf.reduce_mean(tf.nn.ctc_loss(labels, logits_trans, label_len, logit_len, blank_index=-1))\n",
    "        # define loss here instead of in compile\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        # Decode\n",
    "        decoded, _ = tf.nn.ctc_greedy_decoder(logits_trans, logit_len)\n",
    "\n",
    "        # Inaccuracy: label error rate\n",
    "        ler = tf.reduce_mean(tf.edit_distance(tf.cast(decoded[0], tf.int32),labels))\n",
    "        self.add_metric(ler, name='ler', aggregation='mean')\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2068651d-1947-48fb-bedb-a671095f20ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Training Cells\n",
    "# num_units = 50\n",
    "# cells = []\n",
    "# for _ in range(num_layers):\n",
    "#     cell = tf.keras.layers.GRUCell(num_units)\n",
    "#     cells.append(cell)\n",
    "\n",
    "# stack = tf.keras.layers.StackedRNNCells(cells)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08477705-ad36-44ea-b87e-a136207a3567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definning Input Parameters\n",
    "input_feature = tf.keras.layers.Input((None, num_features), name='input_feature')\n",
    "input_label = tf.keras.layers.Input((None,), dtype=tf.int32, sparse=True, name='input_label')\n",
    "input_feature_len = tf.keras.layers.Input((1,), dtype=tf.int32, name='input_feature_len')\n",
    "input_label_len =tf.keras.layers.Input((1,), dtype=tf.int32, name='input_label_len')\n",
    "\n",
    "input_masking = tf.keras.layers.Masking(FEAT_MASK_VALUE)(input_feature)\n",
    "x = tf.keras.layers.LSTM(100,return_sequences=True)(input_masking)\n",
    "x_1 = tf.keras.layers.BatchNormalization()(x)\n",
    "x_2 = tf.keras.layers.LSTM(100,return_sequences=True)(x_1)\n",
    "x_3= tf.keras.layers.BatchNormalization()(x_2)\n",
    "x_4 = tf.keras.layers.LSTM(100,return_sequences=True)(x_3)\n",
    "# x = tf.keras.layers.BatchNormalization()(x)\n",
    "# layer_rnn = tf.keras.layers.LSTM(10, return_sequences=True)(layer_bn)\n",
    "# x = tf.keras.layers.Dropout(0.2, seed=42)(x)\n",
    "layer_output = tf.keras.layers.TimeDistributed(Dense(num_classes, kernel_initializer=tf.keras.initializers.TruncatedNormal(0.0,0.1), bias_initializer='zeros', name='logit'))(x_4)\n",
    "\n",
    "layer_loss = CTCLossLayer()([input_label, layer_output, input_label_len, input_feature_len])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ebad848-3b83-4a0a-acc9-cc02c2659d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_feature (InputLayer)      [(None, None, 13)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, None, 13)     0           input_feature[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, None, 100)    45600       masking[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, None, 100)    400         lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, None, 100)    80400       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, 100)    400         lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, None, 100)    80400       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_label (InputLayer)        [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 223)    22523       lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_label_len (InputLayer)    [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_feature_len (InputLayer)  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc_loss_layer (CTCLossLayer)   (None, None, 223)    0           input_label[0][0]                \n",
      "                                                                 time_distributed[0][0]           \n",
      "                                                                 input_label_len[0][0]            \n",
      "                                                                 input_feature_len[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 229,723\n",
      "Trainable params: 229,323\n",
      "Non-trainable params: 400\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create models for training and prediction\n",
    "model_train = tf.keras.models.Model(inputs=[input_feature, input_label, input_feature_len, input_label_len],\n",
    "            outputs=layer_loss)\n",
    "print(model_train.summary())\n",
    "model_predict = tf.keras.models.Model(inputs=input_feature, outputs=layer_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65a3acd2-a149-4e10-8305-80a2d67ef2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "46/46 [==============================] - 15s 144ms/step - loss: 780.3615 - ler: 1.0340 - val_loss: 153.1605 - val_ler: 1.0000\n",
      "\n",
      "Epoch 00001: ler improved from inf to 1.03400, saving model to ../models/RNN.h5\n",
      "Epoch 2/300\n",
      "46/46 [==============================] - 3s 74ms/step - loss: 132.2440 - ler: 0.9838 - val_loss: 131.0723 - val_ler: 1.0000\n",
      "\n",
      "Epoch 00002: ler improved from 1.03400 to 0.98382, saving model to ../models/RNN.h5\n",
      "Epoch 3/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 124.8919 - ler: 0.9557 - val_loss: 131.0509 - val_ler: 1.0000\n",
      "\n",
      "Epoch 00003: ler improved from 0.98382 to 0.95571, saving model to ../models/RNN.h5\n",
      "Epoch 4/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 123.8795 - ler: 0.9357 - val_loss: 127.5749 - val_ler: 1.0000\n",
      "\n",
      "Epoch 00004: ler improved from 0.95571 to 0.93571, saving model to ../models/RNN.h5\n",
      "Epoch 5/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 123.4388 - ler: 0.8975 - val_loss: 124.7767 - val_ler: 0.9944\n",
      "\n",
      "Epoch 00005: ler improved from 0.93571 to 0.89746, saving model to ../models/RNN.h5\n",
      "Epoch 6/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 123.4324 - ler: 0.8842 - val_loss: 124.3257 - val_ler: 0.9630\n",
      "\n",
      "Epoch 00006: ler improved from 0.89746 to 0.88422, saving model to ../models/RNN.h5\n",
      "Epoch 7/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 123.8656 - ler: 0.8712 - val_loss: 124.2399 - val_ler: 0.9294\n",
      "\n",
      "Epoch 00007: ler improved from 0.88422 to 0.87124, saving model to ../models/RNN.h5\n",
      "Epoch 8/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 122.5893 - ler: 0.8613 - val_loss: 122.4085 - val_ler: 0.8804\n",
      "\n",
      "Epoch 00008: ler improved from 0.87124 to 0.86135, saving model to ../models/RNN.h5\n",
      "Epoch 9/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 121.6179 - ler: 0.8563 - val_loss: 122.9015 - val_ler: 0.8808\n",
      "\n",
      "Epoch 00009: ler improved from 0.86135 to 0.85626, saving model to ../models/RNN.h5\n",
      "Epoch 10/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 121.3674 - ler: 0.8492 - val_loss: 121.0689 - val_ler: 0.8495\n",
      "\n",
      "Epoch 00010: ler improved from 0.85626 to 0.84916, saving model to ../models/RNN.h5\n",
      "Epoch 11/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 119.3349 - ler: 0.8457 - val_loss: 120.6741 - val_ler: 0.8373\n",
      "\n",
      "Epoch 00011: ler improved from 0.84916 to 0.84566, saving model to ../models/RNN.h5\n",
      "Epoch 12/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 118.6382 - ler: 0.8422 - val_loss: 120.0445 - val_ler: 0.8482\n",
      "\n",
      "Epoch 00012: ler improved from 0.84566 to 0.84222, saving model to ../models/RNN.h5\n",
      "Epoch 13/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 118.6002 - ler: 0.8427 - val_loss: 119.7954 - val_ler: 0.8333\n",
      "\n",
      "Epoch 00013: ler did not improve from 0.84222\n",
      "Epoch 14/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 121.0476 - ler: 0.8391 - val_loss: 118.7942 - val_ler: 0.8454\n",
      "\n",
      "Epoch 00014: ler improved from 0.84222 to 0.83912, saving model to ../models/RNN.h5\n",
      "Epoch 15/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 119.5098 - ler: 0.8398 - val_loss: 118.0660 - val_ler: 0.8434\n",
      "\n",
      "Epoch 00015: ler did not improve from 0.83912\n",
      "Epoch 16/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 120.7595 - ler: 0.8386 - val_loss: 117.8936 - val_ler: 0.8465\n",
      "\n",
      "Epoch 00016: ler improved from 0.83912 to 0.83861, saving model to ../models/RNN.h5\n",
      "Epoch 17/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 117.9451 - ler: 0.8320 - val_loss: 116.7056 - val_ler: 0.8202\n",
      "\n",
      "Epoch 00017: ler improved from 0.83861 to 0.83202, saving model to ../models/RNN.h5\n",
      "Epoch 18/300\n",
      "46/46 [==============================] - 3s 72ms/step - loss: 116.5772 - ler: 0.8270 - val_loss: 115.7535 - val_ler: 0.8275\n",
      "\n",
      "Epoch 00018: ler improved from 0.83202 to 0.82698, saving model to ../models/RNN.h5\n",
      "Epoch 19/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 115.0061 - ler: 0.8231 - val_loss: 114.8439 - val_ler: 0.8219\n",
      "\n",
      "Epoch 00019: ler improved from 0.82698 to 0.82311, saving model to ../models/RNN.h5\n",
      "Epoch 20/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 117.3778 - ler: 0.8186 - val_loss: 114.1928 - val_ler: 0.8227\n",
      "\n",
      "Epoch 00020: ler improved from 0.82311 to 0.81857, saving model to ../models/RNN.h5\n",
      "Epoch 21/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 112.4576 - ler: 0.8146 - val_loss: 113.0103 - val_ler: 0.8050\n",
      "\n",
      "Epoch 00021: ler improved from 0.81857 to 0.81464, saving model to ../models/RNN.h5\n",
      "Epoch 22/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 113.4726 - ler: 0.8093 - val_loss: 112.1359 - val_ler: 0.8024\n",
      "\n",
      "Epoch 00022: ler improved from 0.81464 to 0.80932, saving model to ../models/RNN.h5\n",
      "Epoch 23/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 111.1487 - ler: 0.8052 - val_loss: 111.2819 - val_ler: 0.8055\n",
      "\n",
      "Epoch 00023: ler improved from 0.80932 to 0.80523, saving model to ../models/RNN.h5\n",
      "Epoch 24/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 111.0968 - ler: 0.8003 - val_loss: 110.7745 - val_ler: 0.7894\n",
      "\n",
      "Epoch 00024: ler improved from 0.80523 to 0.80026, saving model to ../models/RNN.h5\n",
      "Epoch 25/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 110.5545 - ler: 0.7996 - val_loss: 109.4253 - val_ler: 0.7867\n",
      "\n",
      "Epoch 00025: ler improved from 0.80026 to 0.79963, saving model to ../models/RNN.h5\n",
      "Epoch 26/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 108.0932 - ler: 0.7956 - val_loss: 108.2785 - val_ler: 0.7905\n",
      "\n",
      "Epoch 00026: ler improved from 0.79963 to 0.79564, saving model to ../models/RNN.h5\n",
      "Epoch 27/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 108.0285 - ler: 0.7861 - val_loss: 106.8101 - val_ler: 0.7832\n",
      "\n",
      "Epoch 00027: ler improved from 0.79564 to 0.78612, saving model to ../models/RNN.h5\n",
      "Epoch 28/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 108.4482 - ler: 0.7841 - val_loss: 107.1183 - val_ler: 0.8029\n",
      "\n",
      "Epoch 00028: ler improved from 0.78612 to 0.78410, saving model to ../models/RNN.h5\n",
      "Epoch 29/300\n",
      "46/46 [==============================] - 3s 75ms/step - loss: 105.1662 - ler: 0.7784 - val_loss: 105.1192 - val_ler: 0.7782\n",
      "\n",
      "Epoch 00029: ler improved from 0.78410 to 0.77838, saving model to ../models/RNN.h5\n",
      "Epoch 30/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 105.4332 - ler: 0.7733 - val_loss: 103.5164 - val_ler: 0.7768\n",
      "\n",
      "Epoch 00030: ler improved from 0.77838 to 0.77328, saving model to ../models/RNN.h5\n",
      "Epoch 31/300\n",
      "46/46 [==============================] - 3s 72ms/step - loss: 103.9871 - ler: 0.7687 - val_loss: 102.0265 - val_ler: 0.7659\n",
      "\n",
      "Epoch 00031: ler improved from 0.77328 to 0.76871, saving model to ../models/RNN.h5\n",
      "Epoch 32/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 104.6022 - ler: 0.7662 - val_loss: 100.9912 - val_ler: 0.7657\n",
      "\n",
      "Epoch 00032: ler improved from 0.76871 to 0.76624, saving model to ../models/RNN.h5\n",
      "Epoch 33/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 101.4373 - ler: 0.7601 - val_loss: 100.0953 - val_ler: 0.7807\n",
      "\n",
      "Epoch 00033: ler improved from 0.76624 to 0.76012, saving model to ../models/RNN.h5\n",
      "Epoch 34/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 101.5046 - ler: 0.7542 - val_loss: 98.7005 - val_ler: 0.7416\n",
      "\n",
      "Epoch 00034: ler improved from 0.76012 to 0.75418, saving model to ../models/RNN.h5\n",
      "Epoch 35/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 99.0586 - ler: 0.7472 - val_loss: 97.7029 - val_ler: 0.7456\n",
      "\n",
      "Epoch 00035: ler improved from 0.75418 to 0.74720, saving model to ../models/RNN.h5\n",
      "Epoch 36/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 99.7446 - ler: 0.7403 - val_loss: 96.9328 - val_ler: 0.7518\n",
      "\n",
      "Epoch 00036: ler improved from 0.74720 to 0.74033, saving model to ../models/RNN.h5\n",
      "Epoch 37/300\n",
      "46/46 [==============================] - 3s 74ms/step - loss: 97.3231 - ler: 0.7366 - val_loss: 95.3781 - val_ler: 0.7287\n",
      "\n",
      "Epoch 00037: ler improved from 0.74033 to 0.73664, saving model to ../models/RNN.h5\n",
      "Epoch 38/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 95.0522 - ler: 0.7314 - val_loss: 94.7382 - val_ler: 0.7387\n",
      "\n",
      "Epoch 00038: ler improved from 0.73664 to 0.73143, saving model to ../models/RNN.h5\n",
      "Epoch 39/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 96.5575 - ler: 0.7277 - val_loss: 94.0639 - val_ler: 0.7453\n",
      "\n",
      "Epoch 00039: ler improved from 0.73143 to 0.72771, saving model to ../models/RNN.h5\n",
      "Epoch 40/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 93.7621 - ler: 0.7241 - val_loss: 92.4774 - val_ler: 0.7081\n",
      "\n",
      "Epoch 00040: ler improved from 0.72771 to 0.72408, saving model to ../models/RNN.h5\n",
      "Epoch 41/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 91.0178 - ler: 0.7140 - val_loss: 90.8861 - val_ler: 0.7246\n",
      "\n",
      "Epoch 00041: ler improved from 0.72408 to 0.71402, saving model to ../models/RNN.h5\n",
      "Epoch 42/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 91.3211 - ler: 0.7152 - val_loss: 89.8118 - val_ler: 0.7129\n",
      "\n",
      "Epoch 00042: ler did not improve from 0.71402\n",
      "Epoch 43/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 89.8926 - ler: 0.7084 - val_loss: 88.4634 - val_ler: 0.6955\n",
      "\n",
      "Epoch 00043: ler improved from 0.71402 to 0.70837, saving model to ../models/RNN.h5\n",
      "Epoch 44/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 88.6442 - ler: 0.7054 - val_loss: 88.1445 - val_ler: 0.6696\n",
      "\n",
      "Epoch 00044: ler improved from 0.70837 to 0.70543, saving model to ../models/RNN.h5\n",
      "Epoch 45/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 87.1365 - ler: 0.6971 - val_loss: 86.4819 - val_ler: 0.6973\n",
      "\n",
      "Epoch 00045: ler improved from 0.70543 to 0.69707, saving model to ../models/RNN.h5\n",
      "Epoch 46/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 85.9928 - ler: 0.6928 - val_loss: 85.0566 - val_ler: 0.6824\n",
      "\n",
      "Epoch 00046: ler improved from 0.69707 to 0.69278, saving model to ../models/RNN.h5\n",
      "Epoch 47/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 84.1256 - ler: 0.6906 - val_loss: 84.3607 - val_ler: 0.6814\n",
      "\n",
      "Epoch 00047: ler improved from 0.69278 to 0.69055, saving model to ../models/RNN.h5\n",
      "Epoch 48/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 83.8037 - ler: 0.6815 - val_loss: 83.5219 - val_ler: 0.6701\n",
      "\n",
      "Epoch 00048: ler improved from 0.69055 to 0.68149, saving model to ../models/RNN.h5\n",
      "Epoch 49/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 84.9172 - ler: 0.6755 - val_loss: 82.0680 - val_ler: 0.6769\n",
      "\n",
      "Epoch 00049: ler improved from 0.68149 to 0.67548, saving model to ../models/RNN.h5\n",
      "Epoch 50/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 82.1713 - ler: 0.6693 - val_loss: 80.8768 - val_ler: 0.6705\n",
      "\n",
      "Epoch 00050: ler improved from 0.67548 to 0.66927, saving model to ../models/RNN.h5\n",
      "Epoch 51/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 80.8666 - ler: 0.6679 - val_loss: 79.9694 - val_ler: 0.6597\n",
      "\n",
      "Epoch 00051: ler improved from 0.66927 to 0.66791, saving model to ../models/RNN.h5\n",
      "Epoch 52/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 79.4834 - ler: 0.6613 - val_loss: 78.9845 - val_ler: 0.6544\n",
      "\n",
      "Epoch 00052: ler improved from 0.66791 to 0.66126, saving model to ../models/RNN.h5\n",
      "Epoch 53/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 80.4835 - ler: 0.6540 - val_loss: 78.4353 - val_ler: 0.6532\n",
      "\n",
      "Epoch 00053: ler improved from 0.66126 to 0.65399, saving model to ../models/RNN.h5\n",
      "Epoch 54/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 77.8382 - ler: 0.6463 - val_loss: 76.9155 - val_ler: 0.6346\n",
      "\n",
      "Epoch 00054: ler improved from 0.65399 to 0.64633, saving model to ../models/RNN.h5\n",
      "Epoch 55/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 78.2725 - ler: 0.6450 - val_loss: 75.4483 - val_ler: 0.6324\n",
      "\n",
      "Epoch 00055: ler improved from 0.64633 to 0.64500, saving model to ../models/RNN.h5\n",
      "Epoch 56/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 75.4266 - ler: 0.6337 - val_loss: 74.8327 - val_ler: 0.6209\n",
      "\n",
      "Epoch 00056: ler improved from 0.64500 to 0.63373, saving model to ../models/RNN.h5\n",
      "Epoch 57/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 75.9772 - ler: 0.6297 - val_loss: 74.2026 - val_ler: 0.6244\n",
      "\n",
      "Epoch 00057: ler improved from 0.63373 to 0.62973, saving model to ../models/RNN.h5\n",
      "Epoch 58/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 74.8103 - ler: 0.6267 - val_loss: 73.1700 - val_ler: 0.6131\n",
      "\n",
      "Epoch 00058: ler improved from 0.62973 to 0.62666, saving model to ../models/RNN.h5\n",
      "Epoch 59/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 74.0355 - ler: 0.6214 - val_loss: 72.1825 - val_ler: 0.6030\n",
      "\n",
      "Epoch 00059: ler improved from 0.62666 to 0.62136, saving model to ../models/RNN.h5\n",
      "Epoch 60/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 72.0400 - ler: 0.6115 - val_loss: 71.0331 - val_ler: 0.6060\n",
      "\n",
      "Epoch 00060: ler improved from 0.62136 to 0.61153, saving model to ../models/RNN.h5\n",
      "Epoch 61/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 70.8540 - ler: 0.6060 - val_loss: 70.0088 - val_ler: 0.6046\n",
      "\n",
      "Epoch 00061: ler improved from 0.61153 to 0.60605, saving model to ../models/RNN.h5\n",
      "Epoch 62/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 71.9056 - ler: 0.6037 - val_loss: 69.2812 - val_ler: 0.5954\n",
      "\n",
      "Epoch 00062: ler improved from 0.60605 to 0.60370, saving model to ../models/RNN.h5\n",
      "Epoch 63/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 70.5290 - ler: 0.5966 - val_loss: 68.1634 - val_ler: 0.5796\n",
      "\n",
      "Epoch 00063: ler improved from 0.60370 to 0.59659, saving model to ../models/RNN.h5\n",
      "Epoch 64/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 66.5769 - ler: 0.5873 - val_loss: 67.2987 - val_ler: 0.5671\n",
      "\n",
      "Epoch 00064: ler improved from 0.59659 to 0.58726, saving model to ../models/RNN.h5\n",
      "Epoch 65/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 68.1119 - ler: 0.5839 - val_loss: 66.6567 - val_ler: 0.5635\n",
      "\n",
      "Epoch 00065: ler improved from 0.58726 to 0.58388, saving model to ../models/RNN.h5\n",
      "Epoch 66/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 67.6280 - ler: 0.5743 - val_loss: 65.4516 - val_ler: 0.5869\n",
      "\n",
      "Epoch 00066: ler improved from 0.58388 to 0.57428, saving model to ../models/RNN.h5\n",
      "Epoch 67/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 65.5427 - ler: 0.5711 - val_loss: 64.6731 - val_ler: 0.5609\n",
      "\n",
      "Epoch 00067: ler improved from 0.57428 to 0.57114, saving model to ../models/RNN.h5\n",
      "Epoch 68/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 64.8782 - ler: 0.5617 - val_loss: 63.4292 - val_ler: 0.5605\n",
      "\n",
      "Epoch 00068: ler improved from 0.57114 to 0.56167, saving model to ../models/RNN.h5\n",
      "Epoch 69/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 64.9154 - ler: 0.5582 - val_loss: 64.2295 - val_ler: 0.5586\n",
      "\n",
      "Epoch 00069: ler improved from 0.56167 to 0.55819, saving model to ../models/RNN.h5\n",
      "Epoch 70/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 63.3394 - ler: 0.5502 - val_loss: 62.1070 - val_ler: 0.5299\n",
      "\n",
      "Epoch 00070: ler improved from 0.55819 to 0.55017, saving model to ../models/RNN.h5\n",
      "Epoch 71/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 62.2957 - ler: 0.5473 - val_loss: 61.8737 - val_ler: 0.5417\n",
      "\n",
      "Epoch 00071: ler improved from 0.55017 to 0.54732, saving model to ../models/RNN.h5\n",
      "Epoch 72/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 60.8810 - ler: 0.5411 - val_loss: 60.3546 - val_ler: 0.5294\n",
      "\n",
      "Epoch 00072: ler improved from 0.54732 to 0.54110, saving model to ../models/RNN.h5\n",
      "Epoch 73/300\n",
      "46/46 [==============================] - 3s 74ms/step - loss: 60.4997 - ler: 0.5343 - val_loss: 59.2799 - val_ler: 0.5249\n",
      "\n",
      "Epoch 00073: ler improved from 0.54110 to 0.53427, saving model to ../models/RNN.h5\n",
      "Epoch 74/300\n",
      "46/46 [==============================] - 3s 74ms/step - loss: 60.7830 - ler: 0.5256 - val_loss: 58.7034 - val_ler: 0.5271\n",
      "\n",
      "Epoch 00074: ler improved from 0.53427 to 0.52559, saving model to ../models/RNN.h5\n",
      "Epoch 75/300\n",
      "46/46 [==============================] - 3s 74ms/step - loss: 58.9706 - ler: 0.5211 - val_loss: 57.3157 - val_ler: 0.5035\n",
      "\n",
      "Epoch 00075: ler improved from 0.52559 to 0.52110, saving model to ../models/RNN.h5\n",
      "Epoch 76/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 59.2460 - ler: 0.5161 - val_loss: 57.0728 - val_ler: 0.5016\n",
      "\n",
      "Epoch 00076: ler improved from 0.52110 to 0.51611, saving model to ../models/RNN.h5\n",
      "Epoch 77/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 58.9450 - ler: 0.5045 - val_loss: 56.2812 - val_ler: 0.4918\n",
      "\n",
      "Epoch 00077: ler improved from 0.51611 to 0.50455, saving model to ../models/RNN.h5\n",
      "Epoch 78/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 56.5932 - ler: 0.4974 - val_loss: 55.1683 - val_ler: 0.4849\n",
      "\n",
      "Epoch 00078: ler improved from 0.50455 to 0.49736, saving model to ../models/RNN.h5\n",
      "Epoch 79/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 58.9074 - ler: 0.4961 - val_loss: 54.2772 - val_ler: 0.4760\n",
      "\n",
      "Epoch 00079: ler improved from 0.49736 to 0.49615, saving model to ../models/RNN.h5\n",
      "Epoch 80/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 55.4080 - ler: 0.4908 - val_loss: 53.8124 - val_ler: 0.4634\n",
      "\n",
      "Epoch 00080: ler improved from 0.49615 to 0.49083, saving model to ../models/RNN.h5\n",
      "Epoch 81/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 54.0637 - ler: 0.4821 - val_loss: 52.9260 - val_ler: 0.4495\n",
      "\n",
      "Epoch 00081: ler improved from 0.49083 to 0.48206, saving model to ../models/RNN.h5\n",
      "Epoch 82/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 53.9393 - ler: 0.4762 - val_loss: 51.9590 - val_ler: 0.4643\n",
      "\n",
      "Epoch 00082: ler improved from 0.48206 to 0.47619, saving model to ../models/RNN.h5\n",
      "Epoch 83/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 53.4222 - ler: 0.4684 - val_loss: 52.8360 - val_ler: 0.4627\n",
      "\n",
      "Epoch 00083: ler improved from 0.47619 to 0.46845, saving model to ../models/RNN.h5\n",
      "Epoch 84/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 53.3314 - ler: 0.4655 - val_loss: 51.8199 - val_ler: 0.4726\n",
      "\n",
      "Epoch 00084: ler improved from 0.46845 to 0.46551, saving model to ../models/RNN.h5\n",
      "Epoch 85/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 52.0308 - ler: 0.4567 - val_loss: 50.3104 - val_ler: 0.4494\n",
      "\n",
      "Epoch 00085: ler improved from 0.46551 to 0.45666, saving model to ../models/RNN.h5\n",
      "Epoch 86/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 51.9167 - ler: 0.4502 - val_loss: 50.1381 - val_ler: 0.4454\n",
      "\n",
      "Epoch 00086: ler improved from 0.45666 to 0.45021, saving model to ../models/RNN.h5\n",
      "Epoch 87/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 49.0345 - ler: 0.4432 - val_loss: 48.1701 - val_ler: 0.4186\n",
      "\n",
      "Epoch 00087: ler improved from 0.45021 to 0.44320, saving model to ../models/RNN.h5\n",
      "Epoch 88/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 48.9119 - ler: 0.4321 - val_loss: 47.0883 - val_ler: 0.4178\n",
      "\n",
      "Epoch 00088: ler improved from 0.44320 to 0.43214, saving model to ../models/RNN.h5\n",
      "Epoch 89/300\n",
      "46/46 [==============================] - 3s 74ms/step - loss: 48.1241 - ler: 0.4277 - val_loss: 47.5387 - val_ler: 0.4139\n",
      "\n",
      "Epoch 00089: ler improved from 0.43214 to 0.42772, saving model to ../models/RNN.h5\n",
      "Epoch 90/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 48.7041 - ler: 0.4322 - val_loss: 46.6796 - val_ler: 0.4107\n",
      "\n",
      "Epoch 00090: ler did not improve from 0.42772\n",
      "Epoch 91/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 47.0504 - ler: 0.4244 - val_loss: 46.2872 - val_ler: 0.3971\n",
      "\n",
      "Epoch 00091: ler improved from 0.42772 to 0.42440, saving model to ../models/RNN.h5\n",
      "Epoch 92/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 48.2660 - ler: 0.4183 - val_loss: 44.2788 - val_ler: 0.3757\n",
      "\n",
      "Epoch 00092: ler improved from 0.42440 to 0.41828, saving model to ../models/RNN.h5\n",
      "Epoch 93/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 46.2141 - ler: 0.4124 - val_loss: 45.1916 - val_ler: 0.4067\n",
      "\n",
      "Epoch 00093: ler improved from 0.41828 to 0.41241, saving model to ../models/RNN.h5\n",
      "Epoch 94/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 45.9747 - ler: 0.4011 - val_loss: 43.2912 - val_ler: 0.3861\n",
      "\n",
      "Epoch 00094: ler improved from 0.41241 to 0.40106, saving model to ../models/RNN.h5\n",
      "Epoch 95/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 45.2735 - ler: 0.3997 - val_loss: 44.1343 - val_ler: 0.3868\n",
      "\n",
      "Epoch 00095: ler improved from 0.40106 to 0.39974, saving model to ../models/RNN.h5\n",
      "Epoch 96/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 44.3680 - ler: 0.3955 - val_loss: 43.2310 - val_ler: 0.3955\n",
      "\n",
      "Epoch 00096: ler improved from 0.39974 to 0.39553, saving model to ../models/RNN.h5\n",
      "Epoch 97/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 43.0562 - ler: 0.3901 - val_loss: 41.9359 - val_ler: 0.3752\n",
      "\n",
      "Epoch 00097: ler improved from 0.39553 to 0.39014, saving model to ../models/RNN.h5\n",
      "Epoch 98/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 44.3096 - ler: 0.3845 - val_loss: 41.3693 - val_ler: 0.3576\n",
      "\n",
      "Epoch 00098: ler improved from 0.39014 to 0.38449, saving model to ../models/RNN.h5\n",
      "Epoch 99/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 42.3960 - ler: 0.3815 - val_loss: 41.9878 - val_ler: 0.3659\n",
      "\n",
      "Epoch 00099: ler improved from 0.38449 to 0.38150, saving model to ../models/RNN.h5\n",
      "Epoch 100/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 41.1616 - ler: 0.3691 - val_loss: 39.4403 - val_ler: 0.3577\n",
      "\n",
      "Epoch 00100: ler improved from 0.38150 to 0.36905, saving model to ../models/RNN.h5\n",
      "Epoch 101/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 42.5945 - ler: 0.3650 - val_loss: 39.5911 - val_ler: 0.3411\n",
      "\n",
      "Epoch 00101: ler improved from 0.36905 to 0.36501, saving model to ../models/RNN.h5\n",
      "Epoch 102/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 40.0240 - ler: 0.3638 - val_loss: 38.6841 - val_ler: 0.3484\n",
      "\n",
      "Epoch 00102: ler improved from 0.36501 to 0.36375, saving model to ../models/RNN.h5\n",
      "Epoch 103/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 40.0642 - ler: 0.3551 - val_loss: 38.1980 - val_ler: 0.3332\n",
      "\n",
      "Epoch 00103: ler improved from 0.36375 to 0.35513, saving model to ../models/RNN.h5\n",
      "Epoch 104/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 39.9688 - ler: 0.3507 - val_loss: 37.7510 - val_ler: 0.3242\n",
      "\n",
      "Epoch 00104: ler improved from 0.35513 to 0.35070, saving model to ../models/RNN.h5\n",
      "Epoch 105/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 38.8165 - ler: 0.3399 - val_loss: 36.6653 - val_ler: 0.3173\n",
      "\n",
      "Epoch 00105: ler improved from 0.35070 to 0.33988, saving model to ../models/RNN.h5\n",
      "Epoch 106/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 37.0259 - ler: 0.3344 - val_loss: 36.4369 - val_ler: 0.3105\n",
      "\n",
      "Epoch 00106: ler improved from 0.33988 to 0.33441, saving model to ../models/RNN.h5\n",
      "Epoch 107/300\n",
      "46/46 [==============================] - 3s 74ms/step - loss: 37.1185 - ler: 0.3275 - val_loss: 34.8324 - val_ler: 0.3028\n",
      "\n",
      "Epoch 00107: ler improved from 0.33441 to 0.32746, saving model to ../models/RNN.h5\n",
      "Epoch 108/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 37.4469 - ler: 0.3267 - val_loss: 35.5617 - val_ler: 0.2962\n",
      "\n",
      "Epoch 00108: ler improved from 0.32746 to 0.32672, saving model to ../models/RNN.h5\n",
      "Epoch 109/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 36.9254 - ler: 0.3295 - val_loss: 35.3005 - val_ler: 0.3097\n",
      "\n",
      "Epoch 00109: ler did not improve from 0.32672\n",
      "Epoch 110/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 37.8228 - ler: 0.3313 - val_loss: 36.9035 - val_ler: 0.3354\n",
      "\n",
      "Epoch 00110: ler did not improve from 0.32672\n",
      "Epoch 111/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 36.7781 - ler: 0.3203 - val_loss: 34.5140 - val_ler: 0.2848\n",
      "\n",
      "Epoch 00111: ler improved from 0.32672 to 0.32028, saving model to ../models/RNN.h5\n",
      "Epoch 112/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 35.1907 - ler: 0.3063 - val_loss: 32.9193 - val_ler: 0.2706\n",
      "\n",
      "Epoch 00112: ler improved from 0.32028 to 0.30630, saving model to ../models/RNN.h5\n",
      "Epoch 113/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 34.7602 - ler: 0.3082 - val_loss: 33.4861 - val_ler: 0.2958\n",
      "\n",
      "Epoch 00113: ler did not improve from 0.30630\n",
      "Epoch 114/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 34.5009 - ler: 0.3053 - val_loss: 33.2400 - val_ler: 0.2849\n",
      "\n",
      "Epoch 00114: ler improved from 0.30630 to 0.30528, saving model to ../models/RNN.h5\n",
      "Epoch 115/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 34.6077 - ler: 0.3036 - val_loss: 32.2722 - val_ler: 0.2713\n",
      "\n",
      "Epoch 00115: ler improved from 0.30528 to 0.30361, saving model to ../models/RNN.h5\n",
      "Epoch 116/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 33.2533 - ler: 0.2873 - val_loss: 31.2876 - val_ler: 0.2712\n",
      "\n",
      "Epoch 00116: ler improved from 0.30361 to 0.28731, saving model to ../models/RNN.h5\n",
      "Epoch 117/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 33.8949 - ler: 0.2895 - val_loss: 30.7478 - val_ler: 0.2553\n",
      "\n",
      "Epoch 00117: ler did not improve from 0.28731\n",
      "Epoch 118/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 32.1860 - ler: 0.2816 - val_loss: 30.1719 - val_ler: 0.2592\n",
      "\n",
      "Epoch 00118: ler improved from 0.28731 to 0.28164, saving model to ../models/RNN.h5\n",
      "Epoch 119/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 31.1753 - ler: 0.2772 - val_loss: 30.4047 - val_ler: 0.2726\n",
      "\n",
      "Epoch 00119: ler improved from 0.28164 to 0.27720, saving model to ../models/RNN.h5\n",
      "Epoch 120/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 32.0398 - ler: 0.2765 - val_loss: 29.9680 - val_ler: 0.2400\n",
      "\n",
      "Epoch 00120: ler improved from 0.27720 to 0.27652, saving model to ../models/RNN.h5\n",
      "Epoch 121/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 31.4819 - ler: 0.2691 - val_loss: 29.6290 - val_ler: 0.2488\n",
      "\n",
      "Epoch 00121: ler improved from 0.27652 to 0.26915, saving model to ../models/RNN.h5\n",
      "Epoch 122/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 31.0333 - ler: 0.2706 - val_loss: 30.3673 - val_ler: 0.2629\n",
      "\n",
      "Epoch 00122: ler did not improve from 0.26915\n",
      "Epoch 123/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 30.5973 - ler: 0.2665 - val_loss: 28.2226 - val_ler: 0.2359\n",
      "\n",
      "Epoch 00123: ler improved from 0.26915 to 0.26648, saving model to ../models/RNN.h5\n",
      "Epoch 124/300\n",
      "46/46 [==============================] - 3s 74ms/step - loss: 30.2476 - ler: 0.2678 - val_loss: 28.6361 - val_ler: 0.2254\n",
      "\n",
      "Epoch 00124: ler did not improve from 0.26648\n",
      "Epoch 125/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 29.9691 - ler: 0.2596 - val_loss: 27.9461 - val_ler: 0.2271\n",
      "\n",
      "Epoch 00125: ler improved from 0.26648 to 0.25957, saving model to ../models/RNN.h5\n",
      "Epoch 126/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 28.1249 - ler: 0.2542 - val_loss: 26.7429 - val_ler: 0.2122\n",
      "\n",
      "Epoch 00126: ler improved from 0.25957 to 0.25415, saving model to ../models/RNN.h5\n",
      "Epoch 127/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 28.4765 - ler: 0.2466 - val_loss: 26.7946 - val_ler: 0.2181\n",
      "\n",
      "Epoch 00127: ler improved from 0.25415 to 0.24661, saving model to ../models/RNN.h5\n",
      "Epoch 128/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 27.7565 - ler: 0.2409 - val_loss: 26.6605 - val_ler: 0.2230\n",
      "\n",
      "Epoch 00128: ler improved from 0.24661 to 0.24089, saving model to ../models/RNN.h5\n",
      "Epoch 129/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 28.7461 - ler: 0.2399 - val_loss: 27.0619 - val_ler: 0.2079\n",
      "\n",
      "Epoch 00129: ler improved from 0.24089 to 0.23992, saving model to ../models/RNN.h5\n",
      "Epoch 130/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 27.8362 - ler: 0.2383 - val_loss: 25.7500 - val_ler: 0.1916\n",
      "\n",
      "Epoch 00130: ler improved from 0.23992 to 0.23830, saving model to ../models/RNN.h5\n",
      "Epoch 131/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 27.4884 - ler: 0.2324 - val_loss: 25.4092 - val_ler: 0.1973\n",
      "\n",
      "Epoch 00131: ler improved from 0.23830 to 0.23239, saving model to ../models/RNN.h5\n",
      "Epoch 132/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 26.7855 - ler: 0.2339 - val_loss: 26.0801 - val_ler: 0.2148\n",
      "\n",
      "Epoch 00132: ler did not improve from 0.23239\n",
      "Epoch 133/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 27.6632 - ler: 0.2256 - val_loss: 25.3804 - val_ler: 0.2105\n",
      "\n",
      "Epoch 00133: ler improved from 0.23239 to 0.22558, saving model to ../models/RNN.h5\n",
      "Epoch 134/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 26.4924 - ler: 0.2213 - val_loss: 24.2633 - val_ler: 0.1994\n",
      "\n",
      "Epoch 00134: ler improved from 0.22558 to 0.22134, saving model to ../models/RNN.h5\n",
      "Epoch 135/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 24.6853 - ler: 0.2178 - val_loss: 24.3904 - val_ler: 0.1828\n",
      "\n",
      "Epoch 00135: ler improved from 0.22134 to 0.21777, saving model to ../models/RNN.h5\n",
      "Epoch 136/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 25.6843 - ler: 0.2111 - val_loss: 23.0163 - val_ler: 0.1751\n",
      "\n",
      "Epoch 00136: ler improved from 0.21777 to 0.21109, saving model to ../models/RNN.h5\n",
      "Epoch 137/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 25.1192 - ler: 0.2186 - val_loss: 23.7005 - val_ler: 0.1844\n",
      "\n",
      "Epoch 00137: ler did not improve from 0.21109\n",
      "Epoch 138/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 23.9658 - ler: 0.2059 - val_loss: 23.5608 - val_ler: 0.1862\n",
      "\n",
      "Epoch 00138: ler improved from 0.21109 to 0.20594, saving model to ../models/RNN.h5\n",
      "Epoch 139/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 24.1200 - ler: 0.2031 - val_loss: 22.6806 - val_ler: 0.1703\n",
      "\n",
      "Epoch 00139: ler improved from 0.20594 to 0.20310, saving model to ../models/RNN.h5\n",
      "Epoch 140/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 23.3546 - ler: 0.1950 - val_loss: 22.3904 - val_ler: 0.1642\n",
      "\n",
      "Epoch 00140: ler improved from 0.20310 to 0.19503, saving model to ../models/RNN.h5\n",
      "Epoch 141/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 24.5669 - ler: 0.1999 - val_loss: 22.3297 - val_ler: 0.1730\n",
      "\n",
      "Epoch 00141: ler did not improve from 0.19503\n",
      "Epoch 142/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 23.2806 - ler: 0.1907 - val_loss: 21.2018 - val_ler: 0.1668\n",
      "\n",
      "Epoch 00142: ler improved from 0.19503 to 0.19066, saving model to ../models/RNN.h5\n",
      "Epoch 143/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 23.2051 - ler: 0.1919 - val_loss: 21.1891 - val_ler: 0.1606\n",
      "\n",
      "Epoch 00143: ler did not improve from 0.19066\n",
      "Epoch 144/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 22.6090 - ler: 0.1869 - val_loss: 21.6974 - val_ler: 0.1739\n",
      "\n",
      "Epoch 00144: ler improved from 0.19066 to 0.18691, saving model to ../models/RNN.h5\n",
      "Epoch 145/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 22.4365 - ler: 0.1923 - val_loss: 21.6239 - val_ler: 0.1696\n",
      "\n",
      "Epoch 00145: ler did not improve from 0.18691\n",
      "Epoch 146/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 23.0459 - ler: 0.1863 - val_loss: 20.8787 - val_ler: 0.1517\n",
      "\n",
      "Epoch 00146: ler improved from 0.18691 to 0.18632, saving model to ../models/RNN.h5\n",
      "Epoch 147/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 22.3545 - ler: 0.1793 - val_loss: 21.2675 - val_ler: 0.1718\n",
      "\n",
      "Epoch 00147: ler improved from 0.18632 to 0.17926, saving model to ../models/RNN.h5\n",
      "Epoch 148/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 21.5079 - ler: 0.1766 - val_loss: 19.9064 - val_ler: 0.1519\n",
      "\n",
      "Epoch 00148: ler improved from 0.17926 to 0.17661, saving model to ../models/RNN.h5\n",
      "Epoch 149/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 20.6590 - ler: 0.1714 - val_loss: 19.4204 - val_ler: 0.1512\n",
      "\n",
      "Epoch 00149: ler improved from 0.17661 to 0.17140, saving model to ../models/RNN.h5\n",
      "Epoch 150/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 20.1237 - ler: 0.1729 - val_loss: 19.2204 - val_ler: 0.1411\n",
      "\n",
      "Epoch 00150: ler did not improve from 0.17140\n",
      "Epoch 151/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 20.4182 - ler: 0.1716 - val_loss: 19.6317 - val_ler: 0.1527\n",
      "\n",
      "Epoch 00151: ler did not improve from 0.17140\n",
      "Epoch 152/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 20.0038 - ler: 0.1680 - val_loss: 19.2603 - val_ler: 0.1507\n",
      "\n",
      "Epoch 00152: ler improved from 0.17140 to 0.16800, saving model to ../models/RNN.h5\n",
      "Epoch 153/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 20.5994 - ler: 0.1675 - val_loss: 18.3625 - val_ler: 0.1401\n",
      "\n",
      "Epoch 00153: ler improved from 0.16800 to 0.16746, saving model to ../models/RNN.h5\n",
      "Epoch 154/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 20.2695 - ler: 0.1577 - val_loss: 18.2093 - val_ler: 0.1432\n",
      "\n",
      "Epoch 00154: ler improved from 0.16746 to 0.15766, saving model to ../models/RNN.h5\n",
      "Epoch 155/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 19.6558 - ler: 0.1578 - val_loss: 18.8898 - val_ler: 0.1469\n",
      "\n",
      "Epoch 00155: ler did not improve from 0.15766\n",
      "Epoch 156/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 21.0445 - ler: 0.1660 - val_loss: 18.3213 - val_ler: 0.1410\n",
      "\n",
      "Epoch 00156: ler did not improve from 0.15766\n",
      "Epoch 157/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 19.5057 - ler: 0.1525 - val_loss: 17.5108 - val_ler: 0.1306\n",
      "\n",
      "Epoch 00157: ler improved from 0.15766 to 0.15248, saving model to ../models/RNN.h5\n",
      "Epoch 158/300\n",
      "46/46 [==============================] - 3s 74ms/step - loss: 18.1036 - ler: 0.1489 - val_loss: 17.1614 - val_ler: 0.1265\n",
      "\n",
      "Epoch 00158: ler improved from 0.15248 to 0.14892, saving model to ../models/RNN.h5\n",
      "Epoch 159/300\n",
      "46/46 [==============================] - 3s 74ms/step - loss: 18.6364 - ler: 0.1480 - val_loss: 17.2967 - val_ler: 0.1240\n",
      "\n",
      "Epoch 00159: ler improved from 0.14892 to 0.14804, saving model to ../models/RNN.h5\n",
      "Epoch 160/300\n",
      "46/46 [==============================] - 3s 74ms/step - loss: 19.1231 - ler: 0.1507 - val_loss: 17.2225 - val_ler: 0.1340\n",
      "\n",
      "Epoch 00160: ler did not improve from 0.14804\n",
      "Epoch 161/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 18.6042 - ler: 0.1478 - val_loss: 16.8222 - val_ler: 0.1220\n",
      "\n",
      "Epoch 00161: ler improved from 0.14804 to 0.14778, saving model to ../models/RNN.h5\n",
      "Epoch 162/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 17.9055 - ler: 0.1392 - val_loss: 16.1672 - val_ler: 0.1155\n",
      "\n",
      "Epoch 00162: ler improved from 0.14778 to 0.13923, saving model to ../models/RNN.h5\n",
      "Epoch 163/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 18.2613 - ler: 0.1378 - val_loss: 17.3003 - val_ler: 0.1314\n",
      "\n",
      "Epoch 00163: ler improved from 0.13923 to 0.13781, saving model to ../models/RNN.h5\n",
      "Epoch 164/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 19.2191 - ler: 0.1470 - val_loss: 16.3898 - val_ler: 0.1205\n",
      "\n",
      "Epoch 00164: ler did not improve from 0.13781\n",
      "Epoch 165/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 18.5447 - ler: 0.1505 - val_loss: 16.5038 - val_ler: 0.1221\n",
      "\n",
      "Epoch 00165: ler did not improve from 0.13781\n",
      "Epoch 166/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 17.8345 - ler: 0.1434 - val_loss: 16.3272 - val_ler: 0.1210\n",
      "\n",
      "Epoch 00166: ler did not improve from 0.13781\n",
      "Epoch 167/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 18.2461 - ler: 0.1513 - val_loss: 17.1774 - val_ler: 0.1375\n",
      "\n",
      "Epoch 00167: ler did not improve from 0.13781\n",
      "Epoch 168/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 17.4676 - ler: 0.1354 - val_loss: 15.4327 - val_ler: 0.1083\n",
      "\n",
      "Epoch 00168: ler improved from 0.13781 to 0.13536, saving model to ../models/RNN.h5\n",
      "Epoch 169/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 16.8074 - ler: 0.1288 - val_loss: 15.0303 - val_ler: 0.1060\n",
      "\n",
      "Epoch 00169: ler improved from 0.13536 to 0.12883, saving model to ../models/RNN.h5\n",
      "Epoch 170/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 16.1738 - ler: 0.1182 - val_loss: 15.0607 - val_ler: 0.1069\n",
      "\n",
      "Epoch 00170: ler improved from 0.12883 to 0.11824, saving model to ../models/RNN.h5\n",
      "Epoch 171/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 16.8234 - ler: 0.1239 - val_loss: 14.4507 - val_ler: 0.0969\n",
      "\n",
      "Epoch 00171: ler did not improve from 0.11824\n",
      "Epoch 172/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 15.4653 - ler: 0.1199 - val_loss: 14.5481 - val_ler: 0.0947\n",
      "\n",
      "Epoch 00172: ler did not improve from 0.11824\n",
      "Epoch 173/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 16.8656 - ler: 0.1257 - val_loss: 14.4915 - val_ler: 0.0949\n",
      "\n",
      "Epoch 00173: ler did not improve from 0.11824\n",
      "Epoch 174/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 15.0597 - ler: 0.1162 - val_loss: 13.7011 - val_ler: 0.0895\n",
      "\n",
      "Epoch 00174: ler improved from 0.11824 to 0.11619, saving model to ../models/RNN.h5\n",
      "Epoch 175/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 14.4566 - ler: 0.1090 - val_loss: 13.3691 - val_ler: 0.0894\n",
      "\n",
      "Epoch 00175: ler improved from 0.11619 to 0.10903, saving model to ../models/RNN.h5\n",
      "Epoch 176/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 14.6692 - ler: 0.1097 - val_loss: 13.8088 - val_ler: 0.0879\n",
      "\n",
      "Epoch 00176: ler did not improve from 0.10903\n",
      "Epoch 177/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 15.3076 - ler: 0.1175 - val_loss: 14.3053 - val_ler: 0.0937\n",
      "\n",
      "Epoch 00177: ler did not improve from 0.10903\n",
      "Epoch 178/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 15.6249 - ler: 0.1237 - val_loss: 13.8022 - val_ler: 0.0943\n",
      "\n",
      "Epoch 00178: ler did not improve from 0.10903\n",
      "Epoch 179/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 14.6439 - ler: 0.1101 - val_loss: 13.1472 - val_ler: 0.0889\n",
      "\n",
      "Epoch 00179: ler did not improve from 0.10903\n",
      "Epoch 180/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 13.6020 - ler: 0.1013 - val_loss: 12.7335 - val_ler: 0.0779\n",
      "\n",
      "Epoch 00180: ler improved from 0.10903 to 0.10128, saving model to ../models/RNN.h5\n",
      "Epoch 181/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 15.2645 - ler: 0.1101 - val_loss: 12.8344 - val_ler: 0.0839\n",
      "\n",
      "Epoch 00181: ler did not improve from 0.10128\n",
      "Epoch 182/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 13.9354 - ler: 0.1022 - val_loss: 12.8196 - val_ler: 0.0851\n",
      "\n",
      "Epoch 00182: ler did not improve from 0.10128\n",
      "Epoch 183/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 14.4724 - ler: 0.1079 - val_loss: 12.8363 - val_ler: 0.0799\n",
      "\n",
      "Epoch 00183: ler did not improve from 0.10128\n",
      "Epoch 184/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 14.3006 - ler: 0.1005 - val_loss: 12.5142 - val_ler: 0.0794\n",
      "\n",
      "Epoch 00184: ler improved from 0.10128 to 0.10048, saving model to ../models/RNN.h5\n",
      "Epoch 185/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 13.8259 - ler: 0.1019 - val_loss: 12.6798 - val_ler: 0.0813\n",
      "\n",
      "Epoch 00185: ler did not improve from 0.10048\n",
      "Epoch 186/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 14.2306 - ler: 0.0984 - val_loss: 11.9416 - val_ler: 0.0767\n",
      "\n",
      "Epoch 00186: ler improved from 0.10048 to 0.09836, saving model to ../models/RNN.h5\n",
      "Epoch 187/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 13.9895 - ler: 0.0989 - val_loss: 11.9682 - val_ler: 0.0779\n",
      "\n",
      "Epoch 00187: ler did not improve from 0.09836\n",
      "Epoch 188/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 13.2581 - ler: 0.0971 - val_loss: 11.7972 - val_ler: 0.0740\n",
      "\n",
      "Epoch 00188: ler improved from 0.09836 to 0.09705, saving model to ../models/RNN.h5\n",
      "Epoch 189/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 13.2750 - ler: 0.0935 - val_loss: 11.5839 - val_ler: 0.0741\n",
      "\n",
      "Epoch 00189: ler improved from 0.09705 to 0.09346, saving model to ../models/RNN.h5\n",
      "Epoch 190/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 12.7504 - ler: 0.0895 - val_loss: 11.5007 - val_ler: 0.0733\n",
      "\n",
      "Epoch 00190: ler improved from 0.09346 to 0.08953, saving model to ../models/RNN.h5\n",
      "Epoch 191/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 12.0280 - ler: 0.0849 - val_loss: 11.0869 - val_ler: 0.0676\n",
      "\n",
      "Epoch 00191: ler improved from 0.08953 to 0.08494, saving model to ../models/RNN.h5\n",
      "Epoch 192/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 12.3587 - ler: 0.0892 - val_loss: 11.2743 - val_ler: 0.0692\n",
      "\n",
      "Epoch 00192: ler did not improve from 0.08494\n",
      "Epoch 193/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 14.0474 - ler: 0.1084 - val_loss: 12.0079 - val_ler: 0.0778\n",
      "\n",
      "Epoch 00193: ler did not improve from 0.08494\n",
      "Epoch 194/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 13.6097 - ler: 0.0944 - val_loss: 11.9407 - val_ler: 0.0754\n",
      "\n",
      "Epoch 00194: ler did not improve from 0.08494\n",
      "Epoch 195/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 11.7606 - ler: 0.0832 - val_loss: 11.2895 - val_ler: 0.0692\n",
      "\n",
      "Epoch 00195: ler improved from 0.08494 to 0.08318, saving model to ../models/RNN.h5\n",
      "Epoch 196/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 11.8774 - ler: 0.0782 - val_loss: 10.3595 - val_ler: 0.0590\n",
      "\n",
      "Epoch 00196: ler improved from 0.08318 to 0.07818, saving model to ../models/RNN.h5\n",
      "Epoch 197/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 11.1844 - ler: 0.0751 - val_loss: 10.1711 - val_ler: 0.0569\n",
      "\n",
      "Epoch 00197: ler improved from 0.07818 to 0.07510, saving model to ../models/RNN.h5\n",
      "Epoch 198/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 11.5158 - ler: 0.0811 - val_loss: 10.7506 - val_ler: 0.0636\n",
      "\n",
      "Epoch 00198: ler did not improve from 0.07510\n",
      "Epoch 199/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 13.1616 - ler: 0.1031 - val_loss: 11.7492 - val_ler: 0.0750\n",
      "\n",
      "Epoch 00199: ler did not improve from 0.07510\n",
      "Epoch 200/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 12.9384 - ler: 0.0894 - val_loss: 11.2803 - val_ler: 0.0725\n",
      "\n",
      "Epoch 00200: ler did not improve from 0.07510\n",
      "Epoch 201/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 12.2212 - ler: 0.0850 - val_loss: 10.8177 - val_ler: 0.0649\n",
      "\n",
      "Epoch 00201: ler did not improve from 0.07510\n",
      "Epoch 202/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 12.1223 - ler: 0.0844 - val_loss: 10.7482 - val_ler: 0.0672\n",
      "\n",
      "Epoch 00202: ler did not improve from 0.07510\n",
      "Epoch 203/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 12.6454 - ler: 0.0894 - val_loss: 10.6679 - val_ler: 0.0657\n",
      "\n",
      "Epoch 00203: ler did not improve from 0.07510\n",
      "Epoch 204/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 12.0643 - ler: 0.0875 - val_loss: 10.3939 - val_ler: 0.0649\n",
      "\n",
      "Epoch 00204: ler did not improve from 0.07510\n",
      "Epoch 205/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 11.9861 - ler: 0.0871 - val_loss: 10.3271 - val_ler: 0.0627\n",
      "\n",
      "Epoch 00205: ler did not improve from 0.07510\n",
      "Epoch 206/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 11.3654 - ler: 0.0750 - val_loss: 9.4525 - val_ler: 0.0543\n",
      "\n",
      "Epoch 00206: ler improved from 0.07510 to 0.07497, saving model to ../models/RNN.h5\n",
      "Epoch 207/300\n",
      "46/46 [==============================] - 3s 72ms/step - loss: 10.5360 - ler: 0.0708 - val_loss: 9.3464 - val_ler: 0.0543\n",
      "\n",
      "Epoch 00207: ler improved from 0.07497 to 0.07078, saving model to ../models/RNN.h5\n",
      "Epoch 208/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 10.8846 - ler: 0.0672 - val_loss: 9.4902 - val_ler: 0.0605\n",
      "\n",
      "Epoch 00208: ler improved from 0.07078 to 0.06725, saving model to ../models/RNN.h5\n",
      "Epoch 209/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 11.0556 - ler: 0.0694 - val_loss: 9.3063 - val_ler: 0.0537\n",
      "\n",
      "Epoch 00209: ler did not improve from 0.06725\n",
      "Epoch 210/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 10.3382 - ler: 0.0713 - val_loss: 10.4283 - val_ler: 0.0659\n",
      "\n",
      "Epoch 00210: ler did not improve from 0.06725\n",
      "Epoch 211/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 10.7007 - ler: 0.0713 - val_loss: 9.1534 - val_ler: 0.0503\n",
      "\n",
      "Epoch 00211: ler did not improve from 0.06725\n",
      "Epoch 212/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 10.7766 - ler: 0.0626 - val_loss: 8.8256 - val_ler: 0.0482\n",
      "\n",
      "Epoch 00212: ler improved from 0.06725 to 0.06262, saving model to ../models/RNN.h5\n",
      "Epoch 213/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 9.1984 - ler: 0.0583 - val_loss: 8.7032 - val_ler: 0.0461\n",
      "\n",
      "Epoch 00213: ler improved from 0.06262 to 0.05828, saving model to ../models/RNN.h5\n",
      "Epoch 214/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 9.8917 - ler: 0.0592 - val_loss: 8.4215 - val_ler: 0.0446\n",
      "\n",
      "Epoch 00214: ler did not improve from 0.05828\n",
      "Epoch 215/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 9.4180 - ler: 0.0622 - val_loss: 8.3577 - val_ler: 0.0440\n",
      "\n",
      "Epoch 00215: ler did not improve from 0.05828\n",
      "Epoch 216/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 9.8507 - ler: 0.0626 - val_loss: 8.5518 - val_ler: 0.0471\n",
      "\n",
      "Epoch 00216: ler did not improve from 0.05828\n",
      "Epoch 217/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 10.1433 - ler: 0.0667 - val_loss: 8.4324 - val_ler: 0.0474\n",
      "\n",
      "Epoch 00217: ler did not improve from 0.05828\n",
      "Epoch 218/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 9.2868 - ler: 0.0614 - val_loss: 8.4077 - val_ler: 0.0446\n",
      "\n",
      "Epoch 00218: ler did not improve from 0.05828\n",
      "Epoch 219/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 9.7127 - ler: 0.0640 - val_loss: 8.4138 - val_ler: 0.0457\n",
      "\n",
      "Epoch 00219: ler did not improve from 0.05828\n",
      "Epoch 220/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 9.9348 - ler: 0.0641 - val_loss: 8.4064 - val_ler: 0.0430\n",
      "\n",
      "Epoch 00220: ler did not improve from 0.05828\n",
      "Epoch 221/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 9.6634 - ler: 0.0585 - val_loss: 8.0314 - val_ler: 0.0419\n",
      "\n",
      "Epoch 00221: ler did not improve from 0.05828\n",
      "Epoch 222/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 9.0627 - ler: 0.0558 - val_loss: 7.9960 - val_ler: 0.0402\n",
      "\n",
      "Epoch 00222: ler improved from 0.05828 to 0.05577, saving model to ../models/RNN.h5\n",
      "Epoch 223/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 9.3231 - ler: 0.0553 - val_loss: 8.1039 - val_ler: 0.0462\n",
      "\n",
      "Epoch 00223: ler improved from 0.05577 to 0.05534, saving model to ../models/RNN.h5\n",
      "Epoch 224/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 9.3542 - ler: 0.0555 - val_loss: 8.0573 - val_ler: 0.0410\n",
      "\n",
      "Epoch 00224: ler did not improve from 0.05534\n",
      "Epoch 225/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 8.8115 - ler: 0.0516 - val_loss: 7.4067 - val_ler: 0.0366\n",
      "\n",
      "Epoch 00225: ler improved from 0.05534 to 0.05159, saving model to ../models/RNN.h5\n",
      "Epoch 226/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 8.5074 - ler: 0.0443 - val_loss: 7.1894 - val_ler: 0.0339\n",
      "\n",
      "Epoch 00226: ler improved from 0.05159 to 0.04431, saving model to ../models/RNN.h5\n",
      "Epoch 227/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 8.1050 - ler: 0.0449 - val_loss: 7.0456 - val_ler: 0.0339\n",
      "\n",
      "Epoch 00227: ler did not improve from 0.04431\n",
      "Epoch 228/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 8.5533 - ler: 0.0545 - val_loss: 8.7339 - val_ler: 0.0513\n",
      "\n",
      "Epoch 00228: ler did not improve from 0.04431\n",
      "Epoch 229/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 8.9257 - ler: 0.0507 - val_loss: 7.5398 - val_ler: 0.0387\n",
      "\n",
      "Epoch 00229: ler did not improve from 0.04431\n",
      "Epoch 230/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 8.4471 - ler: 0.0448 - val_loss: 6.8184 - val_ler: 0.0321\n",
      "\n",
      "Epoch 00230: ler did not improve from 0.04431\n",
      "Epoch 231/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 7.7937 - ler: 0.0431 - val_loss: 7.4095 - val_ler: 0.0392\n",
      "\n",
      "Epoch 00231: ler improved from 0.04431 to 0.04311, saving model to ../models/RNN.h5\n",
      "Epoch 232/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 11.1047 - ler: 0.0835 - val_loss: 9.0098 - val_ler: 0.0555\n",
      "\n",
      "Epoch 00232: ler did not improve from 0.04311\n",
      "Epoch 233/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 11.1926 - ler: 0.0808 - val_loss: 9.7514 - val_ler: 0.0647\n",
      "\n",
      "Epoch 00233: ler did not improve from 0.04311\n",
      "Epoch 234/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 10.7707 - ler: 0.0730 - val_loss: 8.2392 - val_ler: 0.0480\n",
      "\n",
      "Epoch 00234: ler did not improve from 0.04311\n",
      "Epoch 235/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 9.4717 - ler: 0.0619 - val_loss: 7.9066 - val_ler: 0.0395\n",
      "\n",
      "Epoch 00235: ler did not improve from 0.04311\n",
      "Epoch 236/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 8.9437 - ler: 0.0565 - val_loss: 7.4947 - val_ler: 0.0387\n",
      "\n",
      "Epoch 00236: ler did not improve from 0.04311\n",
      "Epoch 237/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 8.1802 - ler: 0.0502 - val_loss: 6.9042 - val_ler: 0.0330\n",
      "\n",
      "Epoch 00237: ler did not improve from 0.04311\n",
      "Epoch 238/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 7.6183 - ler: 0.0444 - val_loss: 6.7481 - val_ler: 0.0319\n",
      "\n",
      "Epoch 00238: ler did not improve from 0.04311\n",
      "Epoch 239/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 7.7793 - ler: 0.0440 - val_loss: 6.6379 - val_ler: 0.0311\n",
      "\n",
      "Epoch 00239: ler did not improve from 0.04311\n",
      "Epoch 240/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 7.2639 - ler: 0.0398 - val_loss: 6.2567 - val_ler: 0.0288\n",
      "\n",
      "Epoch 00240: ler improved from 0.04311 to 0.03983, saving model to ../models/RNN.h5\n",
      "Epoch 241/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 7.1965 - ler: 0.0400 - val_loss: 6.4141 - val_ler: 0.0306\n",
      "\n",
      "Epoch 00241: ler did not improve from 0.03983\n",
      "Epoch 242/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 7.7413 - ler: 0.0422 - val_loss: 6.2339 - val_ler: 0.0287\n",
      "\n",
      "Epoch 00242: ler did not improve from 0.03983\n",
      "Epoch 243/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 7.3958 - ler: 0.0419 - val_loss: 6.6586 - val_ler: 0.0339\n",
      "\n",
      "Epoch 00243: ler did not improve from 0.03983\n",
      "Epoch 244/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 7.1812 - ler: 0.0389 - val_loss: 6.1588 - val_ler: 0.0277\n",
      "\n",
      "Epoch 00244: ler improved from 0.03983 to 0.03893, saving model to ../models/RNN.h5\n",
      "Epoch 245/300\n",
      "46/46 [==============================] - 3s 74ms/step - loss: 6.6645 - ler: 0.0367 - val_loss: 6.4467 - val_ler: 0.0290\n",
      "\n",
      "Epoch 00245: ler improved from 0.03893 to 0.03668, saving model to ../models/RNN.h5\n",
      "Epoch 246/300\n",
      "46/46 [==============================] - 3s 74ms/step - loss: 7.2279 - ler: 0.0381 - val_loss: 5.9800 - val_ler: 0.0270\n",
      "\n",
      "Epoch 00246: ler did not improve from 0.03668\n",
      "Epoch 247/300\n",
      "46/46 [==============================] - 3s 74ms/step - loss: 7.1452 - ler: 0.0353 - val_loss: 5.7884 - val_ler: 0.0253\n",
      "\n",
      "Epoch 00247: ler improved from 0.03668 to 0.03532, saving model to ../models/RNN.h5\n",
      "Epoch 248/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 6.8029 - ler: 0.0354 - val_loss: 5.8402 - val_ler: 0.0258\n",
      "\n",
      "Epoch 00248: ler did not improve from 0.03532\n",
      "Epoch 249/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 6.3508 - ler: 0.0357 - val_loss: 5.6569 - val_ler: 0.0240\n",
      "\n",
      "Epoch 00249: ler did not improve from 0.03532\n",
      "Epoch 250/300\n",
      "46/46 [==============================] - 3s 74ms/step - loss: 7.3651 - ler: 0.0439 - val_loss: 6.0648 - val_ler: 0.0283\n",
      "\n",
      "Epoch 00250: ler did not improve from 0.03532\n",
      "Epoch 251/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 6.7694 - ler: 0.0364 - val_loss: 6.0238 - val_ler: 0.0284\n",
      "\n",
      "Epoch 00251: ler did not improve from 0.03532\n",
      "Epoch 252/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 6.5129 - ler: 0.0324 - val_loss: 5.4904 - val_ler: 0.0222\n",
      "\n",
      "Epoch 00252: ler improved from 0.03532 to 0.03241, saving model to ../models/RNN.h5\n",
      "Epoch 253/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 6.3550 - ler: 0.0311 - val_loss: 5.4243 - val_ler: 0.0230\n",
      "\n",
      "Epoch 00253: ler improved from 0.03241 to 0.03106, saving model to ../models/RNN.h5\n",
      "Epoch 254/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 6.5775 - ler: 0.0338 - val_loss: 5.4482 - val_ler: 0.0218\n",
      "\n",
      "Epoch 00254: ler did not improve from 0.03106\n",
      "Epoch 255/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 6.6578 - ler: 0.0340 - val_loss: 5.4126 - val_ler: 0.0230\n",
      "\n",
      "Epoch 00255: ler did not improve from 0.03106\n",
      "Epoch 256/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 6.5252 - ler: 0.0324 - val_loss: 5.4315 - val_ler: 0.0227\n",
      "\n",
      "Epoch 00256: ler did not improve from 0.03106\n",
      "Epoch 257/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 5.8782 - ler: 0.0313 - val_loss: 5.2134 - val_ler: 0.0209\n",
      "\n",
      "Epoch 00257: ler did not improve from 0.03106\n",
      "Epoch 258/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 5.9896 - ler: 0.0304 - val_loss: 5.2656 - val_ler: 0.0210\n",
      "\n",
      "Epoch 00258: ler improved from 0.03106 to 0.03044, saving model to ../models/RNN.h5\n",
      "Epoch 259/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 5.9068 - ler: 0.0275 - val_loss: 5.0290 - val_ler: 0.0203\n",
      "\n",
      "Epoch 00259: ler improved from 0.03044 to 0.02748, saving model to ../models/RNN.h5\n",
      "Epoch 260/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 5.9518 - ler: 0.0324 - val_loss: 5.2816 - val_ler: 0.0203\n",
      "\n",
      "Epoch 00260: ler did not improve from 0.02748\n",
      "Epoch 261/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 6.4136 - ler: 0.0347 - val_loss: 5.5615 - val_ler: 0.0228\n",
      "\n",
      "Epoch 00261: ler did not improve from 0.02748\n",
      "Epoch 262/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 5.8815 - ler: 0.0298 - val_loss: 5.1415 - val_ler: 0.0209\n",
      "\n",
      "Epoch 00262: ler did not improve from 0.02748\n",
      "Epoch 263/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 5.9273 - ler: 0.0300 - val_loss: 4.9719 - val_ler: 0.0194\n",
      "\n",
      "Epoch 00263: ler did not improve from 0.02748\n",
      "Epoch 264/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 6.1380 - ler: 0.0296 - val_loss: 5.1576 - val_ler: 0.0217\n",
      "\n",
      "Epoch 00264: ler did not improve from 0.02748\n",
      "Epoch 265/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 6.1340 - ler: 0.0307 - val_loss: 4.9298 - val_ler: 0.0183\n",
      "\n",
      "Epoch 00265: ler did not improve from 0.02748\n",
      "Epoch 266/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 6.2751 - ler: 0.0347 - val_loss: 5.6205 - val_ler: 0.0244\n",
      "\n",
      "Epoch 00266: ler did not improve from 0.02748\n",
      "Epoch 267/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 7.2723 - ler: 0.0427 - val_loss: 5.7611 - val_ler: 0.0251\n",
      "\n",
      "Epoch 00267: ler did not improve from 0.02748\n",
      "Epoch 268/300\n",
      "46/46 [==============================] - 3s 74ms/step - loss: 6.5472 - ler: 0.0380 - val_loss: 5.1882 - val_ler: 0.0206\n",
      "\n",
      "Epoch 00268: ler did not improve from 0.02748\n",
      "Epoch 269/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 6.3938 - ler: 0.0332 - val_loss: 5.0634 - val_ler: 0.0206\n",
      "\n",
      "Epoch 00269: ler did not improve from 0.02748\n",
      "Epoch 270/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 6.2534 - ler: 0.0313 - val_loss: 4.8469 - val_ler: 0.0183\n",
      "\n",
      "Epoch 00270: ler did not improve from 0.02748\n",
      "Epoch 271/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 5.7793 - ler: 0.0299 - val_loss: 4.9364 - val_ler: 0.0188\n",
      "\n",
      "Epoch 00271: ler did not improve from 0.02748\n",
      "Epoch 272/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 6.0635 - ler: 0.0307 - val_loss: 4.7943 - val_ler: 0.0182\n",
      "\n",
      "Epoch 00272: ler did not improve from 0.02748\n",
      "Epoch 273/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 5.3857 - ler: 0.0282 - val_loss: 4.8019 - val_ler: 0.0172\n",
      "\n",
      "Epoch 00273: ler did not improve from 0.02748\n",
      "Epoch 274/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 5.9026 - ler: 0.0309 - val_loss: 5.2355 - val_ler: 0.0225\n",
      "\n",
      "Epoch 00274: ler did not improve from 0.02748\n",
      "Epoch 275/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 6.4094 - ler: 0.0336 - val_loss: 4.9935 - val_ler: 0.0197\n",
      "\n",
      "Epoch 00275: ler did not improve from 0.02748\n",
      "Epoch 276/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 5.6096 - ler: 0.0302 - val_loss: 4.7483 - val_ler: 0.0189\n",
      "\n",
      "Epoch 00276: ler did not improve from 0.02748\n",
      "Epoch 277/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 5.9727 - ler: 0.0324 - val_loss: 5.1285 - val_ler: 0.0212\n",
      "\n",
      "Epoch 00277: ler did not improve from 0.02748\n",
      "Epoch 278/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 9.2958 - ler: 0.0691 - val_loss: 6.6442 - val_ler: 0.0374\n",
      "\n",
      "Epoch 00278: ler did not improve from 0.02748\n",
      "Epoch 279/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 8.4046 - ler: 0.0611 - val_loss: 6.6604 - val_ler: 0.0365\n",
      "\n",
      "Epoch 00279: ler did not improve from 0.02748\n",
      "Epoch 280/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 7.9070 - ler: 0.0495 - val_loss: 5.7460 - val_ler: 0.0283\n",
      "\n",
      "Epoch 00280: ler did not improve from 0.02748\n",
      "Epoch 281/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 6.2926 - ler: 0.0342 - val_loss: 5.2628 - val_ler: 0.0229\n",
      "\n",
      "Epoch 00281: ler did not improve from 0.02748\n",
      "Epoch 282/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 6.3270 - ler: 0.0337 - val_loss: 4.8852 - val_ler: 0.0199\n",
      "\n",
      "Epoch 00282: ler did not improve from 0.02748\n",
      "Epoch 283/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 5.7657 - ler: 0.0284 - val_loss: 4.5413 - val_ler: 0.0177\n",
      "\n",
      "Epoch 00283: ler did not improve from 0.02748\n",
      "Epoch 284/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 5.2667 - ler: 0.0295 - val_loss: 4.5807 - val_ler: 0.0173\n",
      "\n",
      "Epoch 00284: ler did not improve from 0.02748\n",
      "Epoch 285/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 6.8668 - ler: 0.0384 - val_loss: 5.0567 - val_ler: 0.0224\n",
      "\n",
      "Epoch 00285: ler did not improve from 0.02748\n",
      "Epoch 286/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 6.3207 - ler: 0.0334 - val_loss: 4.7002 - val_ler: 0.0185\n",
      "\n",
      "Epoch 00286: ler did not improve from 0.02748\n",
      "Epoch 287/300\n",
      "46/46 [==============================] - 3s 74ms/step - loss: 5.6879 - ler: 0.0291 - val_loss: 4.5564 - val_ler: 0.0178\n",
      "\n",
      "Epoch 00287: ler did not improve from 0.02748\n",
      "Epoch 288/300\n",
      "46/46 [==============================] - 3s 74ms/step - loss: 5.6006 - ler: 0.0309 - val_loss: 4.4202 - val_ler: 0.0166\n",
      "\n",
      "Epoch 00288: ler did not improve from 0.02748\n",
      "Epoch 289/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 5.5145 - ler: 0.0265 - val_loss: 4.3621 - val_ler: 0.0165\n",
      "\n",
      "Epoch 00289: ler improved from 0.02748 to 0.02646, saving model to ../models/RNN.h5\n",
      "Epoch 290/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 5.1005 - ler: 0.0225 - val_loss: 4.1366 - val_ler: 0.0153\n",
      "\n",
      "Epoch 00290: ler improved from 0.02646 to 0.02254, saving model to ../models/RNN.h5\n",
      "Epoch 291/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 4.8256 - ler: 0.0225 - val_loss: 4.0157 - val_ler: 0.0127\n",
      "\n",
      "Epoch 00291: ler improved from 0.02254 to 0.02248, saving model to ../models/RNN.h5\n",
      "Epoch 292/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 4.8738 - ler: 0.0195 - val_loss: 3.9514 - val_ler: 0.0131\n",
      "\n",
      "Epoch 00292: ler improved from 0.02248 to 0.01954, saving model to ../models/RNN.h5\n",
      "Epoch 293/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 4.4134 - ler: 0.0196 - val_loss: 3.7653 - val_ler: 0.0127\n",
      "\n",
      "Epoch 00293: ler did not improve from 0.01954\n",
      "Epoch 294/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 4.9370 - ler: 0.0247 - val_loss: 4.2246 - val_ler: 0.0163\n",
      "\n",
      "Epoch 00294: ler did not improve from 0.01954\n",
      "Epoch 295/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 4.8507 - ler: 0.0228 - val_loss: 3.9202 - val_ler: 0.0135\n",
      "\n",
      "Epoch 00295: ler did not improve from 0.01954\n",
      "Epoch 296/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 4.7965 - ler: 0.0201 - val_loss: 3.9363 - val_ler: 0.0134\n",
      "\n",
      "Epoch 00296: ler did not improve from 0.01954\n",
      "Epoch 297/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 4.8883 - ler: 0.0202 - val_loss: 3.8174 - val_ler: 0.0132\n",
      "\n",
      "Epoch 00297: ler did not improve from 0.01954\n",
      "Epoch 298/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 4.5493 - ler: 0.0176 - val_loss: 3.5806 - val_ler: 0.0114\n",
      "\n",
      "Epoch 00298: ler improved from 0.01954 to 0.01760, saving model to ../models/RNN.h5\n",
      "Epoch 299/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 4.1403 - ler: 0.0163 - val_loss: 3.4647 - val_ler: 0.0101\n",
      "\n",
      "Epoch 00299: ler improved from 0.01760 to 0.01627, saving model to ../models/RNN.h5\n",
      "Epoch 300/300\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 4.3062 - ler: 0.0158 - val_loss: 3.5202 - val_ler: 0.0107\n",
      "\n",
      "Epoch 00300: ler improved from 0.01627 to 0.01581, saving model to ../models/RNN.h5\n"
     ]
    }
   ],
   "source": [
    "# Compile Training Model with selected optimizer\n",
    "optimizer = tf.keras.optimizers.SGD(initial_learning_rate, momentum)\n",
    "model_train.compile(optimizer=optimizer)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='../models/'+\"RNN\"+'.h5',monitor='ler',verbose=1, save_best_only=True, mode='min')\n",
    "# ModelCheckpoint(filepath='../models/'+\"RNN\"+'.h5', verbose=0,)\n",
    "\n",
    "# Training, Our y is already defined so no need# mlflow.tensorflow.autolog()\n",
    "history = model_train.fit(x=[train_inputs, train_targets, train_seq_len, train_targets_len], y=None,\n",
    "                validation_data=([val_inputs, val_targets, val_seq_len, val_targets_len], None),\n",
    "                batch_size=batch_size, epochs=300,callbacks=[checkpointer])\n",
    "\n",
    "# try:\n",
    "#     experiment_id = mlflow.create_experiment(\"Stacked RNN(LSTM): 50 Cells\")\n",
    "#     experiment = mlflow.get_experiment(experiment_id)\n",
    "# except mlflow.exceptions.MlflowException:\n",
    "#     experiment = mlflow.get_experiment_by_name(\"Stacked RNN(LSTM): 50 Cells\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3297fc44-8655-439d-8442-87b8905793fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'ler', 'val_loss', 'val_ler'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAxSElEQVR4nO3deXxU5dn/8c81k5BAErYkbGFXEFnDIm6ouK8V61Kx2Iq2VVtbq3ZRu2lrfWz9advHPtqnbtVHrdSlKnWtUhV3NlFBQJFFAxjCmoSsM3P9/phDDCTEsEwmyXzfr1dec+Y+y1yHQ+bKvZz7mLsjIiICEEp2ACIi0nooKYiISB0lBRERqaOkICIidZQURESkjpKCiIjUUVIQ2U1mdp+Z/baZ264ys+MSHZPIvqKkIJIku5NcRFqKkoKIiNRRUpB2KWi2+YmZvW9m28zsHjPraWbPmVmZmb1kZt3qbX+6mS02sy1m9oqZHVhv3VgzWxDs9w8gc6fPOs3MFgb7vmlmo/dB/N8xs+VmtsnMZppZn6DczOyPZrbezLYG5zcyWHeKmX0YxLnGzH68t3FI6lFSkPbsLOB4YCjwFeA54GdAHvH/+5cDmNlQ4GHgCiAfeBb4l5l1MLMOwJPAA0B34NHguAT7jgPuBS4BcoG/AjPNLGNPgzazY4CbgK8BvYHVwIxg9QnAkcE5dQXOBTYG6+4BLnH3HGAk8J89jUFSl5KCtGd/dvdid18DvAa84+7vuns18AQwNtjuXOAZd3/R3WuBW4COwGHAIUA68Cd3r3X3x4C59T7jO8Bf3f0dd4+6+/1AdbDfnpoG3OvuC4JYrwUONbOBQC2QAwwDzN2XuPu6YL9aYLiZdXb3ze6+YC9ikBSlpCDtWXG95cpG3mcHy32I/zUOgLvHgM+AgmDdGt9x5sjV9ZYHAD8Kmo62mNkWoF+w357aOZ5y4rWBAnf/D/A/wO1AsZndaWadg03PAk4BVpvZq2Z26F7EIClKSUEE1hL/cgfi7fbEv9jXAOuAgqBsu/71lj8DbnT3rvV+Orn7w/swniziTVNrANz9NncfD4wg3oz0k6B8rrtPAXoQb/J6ZC9ikBSlpCAS//I81cyONbN04EfEm4DeBN4CIsDlZpZmZmcCE+vtexdwqZkdHHQCZ5nZqWaW08zPDptZZr2fDsDfgQvNrDDom/gv4k1fq8zsoOCz0oFtQBUQDfo/pplZl6AJrBSI7v0/jaQaJQVJee6+DDgf+DOwgXin9Ffcvcbda4AzgenAZuL9D/+st+884v0K/xOsXx5s21zXEG/K2v7zH3efBfwSeJx4TWU/YGqwfWfiiWgz8SamjcT7QAC+Aawys1Lg0uCcRHaL6SE7IiKynWoKIiJSR0lBRETqKCmIiEgdJQUREamTluwA9kZeXp4PHDgw2WGIiLQp8+fP3+Du+Y2ta9NJYeDAgcybNy/ZYYiItClmtnpX69R8JCIidZQURESkjpKCiIjUadN9Co2pra2lqKiIqqqqZIciuyEzM5O+ffuSnp6e7FBEUlq7SwpFRUXk5OQwcOBAdpzYUlord2fjxo0UFRUxaNCgZIcjktLaXfNRVVUVubm5SghtiJmRm5ur2p1IK9DukgKghNAG6ZqJtA7tMil8mdpIjM+3VlFVq+nmRUTqS82kEIuxvqyKmkhsnx9748aNFBYWUlhYSK9evSgoKKh7X1NT0+S+8+bN4/LLL//SzzjssMP2SayvvPIKp5122j45loi0D+2uo7k5EtlQkZuby8KFCwG4/vrryc7O5sc//nHd+kgkQlpa4//sEyZMYMKECV/6GW+++eY+iVVEZGcpWVPYrqUeLzR9+nSuuuoqjj76aK6++mrmzJnDYYcdxtixYznssMNYtmwZsONf7tdffz0XXXQRkydPZvDgwdx22211x8vOzq7bfvLkyZx99tkMGzaMadOmsf2hSc8++yzDhg1j0qRJXH755btVI3j44YcZNWoUI0eO5OqrrwYgGo0yffp0Ro4cyahRo/jjH/8IwG233cbw4cMZPXo0U6dObeqwItIGtOuawq//tZgP15Y2KI+5U1kTJTM9TDi0e/WG4X06c91XRux2LB999BEvvfQS4XCY0tJSZs+eTVpaGi+99BI/+9nPePzxxxvss3TpUl5++WXKyso44IAD+O53v9tgHP+7777L4sWL6dOnD4cffjhvvPEGEyZM4JJLLmH27NkMGjSI8847r9lxrl27lquvvpr58+fTrVs3TjjhBJ588kn69evHmjVrWLRoEQBbtmwB4He/+x0rV64kIyOjrkxE2q6E1RSCh5DPMbP3zGyxmf06KL/ezNaY2cLg55R6+1xrZsvNbJmZnZio2JLhnHPOIRwOA7B161bOOeccRo4cyZVXXsnixYsb3efUU08lIyODvLw8evToQXFxcYNtJk6cSN++fQmFQhQWFrJq1SqWLl3K4MGD68b8705SmDt3LpMnTyY/P5+0tDSmTZvG7NmzGTx4MCtWrOAHP/gBzz//PJ07dwZg9OjRTJs2jQcffHCXzWIi0nYk8re4GjjG3cvNLB143cyeC9b90d1vqb+xmQ0n/nDyEUAf4CUzG+ruezxEaFd/0VfVRvmouIz+3TvRtVOHPT38bsnKyqpb/uUvf8nRRx/NE088wapVq5g8eXKj+2RkZNQth8NhIpFIs7bZm+du72rfbt268d577/HCCy9w++2388gjj3DvvffyzDPPMHv2bGbOnMkNN9zA4sWLlRxE2rCE1RQ8rjx4mx78NPVtNQWY4e7V7r4SWA5MTFR8ybR161YKCgoAuO+++/b58YcNG8aKFStYtWoVAP/4xz+ave/BBx/Mq6++yoYNG4hGozz88MMcddRRbNiwgVgsxllnncUNN9zAggULiMVifPbZZxx99NHcfPPNbNmyhfLy8i//EBFptRL6J52ZhYH5wP7A7e7+jpmdDHzfzL4JzAN+5O6bgQLg7Xq7FwVlOx/zYuBigP79++9ZXHu0177z05/+lAsuuIA//OEPHHPMMfv8+B07duSOO+7gpJNOIi8vj4kTd51bZ82aRd++feveP/roo9x0000cffTRuDunnHIKU6ZM4b333uPCCy8kFosP473pppuIRqOcf/75bN26FXfnyiuvpGvXrvv8fESk5djeNDU0+0PMugJPAD8ASoANxGsNNwC93f0iM7sdeMvdHwz2uQd41t0b9sAGJkyY4Ds/ZGfJkiUceOCBTcZTXRtlWXEZ/bp3olsLNR+1tPLycrKzs3F3LrvsMoYMGcKVV16Z7LCa1JxrJyJ7z8zmu3uj499bZEiqu28BXgFOcvdid4+6ewy4iy+aiIqAfvV26wusTUhA26sKLTUmNQnuuusuCgsLGTFiBFu3buWSSy5Jdkgi0gYkrPnIzPKBWnffYmYdgeOA35tZb3dfF2z2VWBRsDwT+LuZ/YF4R/MQYE5CYgte23FO4Morr2z1NQMRaX0S2afQG7g/6FcIAY+4+9Nm9oCZFRL/Tl4FXALg7ovN7BHgQyACXLY3I4+aluxeBRGR1ilhScHd3wfGNlL+jSb2uRG4MVExNfKJLfdRIiJtQEpOc7F9luYW6GMXEWlTUjIpiIhI45QU9rHJkyfzwgsv7FD2pz/9ie9973tN7rN9aO0pp5zS6BxC119/PbfcckuD8vqefPJJPvzww7r3v/rVr3jppZd2I/rGaYptkdSRkkkhkaOPzjvvPGbMmLFD2YwZM5o9/9Czzz67xzeA7ZwUfvOb33Dcccft0bFEJDWlZFJIpLPPPpunn36a6upqAFatWsXatWuZNGkS3/3ud5kwYQIjRozguuuua3T/gQMHsmHDBgBuvPFGDjjgAI477ri66bUhfg/CQQcdxJgxYzjrrLOoqKjgzTffZObMmfzkJz+hsLCQTz75hOnTp/PYY48B8TuXx44dy6hRo7jooovq4hs4cCDXXXcd48aNY9SoUSxdurTZ56optkXan/Y9c9lz18DnHzQoDuMMro7SIS0E4d3Mi71Gwcm/2+Xq3NxcJk6cyPPPP8+UKVOYMWMG5557LmbGjTfeSPfu3YlGoxx77LG8//77jB49utHjzJ8/nxkzZvDuu+8SiUQYN24c48ePB+DMM8/kO9/5DgC/+MUvuOeee/jBD37A6aefzmmnncbZZ5+9w7GqqqqYPn06s2bNYujQoXzzm9/kL3/5C1dccQUAeXl5LFiwgDvuuINbbrmFu++++0v/GTTFtkj7pJpCAtRvQqrfdPTII48wbtw4xo4dy+LFi3do6tnZa6+9xle/+lU6depE586dOf300+vWLVq0iCOOOIJRo0bx0EMP7XLq7e2WLVvGoEGDGDp0KAAXXHABs2fPrlt/5plnAjB+/Pi6SfS+jKbYFmmf2vdv5y7+oo/FnBVrt9K7Syb5OZn7/GPPOOMMrrrqKhYsWEBlZSXjxo1j5cqV3HLLLcydO5du3boxffp0qqqqmjyOWeM32U2fPp0nn3ySMWPGcN999/HKK680eZwvm99q+/Tbu5qee3eOqSm2Rdq2lKwpJHqai+zsbCZPnsxFF11UV0soLS0lKyuLLl26UFxczHPPPdfkMY488kieeOIJKisrKSsr41//+lfdurKyMnr37k1tbS0PPfRQXXlOTg5lZWUNjjVs2DBWrVrF8uXLAXjggQc46qij9uocNcW2SPukP9US5LzzzuPMM8+sa0YaM2YMY8eOZcSIEQwePJjDDz+8yf3HjRvHueeeS2FhIQMGDOCII46oW3fDDTdw8MEHM2DAAEaNGlWXCKZOncp3vvMdbrvttroOZoDMzEz+9re/cc455xCJRDjooIO49NJLd+t8NMW2SGpokamzE2VPp86OubNozVZ6dc6kR+d933wke0ZTZ4u0jKRPnd3apMIsqSIieyIlk4KIiDSuXSaFL2sS2z6qRzWF1qMtN2OKtCftLilkZmaycePGL08MoKzQSrg7GzduJDNT/TsiydbuRh/17duXoqIiSkpKmtyueHMl2zLT2NwxvYUik6ZkZmbuMLpJRJKj3SWF9PR0Bg0a9KXbTfn5c3zriEFcfdKwFohKRKRtaHfNR81lFh+aKiIiX0jZpBAy05PXRER2krCkYGaZZjbHzN4zs8Vm9uugvLuZvWhmHwev3ertc62ZLTezZWZ2YqJiAwhZfA4kERH5QiJrCtXAMe4+BigETjKzQ4BrgFnuPgSYFbzHzIYDU4ERwEnAHWYWTlRwITOUE0REdpSwpOBx22c9Sw9+HJgC3B+U3w+cESxPAWa4e7W7rwSWAxMTFZ/6FEREGkpon4KZhc1sIbAeeNHd3wF6uvs6gOC1R7B5AfBZvd2LgrKdj3mxmc0zs3lfNuy0KaGQ6YYpEZGdJDQpuHvU3QuBvsBEMxvZxOaNPTygwbe2u9/p7hPcfUJ+fv4ex6bmIxGRhlpk9JG7bwFeId5XUGxmvQGC1/XBZkVAv3q79QXWJiqmkJqPREQaSOToo3wz6xosdwSOA5YCM4ELgs0uAJ4KlmcCU80sw8wGAUOAOQmMTzUFEZGdJPKO5t7A/cEIohDwiLs/bWZvAY+Y2beAT4FzANx9sZk9AnwIRIDL3D2aqOBCpknYRER2lrCk4O7vA2MbKd8IHLuLfW4EbkxUTPXF+xSUFERE6kvpO5rVfCQisqOUTQq6T0FEpKGUTQqa+0hEpKEUTgqqKYiI7CyFk4L6FEREdpaySUF9CiIiDaVsUghr7iMRkQZSNimEzIjFkh2FiEjrkrJJwXTzmohIAymbFOKjj5IdhYhI65LCSUF9CiIiO0vhpABRJQURkR2kbFLQ1NkiIg2lbFLQ1NkiIg2lcFLQ6CMRkZ2ldlLQfQoiIjtI2aSgaS5ERBpK2aSgqbNFRBpKWFIws35m9rKZLTGzxWb2w6D8ejNbY2YLg59T6u1zrZktN7NlZnZiomIDCIVUUxAR2VnCntEMRIAfufsCM8sB5pvZi8G6P7r7LfU3NrPhwFRgBNAHeMnMhrp7NBHBqaNZRKShhNUU3H2duy8IlsuAJUBBE7tMAWa4e7W7rwSWAxMTFZ/uUxARaahF+hTMbCAwFngnKPq+mb1vZveaWbegrAD4rN5uRTSSRMzsYjObZ2bzSkpK9jgm3acgItJQwpOCmWUDjwNXuHsp8BdgP6AQWAfcun3TRnZv8K3t7ne6+wR3n5Cfn7/HcenJayIiDSU0KZhZOvGE8JC7/xPA3YvdPeruMeAuvmgiKgL61du9L7A2UbHpGc0iIg0lcvSRAfcAS9z9D/XKe9fb7KvAomB5JjDVzDLMbBAwBJiTwPhUUxAR2UkiRx8dDnwD+MDMFgZlPwPOM7NC4k1Dq4BLANx9sZk9AnxIfOTSZYkaeQTqUxARaUzCkoK7v07j/QTPNrHPjcCNiYqpPg1JFRFpKKXvaFbzkYjIjlI2KWjuIxGRhlI2KYRDmvtIRGRnKZsU1KcgItJQyiYFNR+JiDSUsklBD9kREWkohZOC7lMQEdlZCicFDUkVEdlZyiYFU0eziEgDKZsU4hPiJTsKEZHWJYWTgqlPQURkJymcFCCqpCAisoOUTQpmRkztRyIiO0jZpBBvPkp2FCIirUsKJwXd0SwisrPUTQoh3acgIrKzlE0KmvtIRKShlE0K6lMQEWkohZOCagoiIjtLWFIws35m9rKZLTGzxWb2w6C8u5m9aGYfB6/d6u1zrZktN7NlZnZiomIDPU9BRKQxiawpRIAfufuBwCHAZWY2HLgGmOXuQ4BZwXuCdVOBEcBJwB1mFk5UcKYJ8UREGkhYUnD3de6+IFguA5YABcAU4P5gs/uBM4LlKcAMd69295XAcmBiouILWV2cifoIEZE2p0X6FMxsIDAWeAfo6e7rIJ44gB7BZgXAZ/V2KwrKdj7WxWY2z8zmlZSU7HFMIYtnBdUWRES+0KykYGZZZhYKloea2elmlt7MfbOBx4Er3L20qU0bKWvwle3ud7r7BHefkJ+f35wQGrW9pqB+BRGRLzS3pjAbyDSzAuL9ABcC933ZTkHieBx4yN3/GRQXm1nvYH1vYH1QXgT0q7d7X2BtM+PbbVZXU1BSEBHZrrlJwdy9AjgT+LO7fxUY3uQO8W/de4Al7v6HeqtmAhcEyxcAT9Urn2pmGWY2CBgCzGlmfLstHFQVlBNERL6Q1sztzMwOBaYB32rmvocD3wA+MLOFQdnPgN8Bj5jZt4BPgXMA3H2xmT0CfEh85NJl7h5t7onsLjUfiYg01NykcAVwLfBE8OU9GHi5qR3c/XUa7ycAOHYX+9wI3NjMmPaKOppFRBpqVlJw91eBVwGCDucN7n55IgNLNPUpiIg01NzRR383s85mlkW8eWeZmf0ksaElVt19CrHkxiEi0po0t6N5eDCc9AzgWaA/8f6CNiukmoKISAPNTQrpwfDSM4Cn3L2WRu4haEvU0Swi0lBzk8JfgVVAFjDbzAYATd2I1uqZOppFRBpobkfzbcBt9YpWm9nRiQmpZWxvPtLcRyIiX2huR3MXM/vD9jmHzOxW4rWGNuuL5qPkxiEi0po0t/noXqAM+FrwUwr8LVFBtQR1NIuINNTcm9f2c/ez6r3/db27lNskU0eziEgDza0pVJrZpO1vzOxwoDIxIbWML/oUkhyIiEgr0tyawqXA/5lZl+D9Zr6Y1K5NCgXpMKpOBRGROs0dffQeMMbMOgfvS83sCuD9BMaWUOpTEBFpaLeevObupfUelHNVAuJpMbpPQUSkob15HOeuZkBtE/SMZhGRhvYmKbTpb1NNnS0i0lCTfQpmVkbjX/4GdExIRC1Ecx+JiDTUZFJw95yWCqSl6XkKIiIN7U3zUZum+xRERBpKWFIws3vNbL2ZLapXdr2ZrTGzhcHPKfXWXWtmy81smZmdmKi4AKguo3vJHLpSppqCiEg9iawp3Aec1Ej5H929MPh5FsDMhgNTgRHBPneYWThhkZV8xPiXz2dsaLk6mkVE6klYUnD32cCmZm4+BZjh7tXuvhJYDkxMVGxk5QKQa6WqKYiI1JOMPoXvm9n7QfNSt6CsAPis3jZFQVkDZnbx9im8S0pK9iyCTnkA5FKq+xREROpp6aTwF2A/oBBYB9walDd2I1yj39bufqe7T3D3Cfn5+XsWRYcsouFMulupmo9EROpp0aTg7sXuHnX3GHAXXzQRFQH96m3aF1ibsEDMiGR2J89KiSkriIjUadGkYGa96739KrB9ZNJMYKqZZZjZIGAIMCeRsdRm5tId1RREROpr7tTZu83MHgYmA3lmVgRcB0w2s0LiTUOrgEsA3H2xmT0CfAhEgMvcPZqo2AAimbnk2mrK1acgIlInYUnB3c9rpPieJra/EbgxUfHsLJLZne62iFLlBBGROil7R3OkYx65lBKLxZIdiohIq5GySSGa2Z2OVoPVbkt2KCIirUbqJoWO8XsV0qqae3+diEj7l7JJIdYxfldzh22JG/kqItLWpGxSiGb3AGDsKxfC0meTHI2ISOuQskmh74GH8HO7nOK03vDvX0C0NtkhiYgkXcomhYz0NLIO+jrXV5wDmz6BOXcmOyQRkaRL2H0KbcG0g/tz4lsTeNnHMenFX2MxJ637ANj/OEhv008bFRHZIymdFAbkZvHvKybzP08ZBat+xNAXfw7AZzmFdDrgaHIP/jrkD01ylCIiLcfa8tTREyZM8Hnz5u2TY732cQn3Pf82PYpnc0P4btIsRmmoC890PZ+CiVMYNnwM3bM6kBZO2RY3EWknzGy+u09odJ2Swo7cnY0lxTz40tuc/ckv6BuNP+Zhk2fzSvqRdDrmKo4/ZALhUGOzfYuItH5KCnuhZsMqFrz4ELlbPmBw8QvgzlrrwSe5k+lx2i8ZPqjflx9ERKQVUVLYR2KbVrFi1t1Url7AiPI32ew5zOoxHcZ9g9PGD6ZTh5TuohGRNkJJIQG2rphLyaM/Yv/K9yj1jsyIHUfRmB/y8zPGkZEWTkpMIiLNoaSQKO74qtfZNPtOclfOpMQ7MzNzCjmHf5sjxhxA7y4a1ioirY+SQkv49G02PPtb8j5/jZgbLzKRsuNu5uwjCpMdmYjIDppKChpfua/0P4S8S5/GL32DLeMv4xhbwJEvTeGOe+7i4+KyZEcnItIsqikkSHTt+2x+4JvkVa5kuRdQkV9Ih6/+mWEFuckOTURSnGoKSRDuM5q8q96i8qDLiHTqwegNz7Dir+fxwGvLaMuJWETat4QlBTO718zWm9miemXdzexFM/s4eO1Wb921ZrbczJaZ2YmJiqtFpXek46n/xbCrX6Fi8m84JfQOI178Or96aBYVNZFkRyci0kAiawr3ASftVHYNMMvdhwCzgveY2XBgKjAi2OcOM2tX4zo7Tf4hsXP+j1FpRVzx8XT++v+u4dE5K4jFVGsQkdYjYUnB3WcDOz/rcgpwf7B8P3BGvfIZ7l7t7iuB5cDERMWWLKERU0i/5D+k9RrBlbV3Mf7pk7nlv2/h489Lkx2aiAjQ8n0KPd19HUDw2iMoLwA+q7ddUVDWgJldbGbzzGxeSUlJQoNNiJ4j6HLp8/h5/yC3cxY/3fpbSv9yHP/811NsKK9OdnQikuJaS0dzY7PLNdqu4u53uvsEd5+Qn5+f4LASxAw74CS6XDmHshNuZb/wek6fN517b76Kp95eSlRNSiKSJC2dFIrNrDdA8Lo+KC8C6s8s1xdY28KxtbxwGjmHfZsuP32PygFH89PQg5z43CRevOksPlixJtnRiUgKaumkMBO4IFi+AHiqXvlUM8sws0HAEGBOC8eWNJbZhZwLHydy4Qt8Pvgsjqt9mfB9J3Pn069TXFqV7PBEJIUk7OY1M3sYmAzkAcXAdcCTwCNAf+BT4Bx33xRs/3PgIiACXOHuz33ZZ7Tmm9f2xrZFzxP654WURTvw++g0uh8yje8fO5QuHdOTHZqItAOa+6gtKl5M1ePfI3P9QmZFx/JG+iEc+bUrOHJoT0J6wI+I7AXd0dwW9RxB5qUvw3HXc1TWan4V+wvVD03jyN/+i+cXrUt2dCLSTikptGahEEy6krSrV1B93H9xQngBD9ovePrvt3Pp/W/x6caKZEcoIu2Mmo/ako9fwp+5CtuymmLvxo9j32fMpK8wdWI/+nbrlOzoRKSNUPNRezHkOOzyhTDtMXJz87g/fCOdX/s1p978NL9/fik1kViyIxSRNk5Joa0JhWDI8aRd8jKh8d/k4rRneKvjlaS/9v+45LbHWVFSnuwIRaQNU/NRW7fufXjlJlj2LAB/jp3NKz2nc/nxwzhqaBu941tEEkpDUlPBppVUvPhbOi15jNfCB3NDxZmMn3AY507sz5i+XTDTMFYRiVNSSBXu8M7/4v/+BRaL8HGsgD9HzuDzfqfxu7NHMzg/O9kRikgroKSQasrXw5KZ1M75G+kli3ifIfxX7JscftTJTD98IDmZujNaJJUpKaSqWAzee5joS78mvK2Yp6KH8UD4TEaNP4xvTRqkYawiKUpDUlNVKARjpxG+fAEc+VO+0mEBj/FjDpl7BRfdOoO7X1uhabpFZAeqKaSSik0w9x5ir90KkSqejU7kofSzGD3hSL59xGDyczKSHaGItAA1H8mOytfjb91B5J27SI+U82psNH+IfZ2Jg7px+MEHc9SIgRqtJNKOKSlI46q2wty7ib7xP4Sr4o/TnhM7gO/6tZw2YQg/OWkY2RlpSQ5SRPY1JQVpWsUmePsOojUVhN++HYBHI0fya/82XztkCFeffAAZaeEkByki+4qSgjTfytdgyb9gzl8p6dCXW7edxIt2GEeMHMyPTjiAft01YkmkrVNSkN33yX/g+WuhZClb0nvy39Wn8kZ0BOPHT2TawQMYWdAl2RGKyB5SUpA94w6fvg1Pfhc2rwRglo/npppzSet5ICeM6MUZhX10p7RIG9PqkoKZrQLKgCgQcfcJZtYd+AcwEFgFfM3dNzd1HCWFFhKLwdbP4L0Z+Jt/xmu28W7GQfy9fCz/8kl8/ZDBfG/yfvTonJnsSEWkGVprUpjg7hvqld0MbHL335nZNUA3d7+6qeMoKSRBxSZ4/Y/w4VOwZTUbOxSwocqIYdzd8SIGHfwVph8+SKOWRFqxtpIUlgGT3X2dmfUGXnH3A5o6jpJCErnHp+t+7VaqaiNUlW+lc8VqnohO4vW0Q+l76Nkce2BPxvSN9z3ovgeR1qM1JoWVwGbAgb+6+51mtsXdu9bbZrO7d2tk34uBiwH69+8/fvXq1S0UtTSpthKe/TGRxTNJqynlZ7Xf4pHoUXRMD9E1J4ufnzKc44f3JBxSchBJttaYFPq4+1oz6wG8CPwAmNmcpFCfagqtUG0VPDwVVrxM1NKJWDovhI/i4W3j+DCjkEn75/HzUw+kT9eOyY5UJGU1lRSS0vDr7muD1/Vm9gQwESg2s971mo/WJyM22UvpmTDtMXj3AcIlywiXF/OVj57nKx2e593Ox7F2WQWnLzqfoXkZjDpwOKP6duHoA3qQpT4IkVahxWsKZpYFhNy9LFh+EfgNcCywsV5Hc3d3/2lTx1JNoY2oqYAHz4TP5uA47hAixvOxifyyZjrl6bmcPLIn3z9miIa3irSAVtV8ZGaDgSeCt2nA3939RjPLBR4B+gOfAue4+6amjqWk0IZEqqFyC3z6VryDuktf/K3biRFiYzif9KpNnF7zG7r0GcKYvl359hGDGZSXleyoRdqlVpUU9iUlhTau5CN4+w7YvIrYmvmUWQ6LbQh3lh/Ba7VDGdUvl29NGsQJI3pq7iWRfUhJQVq/j16AWTdA6Rqo3ERNOIs5NpKbt53G6g5DOHi/fKIxJxaLUbthBV874UhOLyxIdtQibZKSgrQdNRXw0fOw6jX8w6ewio1UhrL5S9r5dAlXMbj2E46OvMYNtedTPvYSTh3dm5g74wZ0o7OePS3SLEoK0jZVboEPn4T598PaBXXFsdwh+KYVXF3zHco8k43emcXhYRw7vDeF/bpy0sheev60SBOUFKRtq6mAj/8NAw6DUBqEwvDQOfDZO3WbFGcO4vc15/BExWjMQhw/vCcD87I4Yv98zKBThzADcrPontUhiSci0jooKUj7U1sVf+5DtwGwaSXMvhk2LifaMY8lWQfx6cZtrIjksTRawLjQxzwePYLFPohDB+dy1vi+jOnbhf3yswnpDmtJQUoK0v5FI7DkKVj6DKycDeEMvGwt5jEAajK680mXQ3lpQ1furjiKrWSzf49svjK6D44ztGcOQ3tm06drRzp10I100r4pKUhqqtkGJUvBQvCPb0KkEraVEOmYx+c5I9myaQPUlPOfWCG3R86gv60nI6sLpx1xEKP7dqFPl45sKK+mR04m/XPVRyHth5KCiDuYwbr34N+/jE8BntmZqEP40zeIWZiQR4lhPBudyDPRQ1jsA/nUe5IeNs6b2J9J++fRLasD2RlpHNi7c7LPSGSPKSmINGXFK7DiVehSAKXr8LduxyKVREKZVGX1IbytmAWRwTwaOYK1nssK70Mopwf75WfTPasD22oiTNo/j8kH5LNfframCZdWT0lBZHeUl8CWT+GNP0HlZsgfhi99GitbB0AklMm7nSeTVr6O/Ggxn4d6Mae6P+XekWezz2L/Pt2pjsTonJlOn66ZnDiiF+P6d6MmGqOkrJp+3dUUJcmlpCCyt6K1sOFjKFsHC+6H1W9BVj70GAZFc/GtazCPUpLWm7mh0YRDIbIim3izej8erJ1Mz44w0It4rWoQE4f25fgDe9C5YzolZdX07JzJ8cN7EjLj3U83Ew4ZedkZfLBmK0cP66Gn2Mk+p6QgkkixGMRq481Q7/wvrF0IHo0njY3Ld9i0JtSJZ5jE/OoCMqillE58EBtMRUYeh/E+z1eNYAvZZFPJoaEPKco9nJ+eOprJB+TXNUu5u5qoZK8oKYgky+cfwLLnwYAeI+DDJ+PTd0SqdtgsSpgwURzDcKKWRtgjvG2F/Kn6NDpld2VuZS8yMjIprYoweWg+J4/qRciMtz7ZyKqN2zhmWA++eehAqiMxMtNDmkRQdklJQaQ1iUZg23pI7xgfBbXqdfj8fRhyAnw2Jz5KKlIFmV3wl2/CPApAdagjVaEssBAv1Y7itZoDGBIqYkLaJ2zu0Icny0ewML2Q4poOhM0wg37dOtG7ayb52Rns3yOb/JwMMtPDDMzNYmRBF6pqo/z2mSXURmNcefxQCuo9EW/hZ1so2lzBKSN76ya/dkZJQaStKi+JJ4yqrbD6TYhWQ3U5vuw5LFKJh9Kgxwhs80qoLiVKmGioAyGPEPIoW8K5RNz4mH68Wb0flWSwwTtT5PlszehDzJ1DInMZEC5hhReQMfJ0RgwqoLw6whMvvETv2OesyRlNr159qInG2FBWw/49sino1pGvTejHfvlZCW/K2lJRQ3UkRo+cDDWb7SNKCiLtTW0VbFoBXftDRna8I7xobrxfo2bbF3NEbV0T799Y9Xq8k3wX3EKYxygli6cjE+llm5kcfo8Q8e+H4lAPKsmkOr0Ln0W78VF1dx6LTKJTdlf2655Ol61LOKDqPR7tdC6HjzmQUQVdKauqZdO2GjZti3+pj+7bhUjMqY7EOLBXDv27dyI3O4NwE7WQTzdWcOKfXmZgZDWWtz/fPno4UwoLmtynNSmrqiWnFc7eq6Qgkurc44mjdhuUFceH3G5ZHV9XMA76jIs/LvXN24iteoNYhxzSxnwN2+/o+NPyNiyH2grYVgJl6/Atn9U1a9VXbRksifalxLuy0XPYRke6hiqoJZ2KWBoxjAhpfOK9qfE0wiHolJFJUbfxjB12AJ1rixm08BYWZB9J7vgz+WTxXKYX/YrBtpaV4YH8vvIMVnUYyn77D+OIofn06dqRIT2z6ZGTSWVtlIqaCJ0z08lMb9ifsv27rqVqG/9ZWsy37p/HpP3zuOK4IYwf0L1FPrc5lBREZN/avApWvgbRGgh3gLTM+PDc+fcTKfmI2tIS0qs3Eq4th8xuEK0hVluJuWOxGixa0+CQGz2HdKJ0tgoAPo4V0NdKiHXIIWvyD/HX/4hVbgbgM3qxONqPzZ7NVrKD1ywKbANldKJDZhZV4WzWZg6lc04WNZbJunVryIlupnf/ofQePJyq2ihbKmrJygiTl51B7y7b+1OcTdtqKa2qZWjPbMKhEJU1EWIObyz5lKVrtzCgd0+G9+lMz86Z5OdkkJedQUZaiGWfl1FeHSEvO4PfP/Yq50WewmK1PFx1KPuPOYJjh/diZEFnaiIxnl/0OXk5GYwq6EKXjun07pJJWjjUIpdPSUFEWo9YNF5L2f7dU10Kn/yH6g2fYrXldDjse/ia+VS+908qu+xH9xOvxrr2jzeZrV8MRfPx5S9Ss/FTrHIT4arNhL02fuhgupIvU+6ZRAkRtTDuRiUdKPUsaghTTQcG2udkUMuS2AAqyCCTGrKsisLQJ8QwPmIg66PZlNORcu9IBRlkWxWDbS3rvRubPIdjw++SHy7HQmlYpJLPvTvzYkP5MDYAcIaHVrPeu/G5d2MzOVSEcuie14u07O7UdOhKJL0zBdEiLL0jtZndqPV0euV1p19uJ8KhED07ZzCs155Nt9KmkoKZnQT8NxAG7nb33+1qWyUFEcE93rRVsQk65UJ1WbwfZVtJ/IbDaE28nyUjBzoX4MWLiWxciXmMNKK4x6iuKKOmYiuhSBWhaBXebTBp6R2o/fxDQpFKSMvEY1EyDzyJcAi8aC7RilKiVaVQXYrVVhANdSDSbT86VG8itK0E6zmctFN+D90GwgePUrvydfzTd+hQvgaASOe+hCo2xo/fTNWeRgldqfUwq7sfxuQr7tujf7I2kxTMLAx8BBwPFAFzgfPc/cPGtldSEJE2p7oMsPgAAfd4wqrcFJ9SpWLTF8uVm6HrwPiNkVVb8doqyjavJ1L6OR6NEOs7kfxjf7BHITSVFFrb/fMTgeXuvgLAzGYAU4BGk4KISJuTkfPFsgXJISM7PpKsCQa0xNy8LdOr0XwFwGf13hcFZXXM7GIzm2dm80pKSlo0OBGR9q61JYXGxort0L7l7ne6+wR3n5Cfn99CYYmIpIbWlhSKgH713vcF1iYpFhGRlNPaksJcYIiZDTKzDsBUYGaSYxIRSRmtqqPZ3SNm9n3gBeJDUu9198VJDktEJGW0qqQA4O7PAs8mOw4RkVTU2pqPREQkiZQURESkTqu6o3l3mVkJsHovDpEHbNhH4SRTezkP0Lm0VjqX1mlPz2WAuzc6pr9NJ4W9ZWbzdnWrd1vSXs4DdC6tlc6ldUrEuaj5SERE6igpiIhInVRPCncmO4B9pL2cB+hcWiudS+u0z88lpfsURERkR6leUxARkXqUFEREpE5KJgUzO8nMlpnZcjO7Jtnx7C4zW2VmH5jZQjObF5R1N7MXzezj4LVbsuNsjJnda2brzWxRvbJdxm5m1wbXaZmZnZicqBu3i3O53szWBNdmoZmdUm9dqzwXM+tnZi+b2RIzW2xmPwzK29x1aeJc2uJ1yTSzOWb2XnAuvw7KE3td3D2lfohPtPcJMBjoALwHDE92XLt5DquAvJ3KbgauCZavAX6f7Dh3EfuRwDhg0ZfFDgwPrk8GMCi4buFkn8OXnMv1wI8b2bbVngvQGxgXLOcQfyTu8LZ4XZo4l7Z4XQzIDpbTgXeAQxJ9XVKxplD3yE93rwG2P/KzrZsC3B8s3w+ckbxQds3dZwObdireVexTgBnuXu3uK4HlxK9fq7CLc9mVVnsu7r7O3RcEy2XAEuJPPGxz16WJc9mV1nwu7u7lwdv04MdJ8HVJxaTwpY/8bAMc+LeZzTezi4Oynu6+DuK/GECPpEW3+3YVe1u9Vt83s/eD5qXtVfs2cS5mNhAYS/yv0jZ9XXY6F2iD18XMwma2EFgPvOjuCb8uqZgUvvSRn23A4e4+DjgZuMzMjkx2QAnSFq/VX4D9gEJgHXBrUN7qz8XMsoHHgSvcvbSpTRspa+3n0iavi7tH3b2Q+FMoJ5rZyCY23yfnkopJoc0/8tPd1wav64EniFcRi82sN0Dwuj55Ee62XcXe5q6VuxcHv8gx4C6+qL636nMxs3TiX6IPufs/g+I2eV0aO5e2el22c/ctwCvASST4uqRiUmjTj/w0sywzy9m+DJwALCJ+DhcEm10APJWcCPfIrmKfCUw1swwzGwQMAeYkIb5m2/7LGvgq8WsDrfhczMyAe4Al7v6Heqva3HXZ1bm00euSb2Zdg+WOwHHAUhJ9XZLdw56kXv1TiI9K+AT4ebLj2c3YBxMfYfAesHh7/EAuMAv4OHjtnuxYdxH/w8Sr77XE/7L5VlOxAz8PrtMy4ORkx9+Mc3kA+AB4P/gl7d3azwWYRLyZ4X1gYfBzSlu8Lk2cS1u8LqOBd4OYFwG/CsoTel00zYWIiNRJxeYjERHZBSUFERGpo6QgIiJ1lBRERKSOkoKIiNRRUhBJEjObbGZPJzsOkfqUFEREpI6SgsiXMLPzg3ntF5rZX4NJysrN7FYzW2Bms8wsP9i20MzeDiZee2L7xGtmtr+ZvRTMjb/AzPYLDp9tZo+Z2VIzeyi4I1ckaZQURJpgZgcC5xKfhLAQiALTgCxggccnJnwVuC7Y5f+Aq919NPE7aLeXPwTc7u5jgMOI3wkN8Vk8ryA+F/5g4PAEn5JIk9KSHYBIK3csMB6YG/wR35H4BGQx4B/BNg8C/zSzLkBXd381KL8feDSYq6rA3Z8AcPcqgOB4c9y9KHi/EBgIvJ7wsxLZBSUFkaYZcL+7X7tDodkvd9quqflimmoSqq63HEW/k5Jkaj4Sados4Gwz6wF1z8cdQPx35+xgm68Dr7v7VmCzmR0RlH8DeNXj8/kXmdkZwTEyzKxTS56ESHPprxKRJrj7h2b2C+JPugsRnxH1MmAbMMLM5gNbifc7QHwq4/8NvvRXABcG5d8A/mpmvwmOcU4LnoZIs2mWVJE9YGbl7p6d7DhE9jU1H4mISB3VFEREpI5qCiIiUkdJQURE6igpiIhIHSUFERGpo6QgIiJ1/j/h6mQyEUoN1QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training Loss', 'Validation Loss'], loc='upper left')\n",
    "plt.show()\n",
    "# # summarize history for loss\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2e10152-c2a2-4d7d-b06a-5cac6dfef573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "file_path = glob.glob('/home/dibora_gebreyohannes/AMH-STT/data/test/wav/*.wav')\n",
    "# file_path = file_path[28:32]\n",
    "audio_list = []\n",
    "fs_list = []\n",
    "dur_list = []\n",
    "dropped_file_path = []\n",
    "\n",
    "for file_name in file_path:\n",
    "    audio,fs = librosa.load(file_name,sr=16000)\n",
    "    dur = librosa.get_duration(audio,sr=16000)\n",
    "    if dur > 2 and dur < 6:\n",
    "        dropped_file_path.append(file_name)\n",
    "        audio_list.append(audio)\n",
    "        dur_list.append(dur)\n",
    "        fs_list.append(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389e1fb5-19e0-43e2-a0dc-a7d000ee928f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d2819bd-fbb4-43ee-8f1e-5bf82b0f89c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "     \n",
      "   \n",
      "      \n",
      "     \n",
      "Decoded:\n",
      "     \n",
      "   \n",
      "      \n",
      "     \n",
      "          \n",
      "      \n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "# Decoding\n",
    "print('Original:')\n",
    "print(original_list[0])\n",
    "print(original_list[1])\n",
    "print(original_list[2])\n",
    "print(original_list[3])\n",
    "print('Decoded:')\n",
    "\n",
    "\n",
    "train_inputs = tf.ragged.constant([i for i in inputs_list[:6]], dtype=np.float32)\n",
    "train_seq_len = tf.cast(train_inputs.row_lengths(), tf.int32)\n",
    "train_inputs = train_inputs.to_tensor(default_value=FEAT_MASK_VALUE)\n",
    "\n",
    "decoded, _ = tf.nn.ctc_greedy_decoder(tf.transpose(\n",
    "    model_predict.predict(train_inputs), (1, 0, 2)), train_seq_len)\n",
    "\n",
    "d = tf.sparse.to_dense(decoded[0], default_value=-1).numpy()\n",
    "str_decoded = [''.join([alphabets['num_to_char'][str(x)]\n",
    "                       for x in np.asarray(row) if x != -1]) for row in d]\n",
    "\n",
    "# print('decoded',str_decoded)\n",
    "for s in str_decoded:\n",
    "    # Replacing blank label to none\n",
    "    # s = s.replace(chr(ord('z') + 1), '')\n",
    "    # Replacing space label to space\n",
    "    s = s.replace(alphabets['num_to_char']['0'], ' ')\n",
    "    print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382d422e-0f52-4970-a7f3-d5a2aabe639a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
