{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import scipy.io.wavfile as wav\n",
    "import glob\n",
    "import numpy as np\n",
    "import six\n",
    "from six.moves import xrange as range\n",
    "import json\n",
    "from python_speech_features import mfcc\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow\n",
    "import math\n",
    "import os\n",
    "from tensorflow.keras.layers import (BatchNormalization, Conv1D, Dense, Input,TimeDistributed, Activation, Bidirectional, SimpleRNN, GRU, LSTM)\n",
    "import librosa.display\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint \n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "import gc\n",
    " \n",
    "import IPython.display as ipd\n",
    "import soundfile\n",
    "\n",
    "import random\n",
    "\n",
    "import librosa\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# tf.debugging.set_log_device_placement(True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# Constants \n",
    "SPACE_TOKEN = '<space>'\n",
    "SPACE_INDEX = 0\n",
    "FIRST_INDEX = 1\n",
    "FEAT_MASK_VALUE = 1e+10\n",
    "\n",
    "# Some configs\n",
    "num_features = 13\n",
    "num_units = 100\n",
    "num_classes = 285 + 1 # 285(including space) + blamk label = 286\n",
    "\n",
    "# Hyper-parameters\n",
    "num_epochs = 25\n",
    "num_layers = 1\n",
    "batch_size = 2\n",
    "initial_learning_rate = 0.005\n",
    "momentum = 0.9"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# Loading the data\n",
    "file_path = glob.glob('../data/train/wav*/*.wav')\n",
    "file_path=file_path[1:200]\n",
    "audio_list = []\n",
    "fs_list = []\n",
    "dur_list = []\n",
    "dropped_file_path = []\n",
    "\n",
    "for file_name in file_path:\n",
    "    audio,fs = librosa.load(file_name,sr=16000)\n",
    "    dur = librosa.get_duration(audio,sr=16000)\n",
    "    audio_list.append(audio)\n",
    "    dur_list.append(dur)\n",
    "    fs_list.append(fs)\n",
    "        \n",
    "print(audio_list)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "        6.7117267e-05, -8.8701374e-05,  0.0000000e+00], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([ 0.        ,  0.        ,  0.        , ..., -0.11331162,\n",
      "       -0.12539865, -0.11235649], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([-0.1008661 , -0.12680659, -0.10911231, ..., -0.12267692,\n",
      "       -0.13380562, -0.12095068], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([-0.01868729, -0.0231715 , -0.02033202, ..., -0.01992582,\n",
      "       -0.02184541, -0.0194082 ], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([-0.01748191, -0.02315393, -0.01848109, ..., -0.01950926,\n",
      "       -0.02104453, -0.01912533], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# Create a dataset composed of data with variable lengths\n",
    "inputs_list = []\n",
    "for index in range(len(audio_list)):\n",
    "    input_val = mfcc(audio_list[index], samplerate=fs_list[index])\n",
    "    input_val = (input_val - np.mean(input_val)) / np.std(input_val)\n",
    "    inputs_list.append(input_val)\n",
    "\n",
    "# Transform in 3D Array\n",
    "train_inputs = tf.ragged.constant([i for i in inputs_list], dtype=np.float32)\n",
    "train_seq_len = tf.cast(train_inputs.row_lengths(), tf.int32)\n",
    "train_inputs = train_inputs.to_tensor(default_value=FEAT_MASK_VALUE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "with open('../data/train1.json', 'r', encoding='UTF-8') as label_file:\n",
    "    labels = json.load(label_file)\n",
    "with open('../data/language_model.json', 'r', encoding='UTF-8') as language_file:\n",
    "    alphabets = json.load(language_file)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# Reading Targets\n",
    "original_list = []\n",
    "targets_list = []\n",
    "\n",
    "for path in file_path:\n",
    "    file_name = path[:-4].split('wav')[1][1:]\n",
    "    # Read Label\n",
    "    label = labels[file_name]\n",
    "    original = \" \".join(label.strip().split(' '))\n",
    "    original_list.append(original)\n",
    "    # print(original)\n",
    "    target = original.replace(' ', '  ')\n",
    "    # print('step-1. ',target)\n",
    "    target = target.split(' ')\n",
    "    # print('step-2. ', target)\n",
    "    # Adding blank label\n",
    "    target = np.hstack([SPACE_TOKEN if x == '' else list(x) for x in target])\n",
    "    # print('step-3. ', target)\n",
    "    # Transform char into index\n",
    "    target = np.asarray([alphabets['char_to_num'][x] for x in target])\n",
    "    # print('step-4. ', target)\n",
    "    targets_list.append(target)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "# Creating sparse representation to feed the placeholder\n",
    "train_targets = tf.ragged.constant([i for i in targets_list], dtype=np.int32)\n",
    "train_targets_len = tf.cast(train_targets.row_lengths(), tf.int32)\n",
    "train_targets = train_targets.to_sparse()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "train_targets.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TensorShape([199, 163])"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "# Split Training and Validation sets\n",
    "# train_inputs, val_inputs = train_inputs[:800], train_inputs[800:]\n",
    "# train_seq_len, val_seq_len = train_seq_len[:800], train_seq_len[800:]\n",
    "# train_targets, val_targets = tf.sparse.slice(train_targets, start=[0, 0], size=[800, 163]), tf.sparse.slice(train_targets, start=[800, 0], size=[200, 163])\n",
    "# train_targets_len, val_targets_len = train_targets_len[:800], train_targets_len[800:]\n",
    "\n",
    "# train_inputs, val_inputs = train_inputs[:5], train_inputs[5:]\n",
    "# train_seq_len, val_seq_len = train_seq_len[:5], train_seq_len[5:]\n",
    "# train_targets, val_targets = tf.sparse.slice(train_targets, start=[0, 0], size=[\n",
    "#                                              5, 73]), tf.sparse.slice(train_targets, start=[5, 0], size=[5, 73])\n",
    "# train_targets_len, val_targets_len = train_targets_len[:5], train_targets_len[5:]\n",
    "\n",
    "val_inputs, val_targets, val_seq_len, val_targets_len = train_inputs, train_targets, train_seq_len, train_targets_len\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "class CTCLossLayer(tf.keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        labels = inputs[0]\n",
    "        logits = inputs[1]\n",
    "        label_len = inputs[2]\n",
    "        logit_len = inputs[3]\n",
    "\n",
    "        logits_trans = tf.transpose(logits, (1,0,2))\n",
    "        label_len = tf.reshape(label_len, (-1,))\n",
    "        logit_len = tf.reshape(logit_len, (-1,))\n",
    "        loss = tf.reduce_mean(tf.nn.ctc_loss(labels, logits_trans, label_len, logit_len, blank_index=-1))\n",
    "        # define loss here instead of in compile\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        # Decode\n",
    "        decoded, _ = tf.nn.ctc_greedy_decoder(logits_trans, logit_len)\n",
    "\n",
    "        # Inaccuracy: label error rate\n",
    "        ler = tf.reduce_mean(tf.edit_distance(tf.cast(decoded[0], tf.int32),labels))\n",
    "        self.add_metric(ler, name='ler', aggregation='mean')\n",
    "\n",
    "        return logits\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "# Defining Training Cells\n",
    "cells = []\n",
    "for _ in range(num_layers):\n",
    "    cell = tf.keras.layers.LSTMCell(num_units)\n",
    "    cells.append(cell)\n",
    "\n",
    "stack = tf.keras.layers.StackedRNNCells(cells)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "# Definning Input Parameters\n",
    "input_feature = tf.keras.layers.Input((None, num_features), name='input_feature')\n",
    "input_label = tf.keras.layers.Input((None,), dtype=tf.int32, sparse=True, name='input_label')\n",
    "input_feature_len = tf.keras.layers.Input((1,), dtype=tf.int32, name='input_feature_len')\n",
    "input_label_len =tf.keras.layers.Input((1,), dtype=tf.int32, name='input_label_len')\n",
    "\n",
    "layer_masking = tf.keras.layers.Masking(FEAT_MASK_VALUE)(input_feature)\n",
    "layer_rnn = tf.keras.layers.RNN(stack, return_sequences=True)(layer_masking)\n",
    "# layer_drop = tf.keras.layers.Dropout(0.2, seed=42)(layer_rnn)\n",
    "layer_output = tf.keras.layers.Dense(num_classes, kernel_initializer=tf.keras.initializers.TruncatedNormal(0.0,0.1), bias_initializer='zeros', name='logit')(layer_rnn)\n",
    "\n",
    "layer_loss = CTCLossLayer()([input_label, layer_output, input_label_len, input_feature_len])\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "# Create models for training and prediction\n",
    "model_train = tf.keras.models.Model(inputs=[input_feature, input_label, input_feature_len, input_label_len],\n",
    "            outputs=layer_loss)\n",
    "print(model_train.summary())\n",
    "model_predict = tf.keras.models.Model(inputs=input_feature, outputs=layer_output)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_feature (InputLayer)      [(None, None, 13)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_2 (Masking)             (None, None, 13)     0           input_feature[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "rnn_1 (RNN)                     (None, None, 100)    45600       masking_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_label (InputLayer)        [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "logit (Dense)                   (None, None, 286)    28886       rnn_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_label_len (InputLayer)    [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_feature_len (InputLayer)  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc_loss_layer_2 (CTCLossLayer) (None, None, 286)    0           input_label[0][0]                \n",
      "                                                                 logit[0][0]                      \n",
      "                                                                 input_label_len[0][0]            \n",
      "                                                                 input_feature_len[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 74,486\n",
      "Trainable params: 74,486\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "# Compile Training Model with selected optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(initial_learning_rate, momentum)\n",
    "model_train.compile(optimizer=optimizer)\n",
    "checkpointer = ModelCheckpoint(filepath='../models/'+\"RNN\"+'.h5',monitor='val_loss',verbose=1, save_best_only=True, mode='min')\n",
    "# Training, Our y is already defined so no need\n",
    "try:\n",
    "    experiment_id = mlflow.create_experiment(\"Stacked RNN(LSTM): 50 Cells\")\n",
    "    experiment = mlflow.get_experiment(experiment_id)\n",
    "except mlflow.exceptions.MlflowException:\n",
    "    experiment = mlflow.get_experiment_by_name(\"Stacked RNN(LSTM): 50 Cells\")\n",
    "\n",
    "mlflow.tensorflow.autolog()\n",
    "history=model_train.fit(x=[train_inputs, train_targets, train_seq_len, train_targets_len], y=None,validation_data=([val_inputs, val_targets, val_seq_len, val_targets_len], None),batch_size=batch_size, callbacks=[checkpointer],epochs=num_epochs)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021/08/13 12:55:26 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of tensorflow. If you encounter errors during autologging, try upgrading / downgrading tensorflow to a supported version, or try upgrading MLflow.\n",
      "2021/08/13 12:55:26 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'a52fc1c9c03e47c6ad4df188e24ba55d', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/25\n",
      "100/100 [==============================] - 78s 767ms/step - loss: 491.1688 - ler: 0.9931 - val_loss: 235.2279 - val_ler: 0.9716\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 235.22791, saving model to ../models/RNN.h5\n",
      "Epoch 2/25\n",
      "100/100 [==============================] - 75s 746ms/step - loss: 233.8994 - ler: 0.9714 - val_loss: 233.5392 - val_ler: 0.9716\n",
      "\n",
      "Epoch 00002: val_loss improved from 235.22791 to 233.53915, saving model to ../models/RNN.h5\n",
      "Epoch 3/25\n",
      "100/100 [==============================] - 65s 654ms/step - loss: 235.3895 - ler: 0.9716 - val_loss: 235.4262 - val_ler: 0.9716\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 233.53915\n",
      "Epoch 4/25\n",
      "100/100 [==============================] - 71s 716ms/step - loss: 234.2376 - ler: 0.9715 - val_loss: 233.4127 - val_ler: 0.9716\n",
      "\n",
      "Epoch 00004: val_loss improved from 233.53915 to 233.41266, saving model to ../models/RNN.h5\n",
      "Epoch 5/25\n",
      "100/100 [==============================] - 70s 699ms/step - loss: 233.5114 - ler: 0.9715 - val_loss: 231.6239 - val_ler: 0.9715\n",
      "\n",
      "Epoch 00005: val_loss improved from 233.41266 to 231.62390, saving model to ../models/RNN.h5\n",
      "Epoch 6/25\n",
      "100/100 [==============================] - 71s 710ms/step - loss: 221.3684 - ler: 0.9702 - val_loss: 207.7748 - val_ler: 0.9651\n",
      "\n",
      "Epoch 00006: val_loss improved from 231.62390 to 207.77477, saving model to ../models/RNN.h5\n",
      "Epoch 7/25\n",
      "100/100 [==============================] - 65s 655ms/step - loss: 203.7150 - ler: 0.9499 - val_loss: 196.1016 - val_ler: 0.9408\n",
      "\n",
      "Epoch 00007: val_loss improved from 207.77477 to 196.10158, saving model to ../models/RNN.h5\n",
      "Epoch 8/25\n",
      "100/100 [==============================] - 66s 665ms/step - loss: 198.2587 - ler: 0.9433 - val_loss: 194.9028 - val_ler: 0.9408\n",
      "\n",
      "Epoch 00008: val_loss improved from 196.10158 to 194.90282, saving model to ../models/RNN.h5\n",
      "Epoch 9/25\n",
      "100/100 [==============================] - 66s 665ms/step - loss: 194.8446 - ler: 0.9481 - val_loss: 194.1576 - val_ler: 0.9547\n",
      "\n",
      "Epoch 00009: val_loss improved from 194.90282 to 194.15758, saving model to ../models/RNN.h5\n",
      "Epoch 10/25\n",
      "100/100 [==============================] - 67s 672ms/step - loss: 193.0315 - ler: 0.9504 - val_loss: 190.7680 - val_ler: 0.9455\n",
      "\n",
      "Epoch 00010: val_loss improved from 194.15758 to 190.76799, saving model to ../models/RNN.h5\n",
      "Epoch 11/25\n",
      "100/100 [==============================] - 70s 697ms/step - loss: 191.6973 - ler: 0.9459 - val_loss: 189.2630 - val_ler: 0.9467\n",
      "\n",
      "Epoch 00011: val_loss improved from 190.76799 to 189.26305, saving model to ../models/RNN.h5\n",
      "Epoch 12/25\n",
      "100/100 [==============================] - 65s 648ms/step - loss: 190.3861 - ler: 0.9464 - val_loss: 191.1043 - val_ler: 0.9499\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 189.26305\n",
      "Epoch 13/25\n",
      "100/100 [==============================] - 66s 663ms/step - loss: 188.6469 - ler: 0.9497 - val_loss: 186.4814 - val_ler: 0.9536\n",
      "\n",
      "Epoch 00013: val_loss improved from 189.26305 to 186.48138, saving model to ../models/RNN.h5\n",
      "Epoch 14/25\n",
      "100/100 [==============================] - 66s 661ms/step - loss: 185.8957 - ler: 0.9526 - val_loss: 189.5203 - val_ler: 0.9487\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 186.48138\n",
      "Epoch 15/25\n",
      "100/100 [==============================] - 68s 685ms/step - loss: 182.0235 - ler: 0.9447 - val_loss: 177.7999 - val_ler: 0.9446\n",
      "\n",
      "Epoch 00015: val_loss improved from 186.48138 to 177.79990, saving model to ../models/RNN.h5\n",
      "Epoch 16/25\n",
      "100/100 [==============================] - 69s 693ms/step - loss: 178.6066 - ler: 0.9332 - val_loss: 175.4135 - val_ler: 0.9500\n",
      "\n",
      "Epoch 00016: val_loss improved from 177.79990 to 175.41345, saving model to ../models/RNN.h5\n",
      "Epoch 17/25\n",
      "100/100 [==============================] - 67s 675ms/step - loss: 177.6771 - ler: 0.9428 - val_loss: 175.0716 - val_ler: 0.9518\n",
      "\n",
      "Epoch 00017: val_loss improved from 175.41345 to 175.07162, saving model to ../models/RNN.h5\n",
      "Epoch 18/25\n",
      "100/100 [==============================] - 67s 673ms/step - loss: 175.7781 - ler: 0.9462 - val_loss: 173.1071 - val_ler: 0.9485\n",
      "\n",
      "Epoch 00018: val_loss improved from 175.07162 to 173.10707, saving model to ../models/RNN.h5\n",
      "Epoch 19/25\n",
      "100/100 [==============================] - 68s 677ms/step - loss: 174.4455 - ler: 0.9266 - val_loss: 173.1716 - val_ler: 0.9077\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 173.10707\n",
      "Epoch 20/25\n",
      "100/100 [==============================] - 71s 709ms/step - loss: 174.3362 - ler: 0.8844 - val_loss: 174.6311 - val_ler: 0.8686\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 173.10707\n",
      "Epoch 21/25\n",
      "100/100 [==============================] - 67s 672ms/step - loss: 177.9773 - ler: 0.9155 - val_loss: 172.1397 - val_ler: 0.9296\n",
      "\n",
      "Epoch 00021: val_loss improved from 173.10707 to 172.13974, saving model to ../models/RNN.h5\n",
      "Epoch 22/25\n",
      "100/100 [==============================] - 67s 676ms/step - loss: 171.9254 - ler: 0.8791 - val_loss: 170.4172 - val_ler: 0.8557\n",
      "\n",
      "Epoch 00022: val_loss improved from 172.13974 to 170.41721, saving model to ../models/RNN.h5\n",
      "Epoch 23/25\n",
      "100/100 [==============================] - 67s 675ms/step - loss: 171.8815 - ler: 0.8624 - val_loss: 169.7001 - val_ler: 0.8633\n",
      "\n",
      "Epoch 00023: val_loss improved from 170.41721 to 169.70010, saving model to ../models/RNN.h5\n",
      "Epoch 24/25\n",
      "100/100 [==============================] - 67s 675ms/step - loss: 172.5647 - ler: 0.8577 - val_loss: 170.4404 - val_ler: 0.8546\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 169.70010\n",
      "Epoch 25/25\n",
      "100/100 [==============================] - 71s 716ms/step - loss: 170.9274 - ler: 0.8715 - val_loss: 168.8298 - val_ler: 0.8435\n",
      "\n",
      "Epoch 00025: val_loss improved from 169.70010 to 168.82977, saving model to ../models/RNN.h5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpw9g5_img/model/data/model/assets\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpw9g5_img/model/data/model/assets\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Decoding\n",
    "print('Original:')\n",
    "print(original_list[0])\n",
    "print(original_list[1])\n",
    "print(original_list[2])\n",
    "print(original_list[3])\n",
    "print('Decoded:')\n",
    "\n",
    "\n",
    "# train_inputs = tf.ragged.constant([i for i in inputs_list[:6]], dtype=np.float32)\n",
    "# train_seq_len = tf.cast(train_inputs.row_lengths(), tf.int32)\n",
    "# train_inputs = train_inputs.to_tensor(default_value=FEAT_MASK_VALUE)\n",
    "\n",
    "decoded, _ = tf.nn.ctc_greedy_decoder(tf.transpose(\n",
    "    model_predict.predict(train_inputs), (1, 0, 2)), train_seq_len)\n",
    "\n",
    "d = tf.sparse.to_dense(decoded[0], default_value=-1).numpy()\n",
    "str_decoded = [''.join([alphabets['num_to_char'][str(x)]\n",
    "                       for x in np.asarray(row) if x != -1]) for row in d]\n",
    "\n",
    "# print('decoded',str_decoded)\n",
    "for s in str_decoded:\n",
    "    # Replacing blank label to none\n",
    "    # s = s.replace(chr(ord('z') + 1), '')\n",
    "    # Replacing space label to space\n",
    "    s = s.replace(alphabets['num_to_char']['0'], ' ')\n",
    "    print(s)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "alphabets['num_to_char']['0']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y,sr= librosa.load('../data/train/wav/tr_10_tr01010#bn00.wav',sr=16000)\n",
    "\n",
    "def plot_raw_audio(y, title='Audio Signal', size=(12, 3)):\n",
    "    fig = plt.figure(figsize=size)\n",
    "    ax = fig.add_subplot(111)\n",
    "    steps = len(y)\n",
    "    ax.plot(np.linspace(1, steps, steps), y)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.show()\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_raw_audio(vis_raw_audio)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X = librosa.stft(y)\n",
    "Xdb = librosa.amplitude_to_db(abs(X))\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "def plot_mfcc_feature(vis_mfcc_feature):\n",
    "    # plot the MFCC feature\n",
    "    fig = plt.figure(figsize=(12,5))\n",
    "    ax = fig.add_subplot(111)\n",
    "    im = ax.imshow(vis_mfcc_feature, cmap=plt.cm.jet, aspect='auto')\n",
    "    plt.title('Normalized MFCC')\n",
    "    plt.ylabel('Time')\n",
    "    plt.xlabel('MFCC Coefficient')\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    plt.colorbar(im, cax=cax)\n",
    "    ax.set_xticks(np.arange(0, 13, 2), minor=False);\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_mfcc_feature(mfccs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "def plot_spectrogram_feature(vis_spectrogram_feature):\n",
    "    # plot the normalized spectrogram\n",
    "    fig = plt.figure(figsize=(12,5))\n",
    "    ax = fig.add_subplot(111)\n",
    "    im = ax.imshow(vis_spectrogram_feature, cmap=plt.cm.jet, aspect='auto')\n",
    "    plt.title('Normalized Spectrogram')\n",
    "    plt.ylabel('Time')\n",
    "    plt.xlabel('Frequency')\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    plt.colorbar(im, cax=cax)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "print(history.history.keys())\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training Loss'], loc='upper right')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('tf-gpu': conda)"
  },
  "interpreter": {
   "hash": "9e09945fa8d15c93b0c117548153c35f8a8702e830281d3d09dfb9256247df3a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}